{"updatedAt":"2025-12-15T08:35:52.205Z","createdAt":"2025-12-09T08:25:40.962Z","id":"gwd3P1NQMXjuWzQM","name":"Lego Text + Bild V2","description":null,"active":true,"isArchived":false,"nodes":[{"parameters":{"rule":{"interval":[{"field":"cronExpression","expression":"* * * * *"}]}},"id":"schedule-trigger-v2","name":"Schedule Trigger","type":"n8n-nodes-base.scheduleTrigger","typeVersion":1.3,"position":[-3568,-112]},{"parameters":{"method":"POST","url":"https://api.deepseek.com/v1/chat/completions","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Authorization","value":"={{ $('Load Secrets from Supabase').first().json.DEEPSEEK_API_KEY ? 'Bearer ' + $('Load Secrets from Supabase').first().json.DEEPSEEK_API_KEY : 'Bearer sk-fd178bb87e1240b19786ce816c77d07f' }}"},{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ JSON.stringify({ model: 'deepseek-chat', messages: [{ role: 'system', content: 'Du bist ein Experte für Marktanalyse und E-Book-Trends. Analysiere aktuelle Topseller und Trends aus ALLEN Stilrichtungen (Fiction, Non-Fiction, Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch, Handwerk, Kreativ, Design) und ALLEN Bereichen (Business, Privat, Hobby, Bildung, Gesundheit, Finanzen, Technik, Lifestyle, Handwerk, Kreativität) für verschiedene Zielgruppen: JUNG und ALT, BUSINESS und PRIVAT. Identifiziere profitable E-Book-Themen im DACH-Markt mit hohem Marktpotenzial. Antworte IMMER im JSON-Format mit folgender Struktur: { trends: [{ topic: string (Thema des E-Books, z.B. \"Künstliche Intelligenz im Business\", \"Gesundheit für Senioren\", \"Handwerk für Privatpersonen\"), genre: string (Fiction, Non-Fiction, Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch, Handwerk, Kreativ), target_audience: string (z.B. \"Junge Erwachsene\", \"Senioren\", \"Unternehmer\", \"Privatpersonen\", \"Berufstätige\", \"Handwerker\", \"Kreative\"), popularity: number (1-10), reasoning: string (Warum ist dieses Thema profitabel? Welche Zielgruppe spricht es an?) }], market_insights: string (Zusammenfassung der Marktanalyse) }' }, { role: 'user', content: 'Analysiere die aktuellen E-Book-Topseller und Trends für den DACH-Markt im Jahr 2025. Überprüfe ALLE Stilrichtungen (Fiction, Non-Fiction, Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch, Handwerk, Kreativ, Design) und ALLE Bereiche (Business, Privat, Hobby, Bildung, Gesundheit, Finanzen, Technik, Lifestyle, Handwerk, Kreativität). Berücksichtige verschiedene Zielgruppen: JUNG und ALT, BUSINESS und PRIVAT. Identifiziere 5-7 profitable Themen mit hohem Marktpotenzial aus verschiedenen Kategorien. Fokussiere auf aktuelle Topseller und Trends. Stelle sicher, dass die Themen eine gute Mischung aus verschiedenen Stilrichtungen, Bereichen und Zielgruppen darstellen.' }], temperature: 0.7 }) }}","options":{}},"id":"analyze-trends-v2","name":"Analyze Trends","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[-3152,288],"alwaysOutputData":true,"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Verbesserte Duplikatsprüfung - FIXED VERSION\n// Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Verwendet Topic aus Chat Input, falls vorhanden\n// ERWEITERT: Funktioniert direkt mit Process DeepSeek Parse (intelligent geparst)\n// ERWEITERT: Leitet ALLE Daten weiter, auch wenn sie null sind\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nfunction extractTrendsData(aiResponse) {\n  try {\n    // DeepSeek Response-Struktur\n    if (aiResponse.choices?.[0]?.message?.content) {\n      const content = aiResponse.choices[0].message.content;\n      const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        const parsed = JSON.parse(jsonMatch[0]);\n        return {\n          trends: parsed.trends || [],\n          marketInsights: parsed.market_insights || '',\n          firstTopic: parsed.trends?.[0]?.topic || ''\n        };\n      }\n    }\n  } catch (e) {\n    console.error('[Check Existing] Parse error:', e);\n  }\n  \n  return {\n    trends: [],\n    marketInsights: '',\n    firstTopic: ''\n  };\n}\n\n// WICHTIG: Verwende Input-Daten (kann von Process DeepSeek Parse ODER Intelligent Market Analysis kommen)\nconst inputData = $input.item.json || {};\n\nconsole.log('[Check Existing] Input Data keys:', Object.keys(inputData));\nconsole.log('[Check Existing] Input Data chapterCount:', inputData.chapterCount);\nconsole.log('[Check Existing] Input Data wordsPerChapter:', inputData.wordsPerChapter);\nconsole.log('[Check Existing] Input Data topic:', inputData.topic);\n\n// ERWEITERT: Prüfe ob Input von Process DeepSeek Parse kommt (intelligent geparst)\nconst isFromDeepSeekParse = !!(inputData._fromDeepSeek || inputData._fromFallback || inputData.chatInput);\n\n// ERWEITERT: Prüfe ob Input direkt von Process DeepSeek Parse kommt\nconst isFromChatInput = isFromDeepSeekParse || !!(inputData.chatInput || (inputData.topic && (inputData.chapterCount !== undefined || inputData.wordsPerChapter !== undefined)));\n\n// NEU: Versuche Topic und Parameter aus Chat Input zu holen (hat Priorität)\nlet chatTopic = '';\nlet chatInputData = {};\n\nif (isFromChatInput || isFromDeepSeekParse) {\n  // Input kommt direkt von Process DeepSeek Parse oder Extract Chat Input\n  chatInputData = inputData;\n  chatTopic = inputData.topic || '';\n  console.log('[Check Existing] Input direkt von Process DeepSeek Parse/Extract Chat Input');\n  console.log('[Check Existing] Chat Topic:', chatTopic);\n  console.log('[Check Existing] Chat chapterCount:', chatInputData.chapterCount);\n  console.log('[Check Existing] Chat wordsPerChapter:', chatInputData.wordsPerChapter);\n} else {\n  // Input kommt von Marktanalyse - versuche Chat-Eingaben zu holen\n  try {\n    // Versuche zuerst Process DeepSeek Parse (intelligent geparst)\n    chatInputData = $('Process DeepSeek Parse').item.json || {};\n    chatTopic = chatInputData.topic || '';\n    console.log('[Check Existing] Process DeepSeek Parse gefunden:', chatTopic);\n    console.log('[Check Existing] Process DeepSeek Parse chapterCount:', chatInputData.chapterCount);\n    console.log('[Check Existing] Process DeepSeek Parse wordsPerChapter:', chatInputData.wordsPerChapter);\n  } catch (e) {\n    try {\n      // Fallback: Extract Chat Input\n      chatInputData = $('Extract Chat Input').item.json || {};\n      chatTopic = chatInputData.topic || '';\n      console.log('[Check Existing] Extract Chat Input gefunden:', chatTopic);\n    } catch (e2) {\n      console.log('[Check Existing] Extract Chat Input not found');\n    }\n  }\n}\n\n// Versuche Trends-Daten aus Input zu extrahieren (nur wenn nicht von Chat Input)\nlet trendsData = inputData;\n\nif (!isFromChatInput && !isFromDeepSeekParse) {\n  // Falls Input keine Trends-Daten enthält, versuche von Analyze Trends zu holen (Fallback)\n  if (!trendsData.choices && !trendsData.trends) {\n    try {\n      trendsData = $('Analyze Trends').item.json || inputData;\n    } catch (e) {\n      console.log('[Check Existing] Analyze Trends not found, using input data');\n      trendsData = inputData;\n    }\n  }\n  \n  const extracted = extractTrendsData(trendsData);\n  \n  // WICHTIG: Priorität: Chat Topic > Marktanalyse Topic\n  const finalTopic = chatTopic || extracted.firstTopic || '';\n  \n  console.log('[Check Existing] Chat Topic:', chatTopic);\n  console.log('[Check Existing] Market Analysis Topic:', extracted.firstTopic);\n  console.log('[Check Existing] Final Topic:', finalTopic);\n  console.log('[Check Existing] Has Topic:', !!finalTopic);\n  \n  // Kombiniere Input-Daten mit extrahierten Trends\n  // ERWEITERT: Füge Chat-Daten hinzu, falls vorhanden\n  return {\n    json: {\n      ...inputData,\n      ...trendsData,\n      // ERWEITERT: Füge Chat-Daten hinzu (auch wenn null)\n      topic: chatTopic || finalTopic || inputData.topic || null,\n      chapterCount: chatInputData.chapterCount !== undefined ? chatInputData.chapterCount : (inputData.chapterCount !== undefined ? inputData.chapterCount : null),\n      wordsPerChapter: chatInputData.wordsPerChapter !== undefined ? chatInputData.wordsPerChapter : (inputData.wordsPerChapter !== undefined ? inputData.wordsPerChapter : null),\n      textType: chatInputData.textType || inputData.textType || null,\n      coverImageType: chatInputData.coverImageType || inputData.coverImageType || null,\n      hasTopic: !!finalTopic,\n      trends: extracted.trends || inputData.trends || [],\n      marketInsights: extracted.marketInsights || inputData.marketInsights || inputData.market_insights || ''\n    }\n  };\n} else {\n  // Input kommt direkt von Process DeepSeek Parse/Extract Chat Input - verwende Chat-Daten direkt\n  const finalTopic = chatTopic || inputData.topic || null;\n  \n  console.log('[Check Existing] Direkt von Process DeepSeek Parse/Extract Chat Input');\n  console.log('[Check Existing] Final Topic:', finalTopic);\n  console.log('[Check Existing] Has Topic:', !!finalTopic);\n  console.log('[Check Existing] chapterCount:', inputData.chapterCount);\n  console.log('[Check Existing] wordsPerChapter:', inputData.wordsPerChapter);\n  \n  // ERWEITERT: Leite ALLE Chat-Daten weiter (auch wenn null)\n  return {\n    json: {\n      ...inputData, // WICHTIG: Behalte ALLE Daten vom Process DeepSeek Parse\n      topic: finalTopic,\n      hasTopic: !!finalTopic,\n      trends: [], // Keine Trends von Marktanalyse\n      marketInsights: '', // Keine Market Insights\n      _fromChatInput: true, // Flag für Debugging\n      _fromDeepSeekParse: isFromDeepSeekParse // Flag für Debugging\n    }\n  };\n}"},"id":"check-existing-ebooks","name":"Check Existing E-Books (Duplikatsprüfung)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1456,48]},{"parameters":{"jsCode":"// Vereinfachte Volume-Berechnung - FIXED VERSION\n// WICHTIG: Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\nconsole.log('[Volume Calc] Input Data keys:', Object.keys(inputData));\nconsole.log('[Volume Calc] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Volume Calc] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Trends-Daten aus Input zu holen\nlet trendsData = inputData;\n\n// Falls Input keine Trends-Daten enthält, versuche von Check Existing E-Books zu holen (Fallback)\nif (!trendsData.topic && !trendsData.trends) {\n  try {\n    trendsData = $('Check Existing E-Books (Duplikatsprüfung)').item.json || inputData;\n  } catch (e) {\n    console.log('[Volume Calc] Check Existing E-Books not found, using input data');\n    trendsData = inputData;\n  }\n}\n\n// Versuche normalisierte Daten zu holen\nlet normalizedData = {};\ntry {\n  normalizedData = $('Normalize Query Result').item.json || {};\n} catch (e) {\n  console.log('[Volume Calc] Normalize Query Result not found');\n  normalizedData = {};\n}\n\n// Hole maxVolume aus normalisierten Daten\nconst maxVolume = normalizedData.maxVolume || 0;\nconst nextVolumeNumber = maxVolume + 1;\nconst isContinuation = nextVolumeNumber > 1;\n\nconsole.log('[Volume Calc] Max:', maxVolume, 'Next:', nextVolumeNumber, 'Continuation:', isContinuation);\n\n// ERWEITERT: Kombiniere Input-Daten mit Volume-Daten und leite ALLE Daten weiter\nreturn {\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n    ...trendsData, // Behalte Trends-Daten\n    volumeNumber: nextVolumeNumber,\n    isContinuation: isContinuation,\n    maxExistingVolume: maxVolume,\n    querySuccess: normalizedData.querySuccess || false\n  }\n};"},"id":"calculate-volume-number","name":"Calculate Volume Number","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1040,304]},{"parameters":{"jsCode":"// Generiere E-Book-Vorschläge basierend auf Marktanalyse\n// WICHTIG: Topic hat höchste Priorität von Intelligent Market Analysis\n// ERWEITERT: Berücksichtigt Topseller aus allen Stilrichtungen und Bereichen\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\nconsole.log('[Generate Suggestions] ===== E-BOOK SUGGESTIONS GENERATION START =====');\nconsole.log('[Generate Suggestions] Input Data keys:', Object.keys(inputData));\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (hat IMMER Priorität)\nlet marketTopic = null;\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').item.json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  console.log('[Generate Suggestions] ✅ Topic von Intelligent Market Analysis:', marketTopic);\n} catch (e) {\n  console.log('[Generate Suggestions] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Hole Trends von Intelligent Market Analysis\nlet trends = [];\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').item.json || {};\n  trends = marketData.trends || inputData.trends || [];\n  console.log('[Generate Suggestions] ✅ Trends gefunden:', trends.length);\n} catch (e) {\n  console.log('[Generate Suggestions] ⚠️ Trends nicht gefunden, verwende Input-Daten');\n  trends = inputData.trends || [];\n}\n\n// WICHTIG: Topic-Priorität: Market Topic > Input Topic\nconst finalTopic = marketTopic || inputData.topic || inputData.thema || null;\n\nconsole.log('[Generate Suggestions] ✅ Final Topic (Market > Input):', finalTopic);\n\n// Erstelle E-Book-Vorschläge basierend auf Trends\n// WICHTIG: Wenn Topic vorhanden ist, verwende es als Basis\nlet suggestions = [];\n\nif (finalTopic && trends.length > 0) {\n  // Verwende Topic von Marktanalyse und kombiniere mit Trends\n  for (let i = 0; i < Math.min(trends.length, 5); i++) {\n    const trend = trends[i];\n    suggestions.push({\n      topic: trend.topic || finalTopic,\n      genre: trend.genre || 'non-fiction',\n      target_audience: trend.target_audience || 'Berufstätige und Unternehmer',\n      popularity: trend.popularity || 7,\n      reasoning: trend.reasoning || `Basierend auf Marktanalyse: ${finalTopic}`\n    });\n  }\n} else if (trends.length > 0) {\n  // Verwende nur Trends\n  for (let i = 0; i < Math.min(trends.length, 5); i++) {\n    const trend = trends[i];\n    suggestions.push({\n      topic: trend.topic || 'Aktuelle Markttrends',\n      genre: trend.genre || 'non-fiction',\n      target_audience: trend.target_audience || 'Berufstätige und Unternehmer',\n      popularity: trend.popularity || 7,\n      reasoning: trend.reasoning || 'Basierend auf Marktanalyse'\n    });\n  }\n} else if (finalTopic) {\n  // Fallback: Verwende Topic direkt\n  suggestions.push({\n    topic: finalTopic,\n    genre: 'non-fiction',\n    target_audience: 'Berufstätige und Unternehmer',\n    popularity: 7,\n    reasoning: 'Basierend auf Marktanalyse'\n  });\n} else {\n  // Letzter Fallback: Standard-Vorschlag\n  suggestions.push({\n    topic: 'Aktuelle Markttrends',\n    genre: 'non-fiction',\n    target_audience: 'Berufstätige und Unternehmer',\n    popularity: 7,\n    reasoning: 'Standard-Vorschlag basierend auf Marktanalyse'\n  });\n}\n\nconsole.log('[Generate Suggestions] ✅ Suggestions generiert:', suggestions.length);\nconsole.log('[Generate Suggestions] Suggestions:', suggestions.map(s => s.topic));\n\n// WICHTIG: Kombiniere Input-Daten mit Suggestions und Topic\nconst outputData = {\n  ...inputData,\n  // WICHTIG: Topic immer weiterleiten\n  topic: finalTopic,\n  thema: finalTopic,\n  // Suggestions\n  suggestions: suggestions,\n  // Für Kompatibilität\n  trends: trends\n};\n\nconsole.log('[Generate Suggestions] ===== E-BOOK SUGGESTIONS GENERATION END =====');\nconsole.log('[Generate Suggestions] ✅ Final Topic:', outputData.topic);\nconsole.log('[Generate Suggestions] ✅ Suggestions count:', outputData.suggestions.length);\n\nreturn { json: outputData }; // FIXED: Einzelnes Objekt zurückgeben statt Array"},"id":"generate-ebook-suggestions-v2","name":"Generate E-Book Suggestions","type":"n8n-nodes-base.code","typeVersion":2,"position":[-768,48]},{"parameters":{"jsCode":"// Setze Volume Number & Title basierend auf Duplikatsprüfung\n// WICHTIG: Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\n// WICHTIG: volume_number gehört NICHT zu ebook_market_analyses, sondern zu ebook_proposals\n// Dieser Node bereitet Daten für 'Save Market Analysis' vor, der in ebook_market_analyses speichert\n// volume_number wird später in 'Create E-Book Proposals' hinzugefügt\nconst inputData = $input.first().json || {};\n\nconsole.log('[Set Volume] Input Data keys:', Object.keys(inputData));\nconsole.log('[Set Volume] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Set Volume] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Volume-Daten zu holen\nlet volumeData = {};\ntry {\n  volumeData = $('Calculate Volume Number').item.json || {};\n} catch (e) {\n  console.log('[Set Volume] Calculate Volume Number not found, using input data');\n  volumeData = inputData;\n}\n\nconst volumeNumber = volumeData.volumeNumber || inputData.volumeNumber || 1;\nconst isContinuation = volumeData.isContinuation || false;\n\n// Erstelle sauberes Objekt für ebook_market_analyses (OHNE volume_number)\n// Nur Felder, die in ebook_market_analyses existieren:\n// - analysis_date\n// - data_sources\n// - trends\n// - niches\n// - ebook_suggestions\nconst marketAnalysisData = {\n  analysis_date: inputData.analysis_date || new Date().toISOString(),\n  data_sources: inputData.data_sources || {},\n  trends: inputData.trends || [],\n  niches: inputData.niches || [],\n  ebook_suggestions: inputData.ebook_suggestions || []\n};\n\n// volume_number wird NICHT gesendet (existiert nicht in ebook_market_analyses)\n// volume_number wird später in 'Create E-Book Proposals' hinzugefügt\n\n// ERWEITERT: Kombiniere Input-Daten mit Market Analysis Data und leite ALLE Daten weiter\nreturn [{\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n    ...marketAnalysisData, // Market Analysis Data\n    volumeNumber: volumeNumber, // Für spätere Verwendung\n    isContinuation: isContinuation // Für spätere Verwendung\n  }\n}];"},"id":"set-volume-number-title","name":"Set Volume Number & Title","type":"n8n-nodes-base.code","typeVersion":2,"position":[-592,48]},{"parameters":{"tableId":"ebook_market_analyses","fieldsUi":{"fieldValues":[{"fieldId":"analysis_date","fieldValue":"={{ $json.analysis_date }}"},{"fieldId":"data_sources","fieldValue":"={{ $json.data_sources }}"},{"fieldId":"trends","fieldValue":"={{ $json.trends }}"},{"fieldId":"niches","fieldValue":"={{ $json.niches }}"},{"fieldId":"ebook_suggestions","fieldValue":"={{ $json.ebook_suggestions }}"}]}},"id":"save-market-analysis","name":"Save Market Analysis","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-432,48],"alwaysOutputData":true,"retryOnFail":false,"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"options":{}},"id":"split-into-proposals-v2","name":"Split into Proposals","type":"n8n-nodes-base.splitInBatches","typeVersion":3,"position":[-48,48],"onError":"continueErrorOutput"},{"parameters":{"tableId":"ebook_proposals","fieldsUi":{"fieldValues":[{"fieldId":"topic","fieldValue":"={{ $json.topic }}"},{"fieldId":"genre","fieldValue":"={{ $json.genre }}"},{"fieldId":"language","fieldValue":"={{ $json.language }}"},{"fieldId":"target_audience","fieldValue":"={{ $json.target_audience }}"},{"fieldId":"length","fieldValue":"={{ $json.length }}"},{"fieldId":"volume_number","fieldValue":"={{ $json.volume_number }}"}]}},"id":"create-ebook-proposals-v2","name":"Create E-Book Proposals","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[480,288],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.TELEGRAM_CHAT_ID || $json.chat_id || \"578345520\" }}","text":"={{ $json.text || $json.message || $json.telegramMessage || \"No message content available\" }}","additionalFields":{}},"id":"send-telegram-notification-v2","name":"Send Telegram Notification","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[1936,128],"webhookId":"13082362-7fe7-48bf-b577-fe004a3c13c7","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Initialisiere Multi-Kapitel-Loop basierend auf Marktanalyse ODER Input-Daten\n// Priorität: Marktanalyse > Input-Daten > Fallback-Werte\n// KRITISCH: Hole Topic von Intelligent Market Analysis (Trendanalyse), NICHT vom Chat-Input\n// ERWEITERT: Dynamische Kapitel-Titel basierend auf Topic\nconst inputData = $input.first().json || {};\n\nconsole.log('[Init Loop] ===== INITIALIZE MULTI-CHAPTER LOOP START =====');\nconsole.log('[Init Loop] Input Data keys:', Object.keys(inputData));\nconsole.log('[Init Loop] Input Data chapterCount:', inputData.chapterCount);\nconsole.log('[Init Loop] Input Data wordsPerChapter:', inputData.wordsPerChapter);\nconsole.log('[Init Loop] Input Data topic:', inputData.topic);\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (Trendanalyse) - HÖCHSTE PRIORITÄT\nlet marketTopic = null;\nlet marketChapterCount = null;\nlet marketWordsPerChapter = null;\n\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').first().json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  marketChapterCount = marketData.chapterCount !== null && marketData.chapterCount !== undefined ? marketData.chapterCount : null;\n  marketWordsPerChapter = marketData.wordsPerChapter !== null && marketData.wordsPerChapter !== undefined ? marketData.wordsPerChapter : null;\n  console.log('[Init Loop] ✅ Intelligent Market Analysis gefunden');\n  console.log('[Init Loop] Market-Topic:', marketTopic);\n  console.log('[Init Loop] Market-ChapterCount:', marketChapterCount);\n  console.log('[Init Loop] Market-WordsPerChapter:', marketWordsPerChapter);\n} catch (e) {\n  console.log('[Init Loop] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Fallback: Hole von Generate E-Book Suggestions\nlet suggestionTopic = null;\nlet suggestionChapterCount = null;\nlet suggestionWordsPerChapter = null;\n\ntry {\n  const suggestionData = $('Generate E-Book Suggestions').first().json || {};\n  suggestionTopic = suggestionData.topic || suggestionData.thema || null;\n  suggestionChapterCount = suggestionData.chapterCount !== null && suggestionData.chapterCount !== undefined ? suggestionData.chapterCount : null;\n  suggestionWordsPerChapter = suggestionData.wordsPerChapter !== null && suggestionData.wordsPerChapter !== undefined ? suggestionData.wordsPerChapter : null;\n  console.log('[Init Loop] ✅ Generate E-Book Suggestions gefunden');\n  console.log('[Init Loop] Suggestion-Topic:', suggestionTopic);\n} catch (e) {\n  console.log('[Init Loop] ⚠️ Generate E-Book Suggestions not found');\n}\n\n// Versuche Marktanalyse-Parameter zu holen\nlet marketAnalysisParams = {};\ntry {\n  const marketData = $('Merge Market Analysis Params').first().json || {};\n  if (marketData.hasMarketAnalysisParams) {\n    marketAnalysisParams = {\n      textType: marketData.textType,\n      coverImageType: marketData.coverImageType,\n      chapterCount: marketData.chapterCount,\n      wordsPerChapter: marketData.wordsPerChapter,\n      totalWords: marketData.totalWords\n    };\n    console.log('[Init Loop] Found market analysis params');\n    console.log('[Init Loop] Market Analysis chapterCount:', marketAnalysisParams.chapterCount);\n    console.log('[Init Loop] Market Analysis wordsPerChapter:', marketAnalysisParams.wordsPerChapter);\n  }\n} catch (e) {\n  console.log('[Init Loop] Market analysis params not found');\n}\n\n// Versuche Daten von verschiedenen Quellen zu holen\nlet proposalData = {};\n\n// Fall 1: Input-Daten enthalten Proposal-Informationen (von Send Telegram Notification)\nif (inputData.topic || inputData.volume_number) {\n  proposalData = inputData;\n  console.log('[Init Loop] Using Input Data as Proposal Data');\n}\n// Fall 2: Versuche von 'Create E-Book Proposals' zu holen (wenn ausgeführt)\nelse {\n  try {\n    proposalData = $('Create E-Book Proposals').first().json || {};\n    console.log('[Init Loop] Create E-Book Proposals gefunden');\n  } catch (e) {\n    console.log('[Init Loop] Create E-Book Proposals not executed, using input data');\n    proposalData = inputData;\n  }\n}\n\n// WICHTIG: Topic-Priorität: Market Topic (Trendanalyse) > Suggestion Topic > Proposal > Input\nconst topic = marketTopic || suggestionTopic || proposalData.topic || inputData.topic || null;\nconst genre = proposalData.genre || inputData.genre || 'non-fiction';\nconst targetAudience = proposalData.target_audience || inputData.target_audience || 'Berufstaetige und Unternehmer';\nconst proposalId = proposalData.id || inputData.id || '';\nconst volumeNumber = proposalData.volume_number || inputData.volume_number || 1;\n\nconsole.log('[Init Loop] Topic-Priorität:');\nconsole.log('  Market-Topic (Intelligent Market Analysis):', marketTopic || '(nicht vorhanden)');\nconsole.log('  Suggestion-Topic (Generate E-Book Suggestions):', suggestionTopic || '(nicht vorhanden)');\nconsole.log('  Proposal Topic:', proposalData.topic || '(nicht vorhanden)');\nconsole.log('  Input Topic:', inputData.topic || '(nicht vorhanden)');\nconsole.log('  ✅ Final Topic:', topic || '(KEIN TOPIC)');\n\n// Bestimme E-Book-Parameter: Priorität Market > Input > Fallback\nlet chapterCount, wordsPerChapter, totalTargetWords, coverImageType, textType;\n\nif (marketChapterCount !== null && marketWordsPerChapter !== null) {\n  // Marktanalyse-Parameter haben höchste Priorität\n  chapterCount = marketChapterCount;\n  wordsPerChapter = marketWordsPerChapter;\n  coverImageType = inputData.coverImageType || null;\n  textType = inputData.textType || null;\n  console.log('[Init Loop] Using Market Analysis parameters (highest priority)');\n} else if (suggestionChapterCount !== null && suggestionWordsPerChapter !== null) {\n  // Suggestion-Parameter\n  chapterCount = suggestionChapterCount;\n  wordsPerChapter = suggestionWordsPerChapter;\n  coverImageType = inputData.coverImageType || null;\n  textType = inputData.textType || null;\n  console.log('[Init Loop] Using Suggestion parameters');\n} else if (inputData.chapterCount !== undefined && inputData.chapterCount !== null && \n    inputData.wordsPerChapter !== undefined && inputData.wordsPerChapter !== null) {\n  // Input-Daten direkt\n  chapterCount = inputData.chapterCount;\n  wordsPerChapter = inputData.wordsPerChapter;\n  coverImageType = inputData.coverImageType || null;\n  textType = inputData.textType || null;\n  console.log('[Init Loop] Using Input Data parameters');\n} else if (marketAnalysisParams.chapterCount !== undefined && marketAnalysisParams.chapterCount !== null && \n           marketAnalysisParams.wordsPerChapter !== undefined && marketAnalysisParams.wordsPerChapter !== null) {\n  // Marktanalyse-Parameter (von Merge Market Analysis Params)\n  chapterCount = marketAnalysisParams.chapterCount;\n  wordsPerChapter = marketAnalysisParams.wordsPerChapter;\n  coverImageType = marketAnalysisParams.coverImageType || null;\n  textType = marketAnalysisParams.textType || null;\n  console.log('[Init Loop] Using Market Analysis Params');\n} else {\n  // FIXED: Verwende Fallback-Werte statt Fehler zu werfen\n  console.warn('[Init Loop] ⚠️ KEINE E-BOOK-PARAMETER GEFUNDEN - Verwende Fallback-Werte');\n  \n  // Fallback-Werte: Standard E-Book-Parameter\n  chapterCount = 5;\n  wordsPerChapter = 500;\n  coverImageType = null;\n  textType = null;\n  console.log('[Init Loop] Using Fallback Values:', { chapterCount, wordsPerChapter });\n}\n\ntotalTargetWords = chapterCount * wordsPerChapter;\n\nconsole.log('[Init Loop] Final Parameters:');\nconsole.log('  ✅ Topic:', topic);\nconsole.log('  Chapter Count:', chapterCount);\nconsole.log('  Words Per Chapter:', wordsPerChapter);\nconsole.log('  Total Target Words:', totalTargetWords);\nconsole.log('  Cover Image Type:', coverImageType);\nconsole.log('  Text Type:', textType);\n\n// ERWEITERT: Dynamische Kapitel-Titel basierend auf Topic\n// Generiere themenspezifische Kapitel-Titel (nicht mehr hardcodiert)\nconst chapters = [];\nfor (let i = 1; i <= chapterCount; i++) {\n  let title = '';\n  let description = '';\n  \n  // Generiere themenspezifische Titel basierend auf Topic\n  if (topic) {\n    if (i === 1) {\n      title = `Kapitel 1: Einführung in ${topic}`;\n      description = `Einführung in das Thema ${topic}, Problemstellung, Relevanz für die Zielgruppe`;\n    } else if (i === 2) {\n      title = `Kapitel 2: Grundlagen von ${topic}`;\n      description = `Grundlegende Konzepte und Definitionen zu ${topic}, theoretischer Hintergrund`;\n    } else if (i === chapterCount) {\n      title = `Kapitel ${i}: Fazit zu ${topic}`;\n      description = `Zusammenfassung der wichtigsten Punkte zu ${topic}, Handlungsempfehlungen, Ausblick`;\n    } else {\n      title = `Kapitel ${i}: ${topic} - Praktische Anwendung`;\n      description = `Praktische Ansätze und Methoden zu ${topic}, Schritt-für-Schritt-Anleitungen`;\n    }\n  } else {\n    // Fallback nur wenn kein Topic vorhanden\n    if (i === 1) {\n      title = 'Kapitel 1: Einleitung';\n      description = 'Einführung in das Thema';\n    } else if (i === 2) {\n      title = 'Kapitel 2: Grundlagen';\n      description = 'Grundlegende Konzepte und Definitionen';\n    } else if (i === chapterCount) {\n      title = `Kapitel ${i}: Fazit`;\n      description = 'Zusammenfassung der wichtigsten Punkte';\n    } else {\n      title = `Kapitel ${i}: Praktische Anwendung`;\n      description = 'Praktische Ansätze und Methoden';\n    }\n  }\n  \n  chapters.push({\n    chapterNumber: i,\n    title: title,\n    targetWords: wordsPerChapter,\n    description: description\n  });\n}\n\nconsole.log('[Init Loop] ===== INITIALIZE MULTI-CHAPTER LOOP END =====');\nconsole.log('[Init Loop] ✅ Generated', chapters.length, 'chapters');\nconsole.log('[Init Loop] ✅ First Chapter Topic:', topic);\n\nreturn chapters.map(chapter => ({\n  json: {\n    ...chapter,\n    topic: topic, // WICHTIG: Verwendet Market-Topic (Trendanalyse)\n    genre: genre,\n    target_audience: targetAudience,\n    proposal_id: proposalId,\n    volume_number: volumeNumber,\n    previousChapters: [],\n    totalTargetWords: totalTargetWords,\n    minWordCount: totalTargetWords,\n    wordsPerChapter: wordsPerChapter,\n    coverImageType: coverImageType,\n    textType: textType\n  }\n}));"},"id":"init-multi-chapter-loop-v2","name":"Initialize Multi-Chapter Loop","type":"n8n-nodes-base.code","typeVersion":2,"position":[2096,288]},{"parameters":{"options":{}},"id":"split-chapters-sequential-v2","name":"Split Chapters (Sequential)","type":"n8n-nodes-base.splitInBatches","typeVersion":3,"position":[-2304,768],"onError":"continueErrorOutput"},{"parameters":{},"id":"delay-between-chapters-v2","name":"Delay Between Chapters","type":"n8n-nodes-base.wait","typeVersion":1.1,"position":[-2064,768],"webhookId":"45196287-7eff-449d-870e-051183a5a654"},{"parameters":{"workflowId":{"__rl":true,"value":"RgISyJGT9LvWYfSi","mode":"list","cachedResultUrl":"/workflow/RgISyJGT9LvWYfSi","cachedResultName":"Text Baustein V2"},"workflowInputs":{"mappingMode":"defineBelow","value":{},"matchingColumns":[],"schema":[],"attemptToConvertTypes":false,"convertFieldsToString":true},"options":{}},"id":"generate-chapter-text-baustein-v2","name":"Generate Chapter (Text Baustein V2)","type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[-1856,768]},{"parameters":{"jsCode":"// Collect Chapter & Update Previous\n// Collects generated chapters\n\nconst json = $input.json || {};\nconst binary = $input.binary || {};\n\n// Extract chapter data\nconst chapterData = {\n  chapterText: json.chapterText || json.text || json.content || '',\n  chapterTitle: json.chapterTitle || json.title || 'Kapitel',\n  chapterNumber: json.chapterNumber || json.number || 1,\n  wordCount: json.wordCount || json.words || 0\n};\n\n// Get existing chapters from previous iterations (if any)\nconst existingChapters = json.chapters || json.chapterArray || json.collectedChapters || [];\n\n// Add current chapter\nconst allChapters = [...existingChapters, chapterData];\n\n// Prepare output\nconst output = {\n  ...json,\n  chapters: allChapters,\n  chapterArray: allChapters,\n  collectedChapters: allChapters,\n  chapterCount: allChapters.length,\n  currentChapter: chapterData,\n  // Prepare checkpoint data for Supabase Node\n  checkpointData: {\n    chapters: allChapters,\n    chapterCount: allChapters.length,\n    lastChapter: chapterData\n  },\n  checkpointType: 'chapter'\n};\n\nreturn [{ json: output, binary: binary }];"},"id":"collect-chapter-v2","name":"Collect Chapter & Update Previous","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1648,768]},{"parameters":{"jsCode":"// Aktualisiere previousChapters für nächstes Kapitel\n// WICHTIG: done muss als Boolean zurückgegeben werden, nicht als String\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// ERWEITERT: Topic-Feld-Konsistenz (topic ↔ thema)\nconst chapterData = $input.first().json || {};\nconst currentChapters = chapterData.previousChapters || [];\n\nconsole.log('[Update Chapter State] ===== UPDATE CHAPTER STATE START =====');\nconsole.log('[Update Chapter State] Topic:', chapterData.topic || chapterData.thema);\nconsole.log('[Update Chapter State] Chapter Number:', chapterData.chapterNumber);\nconsole.log('[Update Chapter State] Previous Chapters count:', currentChapters.length);\n\n// Hole Split In Batches Context für done-Status\nconst splitContext = $('Split Chapters (Sequential)').context || {};\nconst done = splitContext.noItemsLeft === true;\n\n// WICHTIG: Topic normalisieren (topic ↔ thema)\nconst topic = chapterData.topic || chapterData.thema || '';\n\n// Füge aktuelles Kapitel zu previousChapters hinzu\nconst updatedPreviousChapters = [\n  ...currentChapters,\n  {\n    chapterNumber: chapterData.chapterNumber,\n    title: chapterData.title,\n    content: chapterData.content,\n    wordCount: chapterData.wordCount\n  }\n];\n\nconst result = {\n  ...chapterData,\n  previousChapters: updatedPreviousChapters,\n  done: done,  // WICHTIG: Boolean, nicht String\n  // WICHTIG: Beide Felder setzen für Konsistenz\n  topic: topic,\n  thema: topic\n};\n\nconsole.log('[Update Chapter State] ===== UPDATE CHAPTER STATE END =====');\nconsole.log('[Update Chapter State] ✅ Final Topic:', result.topic);\nconsole.log('[Update Chapter State] Updated Previous Chapters count:', result.previousChapters.length);\nconsole.log('[Update Chapter State] Done:', result.done);\n\nreturn [{\n  json: result\n}];"},"id":"update-chapter-state-v2","name":"Update Chapter State","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1328,1136]},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":1},"conditions":[{"id":"check-done","leftValue":"={{ $json.done.toBoolean() }}","rightValue":true,"operator":{"type":"boolean","operation":"equals"}}],"combinator":"and"},"options":{}},"id":"check-more-chapters-v2","name":"Check: More Chapters?","type":"n8n-nodes-base.if","typeVersion":2,"position":[-1008,960]},{"parameters":{"jsCode":"// Bereite nächstes Kapitel vor (für Loop-Rückführung)\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// ERWEITERT: Topic-Feld-Konsistenz (topic ↔ thema)\nconst chapterData = $input.first().json || {};\n\nconsole.log('[Prepare Next Chapter] ===== PREPARE NEXT CHAPTER START =====');\nconsole.log('[Prepare Next Chapter] Topic:', chapterData.topic || chapterData.thema);\nconsole.log('[Prepare Next Chapter] Chapter Number:', chapterData.chapterNumber);\n\n// WICHTIG: Topic normalisieren (topic ↔ thema)\nconst topic = chapterData.topic || chapterData.thema || '';\n\n// Die previousChapters wurden bereits aktualisiert\n// Jetzt müssen wir zurück zu Split Chapters (Sequential)\n// Der Split In Batches Node wird automatisch das nächste Kapitel ausgeben\n\nconst result = {\n  ...chapterData,\n  readyForNextChapter: true,\n  // WICHTIG: Beide Felder setzen für Konsistenz\n  topic: topic,\n  thema: topic\n};\n\nconsole.log('[Prepare Next Chapter] ===== PREPARE NEXT CHAPTER END =====');\nconsole.log('[Prepare Next Chapter] ✅ Final Topic:', result.topic);\n\nreturn [{ json: result }];"},"id":"prepare-next-chapter-v2","name":"Prepare Next Chapter","type":"n8n-nodes-base.code","typeVersion":2,"position":[-720,1088]},{"parameters":{"jsCode":"// Combine & Save Full E-Book\n// This node combines all chapters and prepares the full ebook data\n// Also prepares checkpoint data for Supabase Node\n// FIXED: Sicherstellt, dass immer ein Objekt zurückgegeben wird (nie primitiver Wert)\n\ntry {\n  // Get input data - handle all edge cases safely\n  let json = {};\n  let binary = {};\n  \n  // Safely extract input data\n  if ($input && typeof $input === 'object') {\n    if ($input.json && typeof $input.json === 'object') {\n      json = $input.json;\n    } else if (Array.isArray($input) && $input.length > 0) {\n      json = $input[0].json || {};\n      binary = $input[0].binary || {};\n    } else if (typeof $input.item === 'object' && $input.item.json) {\n      json = $input.item.json || {};\n      binary = $input.item.binary || {};\n    }\n  }\n  \n  // Ensure json is an object, never null or undefined\n  if (!json || typeof json !== 'object' || Array.isArray(json)) {\n    json = {};\n  }\n  \n  // Ensure binary is an object if present\n  if (binary && typeof binary !== 'object') {\n    binary = {};\n  }\n  \n  // Extract chapter data and other necessary fields\n  let chapters = json.chapters || json.chapterArray || json.collectedChapters || [];\n  if (!Array.isArray(chapters)) {\n    chapters = [];\n  }\n  \n  const fullText = json.fullText || json.combinedText || json.text || '';\n  \n  // Extract proposal/ebook metadata\n  const proposalId = json.proposalId || json.id || json.proposal_id || null;\n  const isbn = json.isbn || json.ISBN || null;\n  const title = json.title || json.topic || json.thema || 'E-Book';\n  const topic = json.topic || json.thema || title || 'E-Book';\n  const volumeNumber = json.volume_number || json.volumeNumber || json.volume || 1;\n  \n  // Calculate chapter count safely\n  let chapterCount = 0;\n  if (Array.isArray(chapters)) {\n    chapterCount = chapters.length;\n  } else if (json.chapterCount && typeof json.chapterCount === 'number') {\n    chapterCount = json.chapterCount;\n  }\n  \n  // Combine all chapters into full text if not already combined\n  let combinedText = fullText || '';\n  if (!combinedText && Array.isArray(chapters) && chapters.length > 0) {\n    combinedText = chapters\n      .map(function(ch, idx) {\n        if (!ch || typeof ch !== 'object') {\n          return '';\n        }\n        const chapterText = ch.chapterText || ch.text || ch.content || '';\n        const chapterTitle = ch.chapterTitle || ch.title || 'Kapitel ' + (idx + 1);\n        return '# ' + chapterTitle + '\\n\\n' + (chapterText || '');\n      })\n      .filter(function(text) { return text.length > 0; })\n      .join('\\n\\n---\\n\\n');\n  }\n  \n  // Prepare output data object - ALWAYS an object\n  const output = {};\n  \n  // Copy all original data safely\n  for (const key in json) {\n    if (json.hasOwnProperty(key)) {\n      try {\n        output[key] = json[key];\n      } catch (e) {\n        // Skip problematic keys\n        console.log('[Combine & Save] Skipped key:', key, e.message);\n      }\n    }\n  }\n  \n  // Set combined ebook data\n  output.fullText = combinedText || '';\n  output.combinedText = combinedText || '';\n  output.text = combinedText || '';\n  \n  // Set chapter information\n  output.chapters = chapters;\n  output.chapterArray = chapters;\n  output.collectedChapters = chapters;\n  output.chapterCount = chapterCount;\n  \n  // Set metadata\n  output.proposalId = proposalId;\n  output.isbn = isbn;\n  output.title = title || 'E-Book';\n  output.topic = topic || 'E-Book';\n  output.thema = topic || 'E-Book';\n  output.volume_number = volumeNumber;\n  output.volumeNumber = volumeNumber;\n  \n  // Set status flags\n  output.isCombined = true;\n  output.readyForQualityCheck = true;\n  \n  // Set timestamp\n  output.combinedAt = new Date().toISOString();\n  \n  // Prepare checkpoint data for Supabase Node\n  output.checkpointData = {\n    fullText: combinedText || '',\n    chapters: chapters,\n    chapterCount: chapterCount,\n    proposalId: proposalId,\n    isbn: isbn,\n    title: title || 'E-Book',\n    topic: topic || 'E-Book',\n    volumeNumber: volumeNumber\n  };\n  output.checkpointType = 'full_ebook';\n  \n  // Prepare return object - ALWAYS return an array with objects\n  const returnItem = { json: output };\n  \n  // Include binary data if present and valid\n  if (binary && typeof binary === 'object' && !Array.isArray(binary)) {\n    const binaryKeys = Object.keys(binary);\n    if (binaryKeys.length > 0) {\n      returnItem.binary = binary;\n    }\n  }\n  \n  // FIXED: Always return array with object, never primitive\n  return [returnItem];\n  \n} catch (error) {\n  // Error handling - return error information instead of crashing\n  // ALWAYS return an object in an array, never primitive\n  const errorOutput = {\n    error: true,\n    errorMessage: error.message || String(error) || 'Unknown error',\n    errorType: error.name || 'UnknownError',\n    isCombined: false,\n    readyForQualityCheck: false\n  };\n  \n  // Try to keep original data if available\n  try {\n    if ($input && typeof $input === 'object') {\n      let inputJson = {};\n      if ($input.json && typeof $input.json === 'object') {\n        inputJson = $input.json;\n      } else if (Array.isArray($input) && $input.length > 0 && $input[0].json) {\n        inputJson = $input[0].json || {};\n      } else if ($input.item && $input.item.json) {\n        inputJson = $input.item.json || {};\n      }\n      \n      // Copy safe properties\n      for (const key in inputJson) {\n        if (inputJson.hasOwnProperty(key)) {\n          try {\n            errorOutput[key] = inputJson[key];\n          } catch (e) {\n            // Skip problematic keys\n          }\n        }\n      }\n    }\n  } catch (e) {\n    // Ignore errors when trying to preserve input data\n    console.log('[Combine & Save] Error preserving input data:', e.message);\n  }\n  \n  // FIXED: Always return array with object, never primitive\n  return [{ json: errorOutput }];\n}"},"id":"combine-save-full-ebook-v2","name":"Combine & Save Full E-Book","type":"n8n-nodes-base.code","typeVersion":2,"position":[-848,768]},{"parameters":{"jsCode":"// Quality Check (Spelling, Plagiarism, SEO)\n// Verwendet dynamische Mindest-Wortanzahl aus Chat-Eingaben ODER Marktanalyse\nconst ebookData = $input.first().json || {};\nconst totalWordCount = ebookData.totalWordCount || 0;\nconst fullContent = ebookData.fullContent || '';\n\n// Hole Mindest-Wortanzahl und Mindest-Kapitelanzahl: Priorität Chat > Marktanalyse > Standard\nlet MIN_WORD_COUNT = 1500; // Fallback\nlet MIN_CHAPTERS = 3; // Fallback\n\n// Versuche Chat-Eingaben\nlet chatInputData = {};\ntry {\n  chatInputData = $('Extract Chat Input').item.json || {};\n  if (chatInputData.chapterCount && chatInputData.wordsPerChapter) {\n    MIN_WORD_COUNT = chatInputData.chapterCount * chatInputData.wordsPerChapter;\n    MIN_CHAPTERS = chatInputData.chapterCount;\n    console.log('[Quality Check] Using Chat Input parameters');\n  }\n} catch (e) {\n  // Versuche Marktanalyse\n  try {\n    const marketData = $('Merge Market Analysis Params').item.json || {};\n    if (marketData.chapterCount && marketData.wordsPerChapter) {\n      MIN_WORD_COUNT = marketData.chapterCount * marketData.wordsPerChapter;\n      MIN_CHAPTERS = marketData.chapterCount;\n      console.log('[Quality Check] Using Market Analysis parameters');\n    }\n  } catch (e2) {\n    // Fallback: Verwende minWordCount aus ebookData\n    MIN_WORD_COUNT = ebookData.min_word_count || ebookData.minWordCount || 1500;\n    MIN_CHAPTERS = (ebookData.chapters || []).length || 3;\n    console.log('[Quality Check] Using E-Book Data parameters');\n  }\n}\n\n// Basis-Quality-Checks\nconst checks = {\n  wordCount: {\n    passed: totalWordCount >= MIN_WORD_COUNT,\n    actual: totalWordCount,\n    required: MIN_WORD_COUNT,\n    message: totalWordCount >= MIN_WORD_COUNT \n      ? `Wortanzahl OK: ${totalWordCount} Wörter` \n      : `Wortanzahl zu niedrig: ${totalWordCount} < ${MIN_WORD_COUNT}`\n  },\n  contentLength: {\n    passed: fullContent.length > 0,\n    actual: fullContent.length,\n    required: 1,\n    message: fullContent.length > 0 ? 'Inhalt vorhanden' : 'Kein Inhalt'\n  },\n  chapters: {\n    passed: (ebookData.chapters || []).length >= MIN_CHAPTERS,\n    actual: (ebookData.chapters || []).length,\n    required: MIN_CHAPTERS,\n    message: (ebookData.chapters || []).length >= MIN_CHAPTERS \n      ? `Kapitel OK: ${(ebookData.chapters || []).length} Kapitel` \n      : `Zu wenige Kapitel: ${(ebookData.chapters || []).length} < ${MIN_CHAPTERS}`\n  }\n};\n\nconst allPassed = Object.values(checks).every(check => check.passed);\n\nreturn [{\n  json: {\n    ...ebookData,\n    quality_check: allPassed ? 'PASSED' : 'REJECTED',\n    quality_checks: checks,\n    overall: {\n      status: allPassed ? 'success' : 'error',\n      message: allPassed ? 'Alle Quality Checks bestanden' : 'Quality Checks fehlgeschlagen'\n    }\n  }\n}];"},"id":"quality-check-v2","name":"Quality Check","type":"n8n-nodes-base.code","typeVersion":2,"position":[-464,768]},{"parameters":{"workflowId":{"__rl":true,"value":"cK5mek0by9ihHGDI","mode":"list","cachedResultUrl":"/workflow/cK5mek0by9ihHGDI","cachedResultName":"Bild Baustein"},"workflowInputs":{"mappingMode":"defineBelow","value":{},"matchingColumns":[],"schema":[],"attemptToConvertTypes":false,"convertFieldsToString":true},"options":{}},"id":"generate-cover-bild-baustein-v2","name":"Generate Cover (Bild Baustein)","type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[-256,768]},{"parameters":{"jsCode":"// Konvertiere Cover-Bild von Bild Baustein zu Binary\n// FIXED: Generate Cover gibt Daten im dritten Output-Array zurück (output[2])\n// WICHTIG: Prüfe alle Input-Items und Output-Arrays\nconst allInputs = $input.all();\n\nconsole.log('[Convert Cover] ===== CONVERT COVER TO BINARY START =====');\nconsole.log('[Convert Cover] Input items count:', allInputs.length);\n\n// WICHTIG: Generate Cover gibt Daten in verschiedenen Output-Arrays zurück\n// Prüfe alle Input-Items systematisch\nlet bildBausteinOutput = null;\nlet inputData = {};\n\n// Durchsuche alle Input-Items\nfor (let i = 0; i < allInputs.length; i++) {\n  const item = allInputs[i];\n  const json = item.json || {};\n  const binary = item.binary || {};\n  \n  console.log(`[Convert Cover] Input item ${i}:`);\n  console.log(`  JSON keys:`, Object.keys(json));\n  console.log(`  Binary keys:`, Object.keys(binary));\n  console.log(`  Has bestImage:`, !!json.bestImage);\n  console.log(`  Has allImages:`, !!json.allImages);\n  console.log(`  Has imageUrl:`, !!json.imageUrl);\n  console.log(`  Status:`, json.status);\n  \n  // Prüfe ob dieses Item Bild-Daten enthält\n  if (json.bestImage && Object.keys(json.bestImage).length > 0) {\n    bildBausteinOutput = json;\n    console.log(`[Convert Cover] ✅ Bild-Daten in Input item ${i} gefunden (bestImage)`);\n    break;\n  }\n  \n  if (json.allImages && Array.isArray(json.allImages) && json.allImages.length > 0) {\n    bildBausteinOutput = json;\n    console.log(`[Convert Cover] ✅ Bild-Daten in Input item ${i} gefunden (allImages)`);\n    break;\n  }\n  \n  if (json.imageUrl || json.url) {\n    bildBausteinOutput = json;\n    console.log(`[Convert Cover] ✅ Bild-Daten in Input item ${i} gefunden (imageUrl)`);\n    break;\n  }\n  \n  // Prüfe Binary-Daten\n  if (binary.data && binary.data.data) {\n    bildBausteinOutput = { ...json, _hasBinary: true, binary: binary };\n    console.log(`[Convert Cover] ✅ Binary-Daten in Input item ${i} gefunden`);\n    break;\n  }\n  \n  // Fallback: Verwende erstes Item mit Daten\n  if (Object.keys(json).length > 0 && !inputData.topic) {\n    inputData = json;\n  }\n}\n\n// Wenn keine Bild-Daten in Input gefunden, versuche von Generate Cover Node zu holen\nif (!bildBausteinOutput || (!bildBausteinOutput.bestImage && !bildBausteinOutput.allImages && !bildBausteinOutput.imageUrl && !bildBausteinOutput._hasBinary)) {\n  console.log('[Convert Cover] ⚠️ Keine Bild-Daten in Input gefunden, versuche von Generate Cover Node');\n  \n  try {\n    // Generate Cover gibt Daten im dritten Output-Array zurück\n    // Versuche alle Output-Arrays zu prüfen\n    const generateCoverOutputs = $('Generate Cover (Bild Baustein)').all();\n    console.log('[Convert Cover] Generate Cover outputs count:', generateCoverOutputs.length);\n    \n    for (let i = 0; i < generateCoverOutputs.length; i++) {\n      const output = generateCoverOutputs[i];\n      const json = output.json || {};\n      \n      console.log(`[Convert Cover] Generate Cover output ${i} keys:`, Object.keys(json));\n      \n      if (json.bestImage || json.allImages || json.imageUrl || json.status === 'success') {\n        bildBausteinOutput = json;\n        console.log(`[Convert Cover] ✅ Daten von Generate Cover Node output ${i} geholt`);\n        break;\n      }\n    }\n  } catch (e) {\n    console.log('[Convert Cover] ⚠️ Generate Cover Node nicht gefunden:', e.message);\n  }\n}\n\n// Wenn immer noch keine Daten, verwende Input-Daten\nif (!bildBausteinOutput && Object.keys(inputData).length > 0) {\n  bildBausteinOutput = inputData;\n  console.log('[Convert Cover] ⚠️ Verwende Input-Daten als Fallback');\n}\n\n// Wenn immer noch keine Daten, erstelle leeres Objekt\nif (!bildBausteinOutput) {\n  bildBausteinOutput = {};\n  console.warn('[Convert Cover] ⚠️ KEINE INPUT-DATEN GEFUNDEN!');\n  console.warn('[Convert Cover] Alle Input-Items:', allInputs.map((item, i) => ({ \n    index: i, \n    jsonKeys: Object.keys(item.json || {}),\n    binaryKeys: Object.keys(item.binary || {})\n  })));\n}\n\n// Hole auch E-Book-Daten von Quality Check (falls vorhanden)\nlet ebookData = {};\ntry {\n  ebookData = $('Quality Check').first().json || {};\n  console.log('[Convert Cover] ✅ E-Book-Daten von Quality Check geholt');\n} catch (e) {\n  console.log('[Convert Cover] ⚠️ Quality Check Node nicht gefunden');\n  // Fallback: Verwende Input-Daten\n  ebookData = inputData;\n}\n\nconsole.log('[Convert Cover] Bild Baustein Output keys:', Object.keys(bildBausteinOutput));\nconsole.log('[Convert Cover] bestImage:', bildBausteinOutput.bestImage);\nconsole.log('[Convert Cover] allImages:', bildBausteinOutput.allImages);\nconsole.log('[Convert Cover] imageUrl:', bildBausteinOutput.imageUrl);\nconsole.log('[Convert Cover] status:', bildBausteinOutput.status);\nconsole.log('[Convert Cover] Has Binary:', bildBausteinOutput._hasBinary);\n\n// Prüfe zuerst Binary-Daten (höchste Priorität)\nif (bildBausteinOutput._hasBinary && bildBausteinOutput.binary && bildBausteinOutput.binary.data) {\n  const binaryData = bildBausteinOutput.binary.data;\n  const base64Data = binaryData.data || '';\n  const mimeType = binaryData.mimeType || 'image/jpeg';\n  \n  if (base64Data) {\n    console.log('[Convert Cover] ✅ Binary-Daten gefunden, verwende direkt');\n    \n    // Erstelle Dateiname\n    const topic = (ebookData.topic || ebookData.thema || 'ebook').replace(/[^a-zA-Z0-9]/g, '-');\n    const volumeNumber = ebookData.volume_number || 1;\n    const fileExtension = mimeType.includes('png') ? 'png' : 'jpg';\n    const fileName = `cover-${topic}-${volumeNumber}.${fileExtension}`;\n    \n    console.log('[Convert Cover] ===== CONVERT COVER TO BINARY END =====');\n    console.log('[Convert Cover] ✅ Binary-Daten direkt verwendet');\n    console.log('[Convert Cover] File Name:', fileName);\n    \n    return [{\n      json: {\n        ...ebookData,\n        ...bildBausteinOutput,\n        ...inputData,\n        coverImageUrl: `data:${mimeType};base64,${base64Data}`,\n        coverImageMimeType: mimeType,\n        coverImageSize: Buffer.from(base64Data, 'base64').length,\n        coverImageFileName: fileName\n      },\n      binary: {\n        data: {\n          data: base64Data,\n          mimeType: mimeType,\n          fileName: fileName\n        }\n      }\n    }];\n  }\n}\n\n// Extrahiere Bild-URL vom Bild Baustein\n// Prüfe verschiedene mögliche Felder\nlet imageUrl = bildBausteinOutput.bestImage?.imageUrl || \n               bildBausteinOutput.bestImage?.url ||\n               bildBausteinOutput.imageUrl || \n               bildBausteinOutput.url ||\n               '';\n\n// Prüfe auch in allImages Array\nif (!imageUrl && Array.isArray(bildBausteinOutput.allImages) && bildBausteinOutput.allImages.length > 0) {\n  const firstImage = bildBausteinOutput.allImages[0];\n  imageUrl = firstImage.imageUrl || firstImage.url || '';\n  console.log('[Convert Cover] ✅ Bild-URL aus allImages Array gefunden:', imageUrl);\n}\n\n// Wenn immer noch keine URL, prüfe ob es Base64-Daten gibt\nif (!imageUrl) {\n  const base64Data = bildBausteinOutput.bestImage?.base64 || \n                    bildBausteinOutput.base64 ||\n                    bildBausteinOutput.imageData ||\n                    '';\n  \n  if (base64Data) {\n    // Konvertiere Base64 zu Data URL\n    const mimeType = bildBausteinOutput.bestImage?.mimeType || 'image/jpeg';\n    imageUrl = `data:image/${mimeType.replace('image/', '')};base64,${base64Data}`;\n    console.log('[Convert Cover] ✅ Base64-Daten gefunden, konvertiert zu Data URL');\n  }\n}\n\n// Wenn immer noch keine Bild-Daten vorhanden, gib Warnung zurück aber stoppe nicht den Workflow\nif (!imageUrl && !bildBausteinOutput._hasBinary) {\n  console.warn('[Convert Cover] ⚠️ KEIN COVER-BILD GEFUNDEN!');\n  console.warn('[Convert Cover] Bild Baustein Output:', JSON.stringify(bildBausteinOutput, null, 2));\n  console.warn('[Convert Cover] Input Data:', JSON.stringify(inputData, null, 2));\n  \n  // Gib Daten weiter, aber ohne Binary-Daten\n  return [{\n    json: {\n      ...ebookData,\n      ...bildBausteinOutput,\n      ...inputData,\n      coverImageUrl: null,\n      coverImageMimeType: null,\n      coverImageSize: 0,\n      coverImageError: 'Kein Cover-Bild von Bild Baustein erhalten',\n      coverImageNeedsDownload: false\n    }\n  }];\n}\n\nconsole.log('[Convert Cover] ✅ Bild-URL gefunden:', imageUrl.substring(0, 100));\n\n// Wenn Base64 Data URL, extrahiere die Daten\nlet imageData = null;\nif (imageUrl.startsWith('data:image/')) {\n  const base64Match = imageUrl.match(/data:image\\/([^;]+);base64,(.+)/);\n  if (base64Match) {\n    const mimeType = base64Match[1];\n    const base64Data = base64Match[2];\n    imageData = Buffer.from(base64Data, 'base64');\n    \n    console.log('[Convert Cover] ✅ Base64-Daten extrahiert');\n    console.log('[Convert Cover] MIME Type:', mimeType);\n    console.log('[Convert Cover] Image Size:', imageData.length, 'bytes');\n    \n    // Erstelle Dateiname\n    const topic = (ebookData.topic || ebookData.thema || 'ebook').replace(/[^a-zA-Z0-9]/g, '-');\n    const volumeNumber = ebookData.volume_number || 1;\n    const fileExtension = mimeType === 'png' ? 'png' : 'jpg';\n    const fileName = `cover-${topic}-${volumeNumber}.${fileExtension}`;\n    \n    console.log('[Convert Cover] ===== CONVERT COVER TO BINARY END =====');\n    console.log('[Convert Cover] ✅ Binary-Daten erstellt');\n    console.log('[Convert Cover] File Name:', fileName);\n    \n    return [{\n      json: {\n        ...ebookData,\n        ...bildBausteinOutput,\n        ...inputData,\n        coverImageUrl: imageUrl,\n        coverImageMimeType: `image/${mimeType}`,\n        coverImageSize: imageData.length,\n        coverImageFileName: fileName\n      },\n      binary: {\n        data: {\n          data: base64Data,\n          mimeType: `image/${mimeType}`,\n          fileName: fileName\n        }\n      }\n    }];\n  }\n}\n\n// Falls HTTP URL, muss später heruntergeladen werden\nconsole.log('[Convert Cover] ⚠️ HTTP URL erkannt, muss später heruntergeladen werden');\nconsole.log('[Convert Cover] ===== CONVERT COVER TO BINARY END =====');\n\nreturn [{\n  json: {\n    ...ebookData,\n    ...bildBausteinOutput,\n    ...inputData,\n    coverImageUrl: imageUrl,\n    coverImageMimeType: 'image/jpeg',\n    coverImageNeedsDownload: true\n  }\n}];"},"id":"convert-cover-to-binary-v2","name":"Convert Cover to Binary","type":"n8n-nodes-base.code","typeVersion":2,"position":[-64,768]},{"parameters":{"method":"POST","url":"={{ $json.supabaseUrl || 'https://ugsezgnkyhcmsdpohuwf.supabase.co/storage/v1/object/ebooks/' + ($json.filename || 'cover.jpg') }}","sendHeaders":true,"specifyHeaders":"json","sendBody":true,"contentType":"binaryData","options":{"response":{"response":{"fullResponse":true}}}},"id":"upload-cover-to-supabase-v2","name":"Upload Cover to Supabase Storage","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1040,816],"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Erstelle professionelles PDF aus E-Book-Inhalt\n// Vereinfachte Version: Erstellt HTML, das später zu PDF konvertiert werden kann\nconst ebookData = $input.first().json || {};\nconst fullContent = ebookData.fullContent || '';\nconst topic = ebookData.topic || 'E-Book';\nconst volumeNumber = ebookData.volume_number || 1;\nconst coverImageUrl = ebookData.coverImageUrl || '';\n\n// Erstelle HTML-Struktur für PDF\nconst htmlContent = `<!DOCTYPE html>\n<html lang=\"de\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>${topic} - Band ${volumeNumber}</title>\n  <style>\n    @page {\n      size: A4;\n      margin: 2cm;\n    }\n    body {\n      font-family: 'Georgia', 'Times New Roman', serif;\n      line-height: 1.6;\n      color: #333;\n      max-width: 800px;\n      margin: 0 auto;\n      padding: 20px;\n    }\n    .cover {\n      text-align: center;\n      margin-bottom: 40px;\n      page-break-after: always;\n    }\n    .cover img {\n      max-width: 100%;\n      height: auto;\n      margin-bottom: 20px;\n    }\n    .cover h1 {\n      font-size: 2.5em;\n      margin: 20px 0;\n      color: #2c3e50;\n    }\n    .cover .subtitle {\n      font-size: 1.2em;\n      color: #7f8c8d;\n      margin-top: 10px;\n    }\n    h1, h2, h3 {\n      color: #2c3e50;\n      margin-top: 30px;\n      margin-bottom: 15px;\n    }\n    h1 {\n      font-size: 2em;\n      border-bottom: 2px solid #3498db;\n      padding-bottom: 10px;\n    }\n    h2 {\n      font-size: 1.5em;\n    }\n    h3 {\n      font-size: 1.2em;\n    }\n    p {\n      margin-bottom: 15px;\n      text-align: justify;\n    }\n    .chapter-separator {\n      page-break-before: always;\n      border-top: 3px solid #3498db;\n      margin-top: 40px;\n      padding-top: 20px;\n    }\n  </style>\n</head>\n<body>\n  <div class=\"cover\">\n    ${coverImageUrl ? `<img src=\"${coverImageUrl}\" alt=\"Cover\" />` : ''}\n    <h1>${topic}</h1>\n    ${volumeNumber > 1 ? `<div class=\"subtitle\">Band ${volumeNumber}</div>` : ''}\n  </div>\n  \n  ${fullContent.replace(/\\n\\n---\\n\\n/g, '</div><div class=\"chapter-separator\">').replace(/\\n/g, '<br>').replace(/^# (.+)$/gm, '<h1>$1</h1>').replace(/^## (.+)$/gm, '<h2>$1</h2>').replace(/^### (.+)$/gm, '<h3>$1</h3>')}\n  \n</body>\n</html>`;\n\nreturn [{\n  json: {\n    ...ebookData,\n    htmlContent: htmlContent,\n    pdfReady: true\n  }\n}];"},"id":"create-professional-pdf-v2","name":"Create Professional PDF","type":"n8n-nodes-base.code","typeVersion":2,"position":[1216,816]},{"parameters":{"jsCode":"// Erstelle HTML Binary für PDF-Konvertierung\nconst ebookData = $input.first().json || {};\nconst htmlContent = ebookData.htmlContent || '';\nconst topic = ebookData.topic || 'E-Book';\nconst volumeNumber = ebookData.volume_number || 1;\n\nif (!htmlContent) {\n  throw new Error('Kein HTML-Content vorhanden');\n}\n\n// Konvertiere HTML zu Base64\nconst htmlBuffer = Buffer.from(htmlContent, 'utf-8');\nconst htmlBase64 = htmlBuffer.toString('base64');\n\nreturn [{\n  json: {\n    ...ebookData,\n    htmlFileName: `${topic}-Band-${volumeNumber}.html`,\n    htmlSize: htmlBuffer.length\n  },\n  binary: {\n    html: {\n      data: htmlBase64,\n      mimeType: 'text/html',\n      fileName: `${topic}-Band-${volumeNumber}.html`\n    }\n  }\n}];"},"id":"create-html-binary-v2","name":"Create HTML Binary","type":"n8n-nodes-base.code","typeVersion":2,"position":[352,1072]},{"parameters":{"url":"={{ 'https://ugsezgnkyhcmsdpohuwf.supabase.co/storage/v1/object/ebook-covers/' + ($json.pdfFileName || ($json.isbnClean || $json.isbn || 'ebook').replace(/[^a-zA-Z0-9]/g, '') + '.pdf') }}","options":{}},"id":"upload-pdf-to-supabase-v2","name":"Upload PDF to Supabase Storage","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1184,1280],"onError":"continueRegularOutput"},{"parameters":{"tableId":"ebooks","dataToSend":"autoMapInputData"},"id":"save-full-ebook-to-db-v2","name":"Save Full E-Book to DB","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[1392,1280],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.chat_id }}","text":"={{ $json.text || $json.message }}","additionalFields":{}},"id":"final-notification-v2","name":"Final Notification (Telegram)","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[1792,1280],"webhookId":"4e55ad09-6500-4885-8bd6-c92fa48337fc","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Konvertiere boolean 'done' zu String für IF Node\nconst chapterData = $input.first().json || {};\nconst done = chapterData.done || false;\n\nreturn [{\n  json: {\n    ...chapterData,\n    done: done,\n    doneString: done ? 'true' : 'false'\n  }\n}];"},"id":"convert-done-to-string","name":"Convert Done to String","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1168,768],"disabled":true},{"parameters":{},"type":"n8n-nodes-base.manualTrigger","typeVersion":1,"position":[-3568,64],"id":"e84070ce-03fa-4b5e-889c-7ba27d8330db","name":"When clicking ‘Execute workflow’"},{"parameters":{"operation":"getAll","tableId":"ebook_proposals","matchType":"allFilters","filters":{"conditions":[{"keyName":"topic","condition":"eq","keyValue":"={{ $('Check Existing E-Books (Duplikatsprüfung)').item.json.topic || '' }}"},{"keyName":"approval_status","condition":"eq","keyValue":"approved"}]}},"id":"query-existing-ebooks-code","name":"Query Existing E-Books (Supabase)","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-1232,48],"alwaysOutputData":true,"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Filtere leere Proposals heraus\n// ERWEITERT: Prüft auch genre und target_audience als Fallback\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\nconst inputData = $input.first().json || {};\n\nconsole.log('[Filter Proposals] Input Data keys:', Object.keys(inputData));\nconsole.log('[Filter Proposals] Input topic:', inputData.topic);\nconsole.log('[Filter Proposals] Input genre:', inputData.genre);\nconsole.log('[Filter Proposals] Input target_audience:', inputData.target_audience);\n\n// ERWEITERT: Prüfe ob Proposal leer ist - auch genre/target_audience als Fallback\nconst hasTopic = inputData.topic && inputData.topic.trim() !== '' && inputData.topic !== 'Kein Thema gefunden' && inputData.topic !== 'N/A';\nconst hasGenre = inputData.genre && inputData.genre.trim() !== '';\nconst hasTargetAudience = inputData.target_audience && inputData.target_audience.trim() !== '';\n\n// Proposal ist leer wenn weder topic noch genre/target_audience vorhanden\nconst isEmpty = !hasTopic && !hasGenre && !hasTargetAudience;\n\nif (isEmpty) {\n  console.log('[Filter Proposals] Proposal ist leer, wird herausgefiltert');\n  return []; // Leeres Array = Proposal wird herausgefiltert\n}\n\nconsole.log('[Filter Proposals] Proposal ist gültig, wird weitergegeben');\nconsole.log('[Filter Proposals] Has Topic:', hasTopic);\nconsole.log('[Filter Proposals] Has Genre:', hasGenre);\nconsole.log('[Filter Proposals] Has Target Audience:', hasTargetAudience);\n\n// ERWEITERT: Leite ALLE Input-Daten weiter (auch chapterCount, wordsPerChapter, etc.)\nreturn [{\n  json: {\n    ...inputData // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n  }\n}];"},"id":"filter-empty-proposals","name":"Filter Empty Proposals","type":"n8n-nodes-base.code","typeVersion":2,"position":[144,288]},{"parameters":{"jsCode":"// Vereinfachte Normalisierung - Ensure Query Item macht jetzt die Arbeit\n// WICHTIG: Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\nconst inputData = $input.first().json || {};\n\nconsole.log('[Normalize] Input Data keys:', Object.keys(inputData));\nconsole.log('[Normalize] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Normalize] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Trends-Daten zu holen\nlet trendsData = inputData;\n\n// Falls Input keine Trends-Daten enthält, versuche von Check Existing E-Books zu holen (Fallback)\nif (!trendsData.topic && !trendsData.trends) {\n  try {\n    trendsData = $('Check Existing E-Books (Duplikatsprüfung)').item.json || inputData;\n  } catch (e) {\n    console.log('[Normalize] Check Existing E-Books not found, using input data');\n    trendsData = inputData;\n  }\n}\n\n// Versuche Query-Item zu holen\nlet queryItem = {};\ntry {\n  queryItem = $('Ensure Query Item').item.json || {};\n} catch (e) {\n  console.log('[Normalize] Ensure Query Item not found');\n  queryItem = {};\n}\n\nconsole.log('[Normalize] Query isEmpty:', queryItem.isEmpty);\nconsole.log('[Normalize] Query maxVolume:', queryItem.maxVolume);\n\n// Ensure Query Item gibt jetzt immer vollständige Daten zurück\nconst maxVolume = queryItem.maxVolume || 0;\nconst isEmpty = queryItem.isEmpty !== false;\n\n// ERWEITERT: Kombiniere Input-Daten mit Query-Daten und leite ALLE Daten weiter\nreturn [{\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n    ...trendsData, // Behalte Trends-Daten\n    queryResult: isEmpty ? [] : [queryItem],\n    maxVolume: maxVolume,\n    hasTopic: trendsData.hasTopic || trendsData.topic ? true : false,\n    querySuccess: true,\n    isEmpty: isEmpty\n  }\n}];"},"id":"normalize-query-result","name":"Normalize Query Result","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1232,304]},{"parameters":{"jsCode":"// GARANTIERT ein Item zurückgeben - FIXED VERSION\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\nconst items = $input.all();\n\n// Hole Input-Daten (von Query Existing E-Books)\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Query] Input Data keys:', Object.keys(inputData));\nconsole.log('[Ensure Query] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Ensure Query] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Trends-Daten zu holen\nlet trendsData = {};\ntry {\n  trendsData = $('Check Existing E-Books (Duplikatsprüfung)').item.json || {};\n} catch (e) {\n  console.log('[Ensure Query] Check Existing E-Books not found');\n  trendsData = inputData;\n}\n\n// Fallback-Werte\nconst defaultResult = {\n  topic: trendsData.topic || inputData.topic || '',\n  volume_number: null,\n  isEmpty: true,\n  maxVolume: 0\n};\n\n// Wenn keine Items vorhanden\nif (!items || items.length === 0) {\n  console.log('[Ensure Query] No items, returning default');\n  return [{ \n    json: {\n      ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n      ...trendsData, // Behalte Trends-Daten\n      ...defaultResult\n    }\n  }];\n}\n\n// Parse Query-Response\nconst firstItem = items[0];\nlet queryData = firstItem.json;\n\nconsole.log('[Ensure Query] Raw data type:', typeof queryData);\n\n// Wenn Response ein String ist (body), parse ihn\nif (typeof queryData === 'string') {\n  try {\n    queryData = JSON.parse(queryData);\n  } catch (e) {\n    console.error('[Ensure Query] JSON Parse Error:', e);\n    return [{ \n      json: {\n        ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n        ...trendsData, // Behalte Trends-Daten\n        ...defaultResult\n      }\n    }];\n  }\n} else if (queryData.body) {\n  try {\n    queryData = JSON.parse(queryData.body);\n  } catch (e) {\n    console.error('[Ensure Query] Body Parse Error:', e);\n    return [{ \n      json: {\n        ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n        ...trendsData, // Behalte Trends-Daten\n        ...defaultResult\n      }\n    }];\n  }\n}\n\n// Wenn Array zurückkommt (Supabase Standard)\nif (Array.isArray(queryData)) {\n  console.log('[Ensure Query] Array with', queryData.length, 'items');\n  \n  if (queryData.length === 0) {\n    // Leeres Array = kein Duplikat gefunden\n    return [{\n      json: {\n        ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n        ...trendsData, // Behalte Trends-Daten\n        ...defaultResult,\n        isEmpty: true,\n        maxVolume: 0\n      }\n    }];\n  }\n  \n  // Erstes Element zurückgeben\n  const firstResult = queryData[0];\n  return [{\n    json: {\n      ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n      ...trendsData, // Behalte Trends-Daten\n      ...firstResult,\n      isEmpty: false,\n      maxVolume: firstResult.volume_number || 0\n    }\n  }];\n}\n\n// Wenn Objekt, direkt zurückgeben\nconsole.log('[Ensure Query] Object returned');\nreturn [{\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n    ...trendsData, // Behalte Trends-Daten\n    ...queryData,\n    isEmpty: !queryData.volume_number,\n    maxVolume: queryData.volume_number || 0\n  }\n}];"},"id":"ensure-query-item","name":"Ensure Query Item","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1040,48]},{"parameters":{"jsCode":"// Formatiere Secrets vom nativen Supabase Node für nachfolgende Nodes\n// Der Supabase Node gibt direkt ein Array von {key_name, key_value} zurück\nconst items = $input.all();\n\n// Konvertiere Array zu Objekt für einfachen Zugriff\nconst secrets = {};\nitems.forEach(item => {\n  const json = item.json || {};\n  if (json.key_name && json.key_value) {\n    secrets[json.key_name] = json.key_value;\n  }\n});\n\n// Fallback-Werte falls Secrets fehlen\nconst fallbackSecrets = {\n  DEEPSEEK_API_KEY: 'sk-fd178bb87e1240b19786ce816c77d07f',\n  SUPABASE_ANON_KEY: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVnc2V6Z25reWhjbXNkcG9odXdmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTcxMDI2NDAsImV4cCI6MjA3MjY3ODY0MH0.H7s5PSdTDOiHyeic61lcIGFjVITW-ikz8y6c5_bn6Ao',\n  SUPABASE_SERVICE_KEY: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVnc2V6Z25reWhjbXNkcG9odXdmIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NzEwMjY0MCwiZXhwIjoyMDcyNjc4NjQwfQ.PEG6Z3WVpfHgxZIpuLL4aSenbWVVTmYypCvO8knahPM',\n  TELEGRAM_BOT_TOKEN: '',\n  TELEGRAM_CHAT_ID: ''\n};\n\n// Verwende Secrets aus Supabase, falls vorhanden, sonst Fallback\nconst finalSecrets = {\n  DEEPSEEK_API_KEY: secrets.DEEPSEEK_API_KEY || fallbackSecrets.DEEPSEEK_API_KEY,\n  SUPABASE_ANON_KEY: secrets.SUPABASE_ANON_KEY || fallbackSecrets.SUPABASE_ANON_KEY,\n  SUPABASE_SERVICE_KEY: secrets.SUPABASE_SERVICE_KEY || fallbackSecrets.SUPABASE_SERVICE_KEY,\n  TELEGRAM_BOT_TOKEN: secrets.TELEGRAM_BOT_TOKEN || fallbackSecrets.TELEGRAM_BOT_TOKEN,\n  TELEGRAM_CHAT_ID: secrets.TELEGRAM_CHAT_ID || fallbackSecrets.TELEGRAM_CHAT_ID\n};\n\nconsole.log('[Load Secrets] Loaded', Object.keys(secrets).length, 'secrets from Supabase');\nconsole.log('[Load Secrets] Using fallback for', Object.keys(finalSecrets).filter(k => !secrets[k]).length, 'missing keys');\n\n// Gib Secrets als JSON zurück, damit nachfolgende Nodes darauf zugreifen können\nreturn [{\n  json: {\n    secrets: finalSecrets,\n    DEEPSEEK_API_KEY: finalSecrets.DEEPSEEK_API_KEY,\n    SUPABASE_ANON_KEY: finalSecrets.SUPABASE_ANON_KEY,\n    SUPABASE_SERVICE_KEY: finalSecrets.SUPABASE_SERVICE_KEY,\n    TELEGRAM_BOT_TOKEN: finalSecrets.TELEGRAM_BOT_TOKEN,\n    TELEGRAM_CHAT_ID: finalSecrets.TELEGRAM_CHAT_ID\n  }\n}];"},"id":"load-secrets-from-supabase","name":"Load Secrets from Supabase","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2912,48]},{"parameters":{"operation":"getAll","tableId":"app_secrets","returnAll":true,"filterType":"none"},"id":"fetch-secrets-supabase","name":"Fetch Secrets from Supabase","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-3152,48],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"jsCode":"// Füge Volume Number zu Proposal hinzu\n// WICHTIG: Verwendet Input-Daten von Filter Empty Proposals\n// ERWEITERT: Holt topic von Process DeepSeek Parse, falls nicht in Input-Daten\n// ERWEITERT: Generiert topic aus genre/target_audience, falls nicht vorhanden\n// ERWEITERT: Setzt language auf 'de' als Standard, falls nicht vorhanden\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\nconsole.log('[Add Volume] ===== ADD VOLUME NUMBER START =====');\nconsole.log('[Add Volume] Input Data keys:', Object.keys(inputData));\nconsole.log('[Add Volume] Input topic:', inputData.topic);\nconsole.log('[Add Volume] Input genre:', inputData.genre);\nconsole.log('[Add Volume] Input target_audience:', inputData.target_audience);\nconsole.log('[Add Volume] Input language:', inputData.language);\n\n// WICHTIG: Hole Chat-Topic von Process DeepSeek Parse (hat IMMER Priorität)\nlet chatTopic = '';\ntry {\n  const deepSeekParseData = $('Process DeepSeek Parse').item.json || {};\n  chatTopic = deepSeekParseData.topic || '';\n  console.log('[Add Volume] ✅ Process DeepSeek Parse gefunden');\n  console.log('[Add Volume] Chat-Topic von Process DeepSeek Parse:', chatTopic);\n  console.log('[Add Volume] Chat-Topic Source:', deepSeekParseData._source || 'unknown');\n} catch (e) {\n  console.log('[Add Volume] ⚠️ Process DeepSeek Parse not found:', e.message);\n}\n\n// Versuche Volume-Daten zu holen\nlet volumeData = {};\ntry {\n  volumeData = $('Calculate Volume Number').item.json || {};\n  console.log('[Add Volume] Calculate Volume Number gefunden');\n} catch (e) {\n  console.log('[Add Volume] Calculate Volume Number not found, using input data');\n  volumeData = inputData;\n}\n\nconst volumeNumber = volumeData.volumeNumber || inputData.volumeNumber || 1;\n\n// ERWEITERT: Generiere topic, falls nicht vorhanden\nlet finalTopic = chatTopic || inputData.topic || null;\n\n// Wenn kein topic vorhanden, generiere es aus genre und target_audience\nif (!finalTopic || finalTopic.trim() === '' || finalTopic === 'N/A') {\n  const genre = inputData.genre || 'Allgemein';\n  const targetAudience = inputData.target_audience || 'Leser';\n  \n  // Generiere ein sinnvolles topic basierend auf genre und target_audience\n  finalTopic = `${genre} für ${targetAudience}`;\n  \n  console.log('[Add Volume] ⚠️ Topic fehlt, generiert aus genre/target_audience:', finalTopic);\n} else {\n  console.log('[Add Volume] ✅ Topic vorhanden:', finalTopic);\n}\n\n// ERWEITERT: Setze language auf 'de' als Standard, falls nicht vorhanden\nlet finalLanguage = inputData.language || inputData.sprache || 'de';\n\nif (!finalLanguage || finalLanguage.trim() === '' || finalLanguage === 'N/A') {\n  finalLanguage = 'de'; // Standard: Deutsch\n  console.log('[Add Volume] ⚠️ Language fehlt, setze auf Standard:', finalLanguage);\n} else {\n  console.log('[Add Volume] ✅ Language vorhanden:', finalLanguage);\n}\n\nconsole.log('[Add Volume] Topic-Priorität:');\nconsole.log('  Chat-Topic (Process DeepSeek Parse):', chatTopic || '(nicht vorhanden)');\nconsole.log('  Input-Topic:', inputData.topic || '(nicht vorhanden)');\nconsole.log('  ✅ Final Topic (Chat > Input > Generated):', finalTopic);\nconsole.log('[Add Volume] Volume Number:', volumeNumber);\nconsole.log('[Add Volume] Language:', finalLanguage);\n\n// ERWEITERT: Kombiniere Input-Daten mit Volume-Daten\n// Priorität für topic: Chat-Topic (Process DeepSeek Parse) > Input-Daten > Generiert\nconst result = {\n  ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n  volume_number: volumeNumber,\n  // WICHTIG: Topic hat höchste Priorität von Process DeepSeek Parse, dann Input, dann generiert\n  topic: finalTopic,\n  language: finalLanguage,\n  sprache: finalLanguage, // Auch als 'sprache' für Kompatibilität\n  _topicSource: chatTopic ? 'chat' : (inputData.topic ? 'input' : 'generated')\n};\n\nconsole.log('[Add Volume] ===== ADD VOLUME NUMBER END =====');\nconsole.log('[Add Volume] ✅ Final Topic:', result.topic);\nconsole.log('[Add Volume] ✅ Volume Number:', result.volume_number);\nconsole.log('[Add Volume] ✅ Language:', result.language);\n\nreturn { json: result }; // FIXED: Einzelnes Objekt zurückgeben statt Array"},"id":"add-volume-number-to-proposal","name":"Add Volume Number to Proposal","type":"n8n-nodes-base.code","typeVersion":2,"position":[336,288]},{"parameters":{"jsCode":"// Extrahiere ebook_suggestions aus dem Market Analysis Objekt\n// ROBUST: Verwendet Daten aus 'Set Volume Number & Title' falls 'Save Market Analysis' keine Daten zurückgibt\n// FALLBACK: Verwendet trends direkt, falls ebook_suggestions leer ist\n// ERWEITERT: Verwendet Chat-Topic falls vorhanden\n// ERWEITERT: Leitet ALLE Daten weiter (chapterCount, wordsPerChapter, etc.), auch wenn sie nicht in ebook_proposals gespeichert werden\n// WICHTIG: Nur Felder senden, die tatsächlich in ebook_proposals existieren\n// Existierende Spalten: topic, genre, language, target_audience, length, volume_number\n// NICHT existierende Spalten (werden entfernt): popularity_score, total_score, recommendation, priority, reasoning, analysis_date, data_sources\n// Konvertiere Array von Suggestions zu einzelnen Items für Split In Batches\nconst saveMarketAnalysisOutput = $input.first().json || {};\n\nconsole.log('[Extract Suggestions] Input Data keys:', Object.keys(saveMarketAnalysisOutput));\nconsole.log('[Extract Suggestions] Input chapterCount:', saveMarketAnalysisOutput.chapterCount);\nconsole.log('[Extract Suggestions] Input wordsPerChapter:', saveMarketAnalysisOutput.wordsPerChapter);\n\n// ERWEITERT: Hole Chat-Daten (chapterCount, wordsPerChapter, topic, etc.)\nlet chatInputData = {};\nlet chatTopic = '';\n\ntry {\n  // Versuche zuerst Process DeepSeek Parse (intelligent geparst)\n  chatInputData = $('Process DeepSeek Parse').item.json || {};\n  chatTopic = chatInputData.topic || '';\n  console.log('[Extract Suggestions] Process DeepSeek Parse gefunden');\n  console.log('[Extract Suggestions] Process DeepSeek Parse chapterCount:', chatInputData.chapterCount);\n  console.log('[Extract Suggestions] Process DeepSeek Parse wordsPerChapter:', chatInputData.wordsPerChapter);\n} catch (e) {\n  try {\n    // Fallback: Extract Chat Input\n    chatInputData = $('Extract Chat Input').item.json || {};\n    chatTopic = chatInputData.topic || '';\n    console.log('[Extract Suggestions] Extract Chat Input gefunden');\n  } catch (e2) {\n    console.log('[Extract Suggestions] Extract Chat Input not found');\n  }\n}\n\n// Prüfe ob Save Market Analysis Daten zurückgegeben hat\n// Falls nicht, hole Daten vom vorherigen Node 'Set Volume Number & Title'\nlet marketAnalysis = saveMarketAnalysisOutput;\n\n// Wenn Save Market Analysis keine ebook_suggestions hat, hole vom vorherigen Node\nif (!marketAnalysis.ebook_suggestions || (Array.isArray(marketAnalysis.ebook_suggestions) && marketAnalysis.ebook_suggestions.length === 0)) {\n  console.log('[Extract Suggestions] No suggestions in Save Market Analysis output, trying previous node');\n  try {\n    const previousNodeData = $('Set Volume Number & Title').item.json || {};\n    if (previousNodeData.ebook_suggestions && Array.isArray(previousNodeData.ebook_suggestions) && previousNodeData.ebook_suggestions.length > 0) {\n      console.log('[Extract Suggestions] Found suggestions in previous node');\n      marketAnalysis = previousNodeData;\n    }\n  } catch (e) {\n    console.error('[Extract Suggestions] Error accessing previous node:', e);\n  }\n}\n\nconsole.log('[Extract Suggestions] Market Analysis keys:', Object.keys(marketAnalysis));\nconsole.log('[Extract Suggestions] ebook_suggestions type:', typeof marketAnalysis.ebook_suggestions);\nconsole.log('[Extract Suggestions] ebook_suggestions length:', Array.isArray(marketAnalysis.ebook_suggestions) ? marketAnalysis.ebook_suggestions.length : 'N/A');\n\n// Prüfe verschiedene mögliche Datenstrukturen\nlet ebookSuggestions = [];\n\n// Fall 1: ebook_suggestions ist direkt ein Array\nif (Array.isArray(marketAnalysis.ebook_suggestions)) {\n  ebookSuggestions = marketAnalysis.ebook_suggestions;\n}\n// Fall 2: ebook_suggestions ist ein String (JSON)\nelse if (typeof marketAnalysis.ebook_suggestions === 'string') {\n  try {\n    ebookSuggestions = JSON.parse(marketAnalysis.ebook_suggestions);\n  } catch (e) {\n    console.error('[Extract Suggestions] JSON Parse Error:', e);\n  }\n}\n\nconsole.log('[Extract Suggestions] Found', ebookSuggestions.length, 'suggestions from ebook_suggestions');\n\n// FALLBACK: Wenn ebook_suggestions leer ist, verwende trends direkt\nif (!Array.isArray(ebookSuggestions) || ebookSuggestions.length === 0) {\n  console.log('[Extract Suggestions] ebook_suggestions empty, using trends as fallback');\n  const trends = marketAnalysis.trends || [];\n  \n  if (Array.isArray(trends) && trends.length > 0) {\n    // Konvertiere trends zu Suggestions-Format (NUR existierende Felder)\n    ebookSuggestions = trends.map(trend => ({\n      topic: trend.topic || 'Unbekanntes Thema',\n      genre: trend.genre || 'non-fiction',\n      language: 'de',\n      target_audience: trend.target_audience || 'Berufstaetige und Unternehmer',\n      length: 'medium'\n      // Entfernt: popularity_score, total_score, recommendation, priority, reasoning\n    }));\n    \n    console.log('[Extract Suggestions] Created', ebookSuggestions.length, 'suggestions from trends');\n  }\n}\n\n// NEU: Wenn Chat-Topic vorhanden ist, erstelle ein Suggestion mit Chat-Topic\nif (chatTopic && chatTopic.trim().length > 0) {\n  console.log('[Extract Suggestions] Chat Topic vorhanden, erstelle Suggestion mit Chat-Topic:', chatTopic);\n  \n  // Prüfe ob Chat-Topic bereits in Suggestions vorhanden ist\n  const topicExists = ebookSuggestions.some(s => s.topic && s.topic.toLowerCase().includes(chatTopic.toLowerCase()));\n  \n  if (!topicExists) {\n    // Erstelle neues Suggestion mit Chat-Topic (an erster Stelle für Priorität)\n    ebookSuggestions.unshift({\n      topic: chatTopic,\n      genre: 'non-fiction',\n      language: 'de',\n      target_audience: 'Berufstaetige und Unternehmer',\n      length: 'medium',\n      _fromChatInput: true // Flag für Debugging\n    });\n    console.log('[Extract Suggestions] Chat-Topic Suggestion hinzugefügt');\n  } else {\n    // Aktualisiere erstes Suggestion mit Chat-Topic\n    const firstSuggestion = ebookSuggestions[0];\n    if (firstSuggestion) {\n      firstSuggestion.topic = chatTopic;\n      firstSuggestion._fromChatInput = true;\n      console.log('[Extract Suggestions] Erstes Suggestion mit Chat-Topic aktualisiert');\n    }\n  }\n}\n\n// ERWEITERT: Kombiniere Chat-Daten mit Market Analysis Daten\n// Diese Daten werden durch die gesamte Kette weitergegeben, auch wenn sie nicht in ebook_proposals gespeichert werden\nconst chatDataToPass = {\n  chapterCount: chatInputData.chapterCount !== undefined ? chatInputData.chapterCount : (saveMarketAnalysisOutput.chapterCount !== undefined ? saveMarketAnalysisOutput.chapterCount : null),\n  wordsPerChapter: chatInputData.wordsPerChapter !== undefined ? chatInputData.wordsPerChapter : (saveMarketAnalysisOutput.wordsPerChapter !== undefined ? saveMarketAnalysisOutput.wordsPerChapter : null),\n  topic: chatTopic || saveMarketAnalysisOutput.topic || null,\n  textType: chatInputData.textType || saveMarketAnalysisOutput.textType || null,\n  coverImageType: chatInputData.coverImageType || saveMarketAnalysisOutput.coverImageType || null,\n  imageType: chatInputData.imageType || saveMarketAnalysisOutput.imageType || null,\n  style: chatInputData.style || saveMarketAnalysisOutput.style || null,\n  aspectRatio: chatInputData.aspectRatio || saveMarketAnalysisOutput.aspectRatio || null,\n  hasText: chatInputData.hasText !== undefined ? chatInputData.hasText : (saveMarketAnalysisOutput.hasText !== undefined ? saveMarketAnalysisOutput.hasText : null),\n  imagesInBook: chatInputData.imagesInBook !== undefined ? chatInputData.imagesInBook : (saveMarketAnalysisOutput.imagesInBook !== undefined ? saveMarketAnalysisOutput.imagesInBook : null),\n  imageCount: chatInputData.imageCount !== undefined ? chatInputData.imageCount : (saveMarketAnalysisOutput.imageCount !== undefined ? saveMarketAnalysisOutput.imageCount : null)\n};\n\nconsole.log('[Extract Suggestions] Chat Data to Pass:', chatDataToPass);\n\n// Wenn immer noch keine Suggestions vorhanden sind, gib ein leeres Item zurück (Workflow stoppt nicht)\nif (!Array.isArray(ebookSuggestions) || ebookSuggestions.length === 0) {\n  console.warn('[Extract Suggestions] No suggestions found after fallback, returning empty item');\n  return [{\n    json: {\n      topic: chatTopic || 'Kein Thema gefunden', // WICHTIG: Verwendet Chat-Topic falls vorhanden\n      genre: 'non-fiction',\n      target_audience: 'Berufstaetige und Unternehmer',\n      // ERWEITERT: Füge Chat-Daten hinzu\n      ...chatDataToPass,\n      _warning: 'Keine Suggestions gefunden',\n      _debug: {\n        hasEbookSuggestions: !!marketAnalysis.ebook_suggestions,\n        ebookSuggestionsType: typeof marketAnalysis.ebook_suggestions,\n        hasTrends: !!(marketAnalysis.trends && Array.isArray(marketAnalysis.trends) && marketAnalysis.trends.length > 0),\n        trendsLength: Array.isArray(marketAnalysis.trends) ? marketAnalysis.trends.length : 0,\n        marketAnalysisKeys: Object.keys(marketAnalysis),\n        chatTopic: chatTopic || '(nicht vorhanden)'\n      }\n    }\n  }];\n}\n\n// Konvertiere jedes Suggestion zu einem Item\n// WICHTIG: Nur Felder senden, die in ebook_proposals existieren\n// ERWEITERT: Füge Chat-Daten hinzu, die durch die Kette weitergegeben werden\nconst items = ebookSuggestions.map(suggestion => {\n  // Erstelle sauberes Suggestion-Objekt mit NUR existierenden Feldern für ebook_proposals\n  const cleanSuggestion = {\n    topic: suggestion.topic || '',\n    genre: suggestion.genre || 'non-fiction',\n    language: suggestion.language || 'de',\n    target_audience: suggestion.target_audience || 'Berufstaetige und Unternehmer',\n    length: suggestion.length || 'medium'\n    // Entfernt: popularity_score, total_score, recommendation, priority, reasoning\n    // Diese Felder existieren nicht in ebook_proposals\n  };\n  \n  // ERWEITERT: Füge Chat-Daten hinzu (werden nicht in ebook_proposals gespeichert, aber durch Kette weitergegeben)\n  return { \n    json: {\n      ...cleanSuggestion,\n      ...chatDataToPass // WICHTIG: Diese Daten werden durch die gesamte Kette weitergegeben\n    }\n  };\n});\n\nconsole.log('[Extract Suggestions] Returning', items.length, 'items (nur existierende Felder für ebook_proposals + Chat-Daten)');\nif (chatTopic) {\n  console.log('[Extract Suggestions] Chat-Topic wird verwendet:', chatTopic);\n}\nif (chatDataToPass.chapterCount || chatDataToPass.wordsPerChapter) {\n  console.log('[Extract Suggestions] Chat-Daten werden weitergegeben:', { chapterCount: chatDataToPass.chapterCount, wordsPerChapter: chatDataToPass.wordsPerChapter });\n}\nreturn items;"},"id":"extract-ebook-suggestions","name":"Extract E-Book Suggestions","type":"n8n-nodes-base.code","typeVersion":2,"position":[-240,48]},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":1},"conditions":[{"id":"check-done","leftValue":"={{ $('Split into Proposals').context?.noItemsLeft === true }}","rightValue":"true","operator":{"type":"boolean","operation":"equals"}}],"combinator":"and"},"options":{"looseTypeValidation":true}},"id":"check-proposals-done","name":"Check: All Proposals Done?","type":"n8n-nodes-base.if","typeVersion":2,"position":[1296,32],"onError":"continueErrorOutput"},{"parameters":{"options":{}},"id":"groq-chat-trigger","name":"DeepSeek Chat Trigger","type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.4,"position":[-3216,-368],"webhookId":"02f6c8d3-7e63-432a-9b7a-de7615de11f9","disabled":true},{"parameters":{"jsCode":"// NEU: Intelligenter Extract Chat Input\n// Leitet Chat Input an DeepSeek API weiter für intelligente Analyse\n// Dieser Node bereitet nur die Daten vor und leitet sie weiter\nconst chatInput = $input.first().json.chatInput || $input.first().json.message || '';\n\nconsole.log('[Extract Chat Input] Chat Input erhalten:', chatInput);\n\n// Leite Chat Input direkt an DeepSeek Intelligent Parse weiter\n// Die eigentliche Analyse erfolgt in DeepSeek Intelligent Parse Node\nreturn [{\n  json: {\n    chatInput: chatInput,\n    message: chatInput,\n    _needsIntelligentParse: true\n  }\n}];"},"id":"extract-chat-input","name":"Extract Chat Input","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2992,-368],"disabled":true},{"parameters":{"jsCode":"// Intelligente Marktanalyse: Extrahiert E-Book-Parameter aus Marktanalyse-Daten\n// ERWEITERT: Fokus auf Topseller aus allen Stilrichtungen und Bereichen\n// WICHTIG: Verwendet Input-Daten von Process Analyze Trends Response\nconst inputData = $input.first().json || {};\n\nconsole.log('[Market Analysis] ===== INTELLIGENT MARKET ANALYSIS START =====');\nconsole.log('[Market Analysis] Input keys:', Object.keys(inputData));\nconsole.log('[Market Analysis] Has trends:', !!inputData.trends);\nconsole.log('[Market Analysis] Has marketInsights:', !!inputData.marketInsights);\n\n// Extrahiere Marktanalyse-Daten aus Input (von Process Analyze Trends Response)\nfunction extractTrendsData(data) {\n  try {\n    // Falls bereits geparste Trends vorhanden\n    if (data.trends && Array.isArray(data.trends)) {\n      return {\n        trends: data.trends,\n        market_insights: data.marketInsights || data.market_insights || ''\n      };\n    }\n    \n    // Falls noch in Response-Format\n    if (data.choices?.[0]?.message?.content) {\n      const content = data.choices[0].message.content;\n      const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]);\n      }\n    }\n  } catch (e) {\n    console.error('[Market Analysis] Parse error:', e);\n  }\n  return { trends: [], market_insights: '' };\n}\n\n// Verwende Input-Daten (von Process Analyze Trends Response)\nconst parsedData = extractTrendsData(inputData);\nconst trends = parsedData.trends || inputData.trends || [];\nconst marketInsights = parsedData.market_insights || parsedData.marketInsights || inputData.marketInsights || inputData.market_insights || '';\n\nconsole.log('[Market Analysis] Trends count:', trends.length);\nconsole.log('[Market Analysis] Market insights length:', marketInsights.length);\n\n// WICHTIG: Wähle den besten Trend basierend auf Popularität und Vielfalt\n// Priorisiere Trends mit hoher Popularität und verschiedenen Zielgruppen\nlet bestTrend = null;\nlet bestPopularity = 0;\n\nfor (const trend of trends) {\n  const popularity = trend.popularity || 0;\n  if (popularity > bestPopularity) {\n    bestPopularity = popularity;\n    bestTrend = trend;\n  }\n}\n\n// Falls kein Trend gefunden, verwende ersten Trend\nif (!bestTrend && trends.length > 0) {\n  bestTrend = trends[0];\n}\n\n// Falls immer noch kein Trend, erstelle Standard-Trend\nif (!bestTrend) {\n  bestTrend = {\n    topic: 'Aktuelle Markttrends',\n    genre: 'non-fiction',\n    target_audience: 'Berufstätige und Unternehmer',\n    popularity: 7\n  };\n}\n\nconsole.log('[Market Analysis] Best Trend:', bestTrend);\n\n// Bestimme optimale E-Book-Parameter basierend auf Marktanalyse\n// ERWEITERT: Berücksichtigt verschiedene Stilrichtungen und Zielgruppen\nconst genre = (bestTrend.genre || 'non-fiction').toLowerCase();\nconst popularity = bestTrend.popularity || 7;\nconst targetAudience = (bestTrend.target_audience || '').toLowerCase();\nconst topic = bestTrend.topic || '';\n\nlet ebookParams = {\n  textType: 'Ratgeber',\n  coverImageType: 'Bilder im eBook',\n  chapterCount: 5,\n  wordsPerChapter: 600,\n  topic: topic, // WICHTIG: Topic von Trend übernehmen\n  reasoning: `Basierend auf Marktanalyse: ${bestTrend.reasoning || 'Topseller-Trend aus Marktanalyse'}`\n};\n\n// ERWEITERT: Bild-Parameter\nlet imageParams = {\n  imageType: 'cover',\n  style: 'modern',\n  aspectRatio: '16:9',\n  hasText: false,\n  imagesInBook: true,\n  imageCount: 3\n};\n\n// Bestimme Parameter basierend auf Genre und Zielgruppe\nif (genre.includes('fiction') || genre.includes('story') || genre.includes('roman')) {\n  ebookParams.textType = 'Story';\n  ebookParams.chapterCount = 8;\n  ebookParams.wordsPerChapter = 800;\n  ebookParams.coverImageType = 'Modern';\n  imageParams.imageType = 'cover';\n  imageParams.style = 'artistic';\n  imageParams.aspectRatio = '9:16';\n  imageParams.hasText = false;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 5;\n} else if (genre.includes('tutorial') || genre.includes('anleitung') || genre.includes('guide')) {\n  ebookParams.textType = 'Tutorial';\n  ebookParams.chapterCount = 6;\n  ebookParams.wordsPerChapter = 500;\n  ebookParams.coverImageType = 'Bilder im eBook';\n  imageParams.imageType = 'title-with-text';\n  imageParams.style = 'professional';\n  imageParams.aspectRatio = '16:9';\n  imageParams.hasText = true;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 8;\n} else if (genre.includes('handwerk') || targetAudience.includes('handwerk')) {\n  ebookParams.textType = 'Anleitung';\n  ebookParams.chapterCount = 7;\n  ebookParams.wordsPerChapter = 600;\n  ebookParams.coverImageType = 'AllesHandwerknzahl';\n  imageParams.imageType = 'cover';\n  imageParams.style = 'classic';\n  imageParams.aspectRatio = '4:3';\n  imageParams.hasText = false;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 10;\n} else {\n  // Non-fiction / Ratgeber\n  ebookParams.textType = 'Ratgeber';\n  ebookParams.chapterCount = 5;\n  ebookParams.wordsPerChapter = 600;\n  ebookParams.coverImageType = 'Bilder im eBook';\n  imageParams.imageType = 'cover';\n  imageParams.style = 'modern';\n  imageParams.aspectRatio = '16:9';\n  imageParams.hasText = false;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 3;\n}\n\n// Anpassung basierend auf Popularität\nif (popularity >= 9) {\n  ebookParams.chapterCount = Math.min(ebookParams.chapterCount + 2, 10);\n  ebookParams.wordsPerChapter = Math.min(ebookParams.wordsPerChapter + 100, 1000);\n  imageParams.imageCount = Math.min(imageParams.imageCount + 2, 15);\n} else if (popularity <= 6) {\n  ebookParams.chapterCount = Math.max(ebookParams.chapterCount - 1, 3);\n  ebookParams.wordsPerChapter = Math.max(ebookParams.wordsPerChapter - 100, 300);\n  imageParams.imageCount = Math.max(imageParams.imageCount - 1, 1);\n}\n\n// Anpassung basierend auf Zielgruppe\nif (targetAudience.includes('unternehmer') || targetAudience.includes('business')) {\n  imageParams.style = 'professional';\n  imageParams.aspectRatio = '16:9';\n  imageParams.hasText = true;\n} else if (targetAudience.includes('handwerk') || targetAudience.includes('handwerker')) {\n  imageParams.style = 'classic';\n  imageParams.aspectRatio = '4:3';\n  imageParams.hasText = false;\n} else if (targetAudience.includes('kreativ') || targetAudience.includes('design')) {\n  imageParams.style = 'artistic';\n  imageParams.aspectRatio = '1:1';\n  imageParams.hasText = false;\n} else if (targetAudience.includes('jung') || targetAudience.includes('junge')) {\n  imageParams.style = 'modern';\n  imageParams.aspectRatio = '9:16';\n  imageParams.hasText = false;\n} else if (targetAudience.includes('alt') || targetAudience.includes('senior')) {\n  imageParams.style = 'classic';\n  imageParams.aspectRatio = '4:3';\n  imageParams.hasText = true;\n}\n\n// Bestimme imageType basierend auf coverImageType\nif (ebookParams.coverImageType === 'AllesHandwerknzahl') {\n  imageParams.imageType = 'cover';\n  imageParams.style = 'classic';\n} else if (ebookParams.coverImageType === 'Bilder im eBook') {\n  imageParams.imageType = 'title-with-text';\n  imageParams.hasText = true;\n} else if (ebookParams.coverImageType === 'Modern') {\n  imageParams.imageType = 'cover';\n  imageParams.style = 'modern';\n}\n\n// Berechne Gesamt-Wortanzahl\nconst totalWords = ebookParams.chapterCount * ebookParams.wordsPerChapter;\n\nconsole.log('[Market Analysis] ===== INTELLIGENT MARKET ANALYSIS END =====');\nconsole.log('[Market Analysis] E-Book Parameters:');\nconsole.log('  Topic:', ebookParams.topic);\nconsole.log('  Text Type:', ebookParams.textType);\nconsole.log('  Cover Image Type:', ebookParams.coverImageType);\nconsole.log('  Chapter Count:', ebookParams.chapterCount);\nconsole.log('  Words Per Chapter:', ebookParams.wordsPerChapter);\nconsole.log('  Total Words:', totalWords);\nconsole.log('[Market Analysis] Image Parameters:');\nconsole.log('  Image Type:', imageParams.imageType);\nconsole.log('  Style:', imageParams.style);\nconsole.log('  Aspect Ratio:', imageParams.aspectRatio);\nconsole.log('  Has Text:', imageParams.hasText);\nconsole.log('  Images In Book:', imageParams.imagesInBook);\nconsole.log('  Image Count:', imageParams.imageCount);\n\n// WICHTIG: Kombiniere ALLE Input-Daten mit neuen Parametern und leite sie weiter\n// KRITISCH: Topic muss immer vorhanden sein!\nreturn [{\n  json: {\n    ...inputData, // Behalte alle ursprünglichen Daten\n    // WICHTIG: Topic von Trend übernehmen (höchste Priorität)\n    topic: ebookParams.topic || inputData.topic || null,\n    thema: ebookParams.topic || inputData.thema || inputData.topic || null,\n    // E-Book-Parameter aus Marktanalyse\n    marketAnalysisEbookParams: {\n      textType: ebookParams.textType,\n      coverImageType: ebookParams.coverImageType,\n      chapterCount: ebookParams.chapterCount,\n      wordsPerChapter: ebookParams.wordsPerChapter,\n      totalWords: totalWords,\n      reasoning: ebookParams.reasoning,\n      topic: ebookParams.topic\n    },\n    // ERWEITERT: Bild-Parameter aus Marktanalyse\n    marketAnalysisImageParams: {\n      imageType: imageParams.imageType,\n      style: imageParams.style,\n      aspectRatio: imageParams.aspectRatio,\n      hasText: imageParams.hasText,\n      imagesInBook: imageParams.imagesInBook,\n      imageCount: imageParams.imageCount\n    },\n    // Für Kompatibilität mit nachfolgenden Nodes\n    textType: ebookParams.textType,\n    coverImageType: ebookParams.coverImageType,\n    chapterCount: ebookParams.chapterCount,\n    wordsPerChapter: ebookParams.wordsPerChapter,\n    totalWords: totalWords,\n    minWordCount: totalWords,\n    // Bild-Parameter für Kompatibilität\n    imageType: imageParams.imageType,\n    style: imageParams.style,\n    aspectRatio: imageParams.aspectRatio,\n    hasText: imageParams.hasText,\n    imagesInBook: imageParams.imagesInBook,\n    imageCount: imageParams.imageCount,\n    // Trends-Daten für nachfolgende Nodes\n    trends: trends,\n    marketInsights: marketInsights,\n    market_insights: marketInsights\n  }\n}];"},"id":"intelligent-market-analysis","name":"Intelligent Market Analysis (MCP)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2464,48]},{"parameters":{"method":"POST","url":"https://api.deepseek.com/v1/chat/completions","authentication":"predefinedCredentialType","nodeCredentialType":"deepSeekApi","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Authorization","value":"Bearer sk-fd178bb87e1240b19786ce816c77d07f"},{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ JSON.stringify({ model: 'deepseek-chat', messages: [{ role: 'system', content: 'Du bist ein Experte für E-Book-Optimierung und Marktanalyse. Analysiere Marktdaten und bestimme optimale E-Book-Parameter inklusive Bild-Parameter. Antworte IMMER im JSON-Format.' }, { role: 'user', content: 'Basierend auf folgenden Marktanalyse-Daten:\\n\\nMarkt-Insights: ' + ($json.marketInsights || $json.market_insights || '') + '\\nTop-Trend: ' + ($json.trends?.[0]?.topic || 'Unbekannt') + '\\nGenre: ' + ($json.trends?.[0]?.genre || 'non-fiction') + '\\nZielgruppe: ' + ($json.trends?.[0]?.target_audience || 'Berufstätige und Unternehmer') + '\\nPopularität: ' + ($json.trends?.[0]?.popularity || 7) + '/10\\n\\nBestimme die optimalen E-Book-Parameter:\\n1. Text-Art (Ratgeber, Tutorial, Story, Anleitung, Guide)\\n2. Titelbild-Style (Bilder im eBook, AllesHandwerknzahl, Modern, Klassisch)\\n3. Kapitelanzahl (3-10)\\n4. Worte pro Kapitel (300-1000)\\n\\nERWEITERT: Bild-Parameter:\\n5. imageType (cover, title, in-book, title-with-text)\\n6. style (modern, classic, minimalist, professional, artistic)\\n7. aspectRatio (16:9, 9:16, 1:1, 4:3, 3:4)\\n8. hasText (boolean - Titelbild mit Text?)\\n9. imagesInBook (boolean - Bilder im eBook selbst?)\\n10. imageCount (number - Anzahl Bilder im eBook)\\n\\nAntworte im JSON-Format: {\\\"textType\\\": \\\"string\\\", \\\"coverImageType\\\": \\\"string\\\", \\\"chapterCount\\\": number, \\\"wordsPerChapter\\\": number, \\\"imageType\\\": \\\"string\\\", \\\"style\\\": \\\"string\\\", \\\"aspectRatio\\\": \\\"string\\\", \\\"hasText\\\": boolean, \\\"imagesInBook\\\": boolean, \\\"imageCount\\\": number, \\\"reasoning\\\": \\\"string\\\"}' }], temperature: 0.7 }) }}","options":{}},"id":"groq-enhanced-analysis","name":"DeepSeek Enhanced Analysis","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[-2288,304],"alwaysOutputData":true,"credentials":{"httpHeaderAuth":{"id":"u3Sgkv5o7BSKcUY2","name":"X.AI (Grok)"},"deepSeekApi":{"id":"ZDG2m0jA1qkyUnC3","name":"DeepSeek"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const items = $input.all(); const result = items.map(item => ({ json: item.json })); return result.length > 0 ? result : [{ json: {} }];"},"id":"merge-market-analysis-params","name":"Merge Market Analysis Params","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1744,304]},{"parameters":{"jsCode":"// Verarbeite Analyze Trends Response\n// KRITISCH: DeepSeek API gibt JSON in Code-Block zurück (```json ... ```)\n// Dieser Node extrahiert das JSON und formatiert es für nachfolgende Nodes\nconst inputData = $input.first().json || {};\n\nconsole.log('[Process Analyze Trends] ===== PROCESS ANALYZE TRENDS RESPONSE START =====');\nconsole.log('[Process Analyze Trends] Input keys:', Object.keys(inputData));\n\n// Extrahiere JSON aus API Response\nlet trendsData = null;\n\ntry {\n  // Prüfe ob choices vorhanden sind\n  if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n    const content = inputData.choices[0].message.content || '';\n    console.log('[Process Analyze Trends] Content length:', content.length);\n    console.log('[Process Analyze Trends] Content preview:', content.substring(0, 200));\n    \n    // Entferne Code-Block-Markierungen (```json ... ```)\n    let jsonContent = content.trim();\n    \n    // Entferne ```json am Anfang\n    if (jsonContent.startsWith('```json')) {\n      jsonContent = jsonContent.substring(7).trim();\n    } else if (jsonContent.startsWith('```')) {\n      jsonContent = jsonContent.substring(3).trim();\n    }\n    \n    // Entferne ``` am Ende\n    if (jsonContent.endsWith('```')) {\n      jsonContent = jsonContent.substring(0, jsonContent.length - 3).trim();\n    }\n    \n    console.log('[Process Analyze Trends] Cleaned JSON content length:', jsonContent.length);\n    \n    // Parse JSON\n    trendsData = JSON.parse(jsonContent);\n    console.log('[Process Analyze Trends] ✅ JSON erfolgreich geparst');\n    console.log('[Process Analyze Trends] Trends count:', trendsData.trends ? trendsData.trends.length : 0);\n    console.log('[Process Analyze Trends] Market insights length:', trendsData.market_insights ? trendsData.market_insights.length : 0);\n  } else {\n    console.log('[Process Analyze Trends] ⚠️ Keine choices in Response');\n    // Fallback: Versuche direkt zu parsen\n    if (typeof inputData === 'object' && inputData.trends) {\n      trendsData = inputData;\n      console.log('[Process Analyze Trends] ✅ Direktes Parsing erfolgreich');\n    }\n  }\n} catch (e) {\n  console.error('[Process Analyze Trends] ❌ Parse Error:', e.message);\n  console.error('[Process Analyze Trends] Stack:', e.stack);\n  \n  // Fallback: Versuche JSON direkt aus Input zu extrahieren\n  try {\n    if (inputData.trends && Array.isArray(inputData.trends)) {\n      trendsData = {\n        trends: inputData.trends,\n        market_insights: inputData.market_insights || inputData.market_insights || ''\n      };\n      console.log('[Process Analyze Trends] ✅ Fallback: Direktes Parsing aus Input');\n    }\n  } catch (e2) {\n    console.error('[Process Analyze Trends] ❌ Fallback auch fehlgeschlagen:', e2.message);\n  }\n}\n\nif (!trendsData || !trendsData.trends || !Array.isArray(trendsData.trends)) {\n  console.error('[Process Analyze Trends] ❌ KEINE TRENDS GEFUNDEN!');\n  console.error('[Process Analyze Trends] TrendsData:', JSON.stringify(trendsData, null, 2));\n  console.error('[Process Analyze Trends] Input Data:', JSON.stringify(inputData, null, 2));\n  \n  // Fallback: Leere Trends-Struktur\n  trendsData = {\n    trends: [],\n    market_insights: 'Keine Trends gefunden'\n  };\n}\n\n// Formatiere Daten für nachfolgende Nodes\nconst outputData = {\n  ...inputData, // Behalte alle ursprünglichen Daten\n  // WICHTIG: Extrahiertes JSON\n  trends: trendsData.trends || [],\n  market_insights: trendsData.market_insights || trendsData.marketInsights || '',\n  marketInsights: trendsData.market_insights || trendsData.marketInsights || ''\n};\n\nconsole.log('[Process Analyze Trends] ===== PROCESS ANALYZE TRENDS RESPONSE END =====');\nconsole.log('[Process Analyze Trends] ✅ Output Data:');\nconsole.log('  Trends count:', outputData.trends.length);\nconsole.log('  Market insights length:', outputData.market_insights.length);\nif (outputData.trends.length > 0) {\n  console.log('  First trend topic:', outputData.trends[0].topic);\n  console.log('  First trend popularity:', outputData.trends[0].popularity);\n}\n\nreturn [{ json: outputData }];"},"id":"process-analyze-trends-response","name":"Process Analyze Trends Response","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2656,288]},{"parameters":{"jsCode":"const items = $input.all(); const result = items.map(item => ({ json: item.json })); return result.length > 0 ? result : [{ json: {} }];"},"id":"process-groq-enhanced-response","name":"Process DeepSeek Enhanced Response","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1936,304]},{"parameters":{"jsCode":"// Stelle sicher, dass Analyze Trends immer Daten hat\n// Dieser Node wird NACH Analyze Trends ausgeführt und stellt sicher, dass Daten vorhanden sind\n// Falls Analyze Trends leer ist, werden Standard-Trends erstellt\n// FIXED: Erstellt Fallback-Trends basierend auf Marktanalyse, wenn Analyze Trends leer ist\n\n// Hole Input-Daten (von Analyze Trends)\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Analyze Trends] ===== ENSURE ANALYZE TRENDS DATA START =====');\nconsole.log('[Ensure Analyze Trends] Input keys:', Object.keys(inputData));\nconsole.log('[Ensure Analyze Trends] Input length:', Object.keys(inputData).length);\nconsole.log('[Ensure Analyze Trends] Has choices:', !!inputData.choices);\n\n// Hole Daten vom vorherigen Node (Load Secrets)\nlet secretsData = {};\ntry {\n  secretsData = $('Load Secrets from Supabase').first().json || {};\n  console.log('[Ensure Analyze Trends] ✅ Secrets data found');\n} catch (e) {\n  console.log('[Ensure Analyze Trends] ⚠️ Secrets data not found:', e.message);\n}\n\n// Prüfe ob Analyze Trends Daten hat\nconst hasAnalyzeTrendsData = inputData.choices && inputData.choices.length > 0 && inputData.choices[0].message && inputData.choices[0].message.content;\n\nif (hasAnalyzeTrendsData) {\n  console.log('[Ensure Analyze Trends] ✅ Analyze Trends hat Daten, verwende diese');\n  const output = { ...secretsData, ...inputData };\n  console.log('[Ensure Analyze Trends] Output keys:', Object.keys(output));\n  return [{ json: output }];\n}\n\n// Falls Analyze Trends leer ist, erstelle Fallback-Daten mit Standard-Trends\nconsole.warn('[Ensure Analyze Trends] ⚠️ Analyze Trends ist leer, erstelle Fallback-Daten mit Standard-Trends');\n\n// Standard-Trends: Topseller aus verschiedenen Stilrichtungen und Bereichen\nconst fallbackTrends = [\n  {\n    topic: 'Künstliche Intelligenz im Business',\n    genre: 'Ratgeber',\n    target_audience: 'Unternehmer',\n    popularity: 9,\n    reasoning: 'Hohe Nachfrage nach KI-Anwendungen im Business-Bereich, aktuelle Topseller-Thematik'\n  },\n  {\n    topic: 'Gesundheit und Wohlbefinden für Senioren',\n    genre: 'Ratgeber',\n    target_audience: 'Senioren',\n    popularity: 8,\n    reasoning: 'Wachsende Zielgruppe, hohe Relevanz für Gesundheitsthemen'\n  },\n  {\n    topic: 'Nachhaltigkeit und Umweltschutz',\n    genre: 'Sachbuch',\n    target_audience: 'Junge Erwachsene',\n    popularity: 9,\n    reasoning: 'Aktuelles Trend-Thema mit hoher gesellschaftlicher Relevanz'\n  },\n  {\n    topic: 'Finanzielle Unabhängigkeit für Privatpersonen',\n    genre: 'Ratgeber',\n    target_audience: 'Privatpersonen',\n    popularity: 8,\n    reasoning: 'Hohe Nachfrage nach Finanzthemen, praktische Anwendbarkeit'\n  },\n  {\n    topic: 'Handwerk und DIY-Projekte',\n    genre: 'Anleitung',\n    target_audience: 'Privatpersonen',\n    popularity: 7,\n    reasoning: 'Wachsende Beliebtheit von Handwerk und DIY, praktische Anleitungen'\n  },\n  {\n    topic: 'Produktivität und Zeitmanagement',\n    genre: 'Ratgeber',\n    target_audience: 'Berufstätige',\n    popularity: 8,\n    reasoning: 'Immer relevante Thematik für Berufstätige, hohe Nachfrage'\n  },\n  {\n    topic: 'Kreativität und Design',\n    genre: 'Kreativ',\n    target_audience: 'Kreative',\n    popularity: 7,\n    reasoning: 'Wachsende Kreativwirtschaft, hohe Nachfrage nach Design-Themen'\n  }\n];\n\nconst fallbackData = {\n  ...secretsData,\n  choices: [{\n    message: {\n      content: JSON.stringify({\n        trends: fallbackTrends,\n        market_insights: 'Standard-Trends basierend auf aktuellen Topsellern aus verschiedenen Stilrichtungen und Bereichen (Business, Privat, jung, alt). Diese Trends wurden verwendet, da die Marktanalyse-API keine Daten zurückgegeben hat.'\n      })\n    }\n  }],\n  _fallback: true,\n  _analyzeTrendsEmpty: true,\n  _standardTrends: true\n};\n\nconsole.log('[Ensure Analyze Trends] ✅ Fallback-Daten erstellt mit', fallbackTrends.length, 'Trends');\nconsole.log('[Ensure Analyze Trends] Trends:', fallbackTrends.map(t => t.topic));\nconsole.log('[Ensure Analyze Trends] ===== ENSURE ANALYZE TRENDS DATA END =====');\n\nreturn [{ json: fallbackData }];"},"id":"ensure-analyze-trends-data","name":"Ensure Analyze Trends Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2912,288]},{"parameters":{"jsCode":"// Stelle sicher, dass Groq Enhanced Analysis immer Daten hat\n// Dieser Node wird NACH Groq Enhanced Analysis ausgeführt und stellt sicher, dass Daten vorhanden sind\n// Falls Groq Enhanced Analysis leer ist, werden die Daten vom vorherigen Node weitergeleitet\n\n// Hole Input-Daten (von Groq Enhanced Analysis)\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Groq Enhanced] Input keys:', Object.keys(inputData));\nconsole.log('[Ensure Groq Enhanced] Input length:', Object.keys(inputData).length);\n\n// Hole Daten vom vorherigen Node (Intelligent Market Analysis)\nlet marketAnalysisData = {};\ntry {\n  marketAnalysisData = $('Intelligent Market Analysis (MCP)').item.json || {};\n  console.log('[Ensure Groq Enhanced] Market Analysis data found');\n} catch (e) {\n  console.log('[Ensure Groq Enhanced] Market Analysis data not found');\n}\n\n// Prüfe ob Groq Enhanced Analysis Daten hat\nconst hasGroqData = inputData.choices || (Object.keys(inputData).length > 2 && !inputData.error);\n\nif (hasGroqData) {\n  console.log('[Ensure Groq Enhanced] Groq Enhanced Analysis hat Daten, verwende diese');\n  return [{ json: { ...marketAnalysisData, ...inputData } }];\n}\n\n// Falls Groq Enhanced Analysis leer ist, erstelle Fallback-Daten basierend auf Market Analysis\nconsole.warn('[Ensure Groq Enhanced] Groq Enhanced Analysis ist leer, erstelle Fallback-Daten');\n\nconst marketParams = marketAnalysisData.marketAnalysisEbookParams || {};\nconst imageParams = marketAnalysisData.marketAnalysisImageParams || {};\n\nconst fallbackData = {\n  ...marketAnalysisData,\n  choices: [{\n    message: {\n      content: JSON.stringify({\n        textType: marketParams.textType || 'Ratgeber',\n        coverImageType: marketParams.coverImageType || 'Bilder im eBook',\n        chapterCount: marketParams.chapterCount || 5,\n        wordsPerChapter: marketParams.wordsPerChapter || 600,\n        imageType: imageParams.imageType || 'cover',\n        style: imageParams.style || 'modern',\n        aspectRatio: imageParams.aspectRatio || '16:9',\n        hasText: imageParams.hasText !== undefined ? imageParams.hasText : false,\n        imagesInBook: imageParams.imagesInBook !== undefined ? imageParams.imagesInBook : true,\n        imageCount: imageParams.imageCount || 3,\n        reasoning: marketParams.reasoning || 'Standard-Parameter basierend auf Marktanalyse'\n      })\n    }\n  }],\n  _fallback: true,\n  _groqEnhancedEmpty: true\n};\n\nconsole.log('[Ensure Groq Enhanced] Fallback-Daten erstellt');\nreturn [{ json: fallbackData }];"},"id":"ensure-groq-enhanced-data","name":"Ensure DeepSeek Enhanced Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2112,304]},{"parameters":{"method":"POST","url":"https://api.deepseek.com/v1/chat/completions","authentication":"predefinedCredentialType","nodeCredentialType":"deepSeekApi","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Authorization","value":"Bearer sk-fd178bb87e1240b19786ce816c77d07f"},{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ JSON.stringify({ model: 'deepseek-chat', messages: [{ role: 'system', content: 'Du bist ein Experte für die Analyse von E-Book-Anfragen. Analysiere die Benutzeranfrage und extrahiere alle relevanten Parameter. Antworte IMMER im JSON-Format mit folgender Struktur: { topic: string (Thema des E-Books, z.B. \"Mäuse\"), textType: string (Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch), coverImageType: string (Bilder im eBook, AllesHandwerknzahl, Modern, Klassisch), chapterCount: number (Anzahl Kapitel, z.B. 2), wordsPerChapter: number (Wörter pro Kapitel, z.B. 400), imageType: string (cover, title, in-book, title-with-text), style: string (modern, classic, minimalist, professional, artistic), aspectRatio: string (16:9, 9:16, 1:1, 4:3, 3:4), hasText: boolean (Titelbild mit Text?), imagesInBook: boolean (Bilder im eBook?), imageCount: number (Anzahl Bilder im eBook) }. Wenn ein Parameter nicht im Text erwähnt wird, verwende null (nicht einen Standard-Wert).' }, { role: 'user', content: (() => { try { const extractData = $('Extract Chat Input').item.json || {}; const chatInput = extractData.chatInput || extractData.message || ''; return 'Analysiere folgende E-Book-Anfrage und extrahiere alle Parameter: ' + chatInput; } catch (e) { return 'Analysiere folgende E-Book-Anfrage und extrahiere alle Parameter: ' + ($json.chatInput || $json.message || ''); } })() }], temperature: 0.3 }) }}","options":{}},"id":"groq-intelligent-parse","name":"DeepSeek Intelligent Parse","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[-2672,-368],"alwaysOutputData":true,"credentials":{"httpHeaderAuth":{"id":"Y6Cp0o6zzWX3U7sx","name":"Deepgram TTS"},"deepSeekApi":{"id":"ZDG2m0jA1qkyUnC3","name":"DeepSeek"}},"disabled":true},{"parameters":{"jsCode":"// Verarbeite Groq Intelligent Parse Response\n// Extrahiert strukturierte Daten aus Groq API Response\n// Fallback auf Regex-Patterns, falls Groq fehlschlägt\n// FIXED: Verbesserte Regex-Patterns für \"Thema X\" und \"ebook über X\" Format\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// KRITISCH: Chat-Input muss IMMER vorhanden sein - hole von mehreren Quellen\nconst inputData = $input.first().json || {};\n\nconsole.log('[Process DeepSeek Parse] ===== TOPIC EXTRACTION START =====');\nconsole.log('[Process DeepSeek Parse] Input Data keys:', Object.keys(inputData));\nconsole.log('[Process DeepSeek Parse] Input Data chatInput:', inputData.chatInput);\nconsole.log('[Process DeepSeek Parse] Input Data message:', inputData.message);\n\n// KRITISCH: Hole Chat Input von MEHREREN Quellen (Priorität: Input > Extract Chat Input > DeepSeek Chat Trigger)\nlet chatInput = '';\n\n// Priorität 1: Input-Daten direkt (von DeepSeek Intelligent Parse)\nif (inputData.chatInput || inputData.message) {\n  chatInput = inputData.chatInput || inputData.message || '';\n  console.log('[Process DeepSeek Parse] ✅ Chat Input von Input Data:', chatInput);\n}\n\n// Priorität 2: Extract Chat Input Node\nif (!chatInput || chatInput.trim().length === 0) {\n  try {\n    const extractData = $('Extract Chat Input').item.json || {};\n    chatInput = extractData.chatInput || extractData.message || '';\n    if (chatInput && chatInput.trim().length > 0) {\n      console.log('[Process DeepSeek Parse] ✅ Chat Input von Extract Chat Input:', chatInput);\n    }\n  } catch (e) {\n    console.log('[Process DeepSeek Parse] Extract Chat Input not found:', e.message);\n  }\n}\n\n// Priorität 3: DeepSeek Chat Trigger (falls alles andere fehlschlägt)\nif (!chatInput || chatInput.trim().length === 0) {\n  try {\n    const triggerData = $('DeepSeek Chat Trigger').item.json || {};\n    chatInput = triggerData.chatInput || triggerData.message || '';\n    if (chatInput && chatInput.trim().length > 0) {\n      console.log('[Process DeepSeek Parse] ✅ Chat Input von DeepSeek Chat Trigger:', chatInput);\n    }\n  } catch (e) {\n    console.log('[Process DeepSeek Parse] DeepSeek Chat Trigger not found:', e.message);\n  }\n}\n\nif (!chatInput || chatInput.trim().length === 0) {\n  console.warn('[Process DeepSeek Parse] ⚠️ KEIN CHAT-INPUT GEFUNDEN!');\n  console.warn('[Process DeepSeek Parse] Input Data:', JSON.stringify(inputData, null, 2));\n}\n\nconsole.log('[Process DeepSeek Parse] Chat Input (raw):', chatInput);\nconsole.log('[Process DeepSeek Parse] Chat Input length:', chatInput.length);\n\n// Versuche Groq Response zu parsen\nlet groqParsedData = null;\n\ntry {\n  if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n    const content = inputData.choices[0].message.content || '';\n    console.log('[Process DeepSeek Parse] Groq Response Content length:', content.length);\n    const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n      groqParsedData = JSON.parse(jsonMatch[0]);\n      console.log('[Process DeepSeek Parse] ✅ Groq Response erfolgreich geparst');\n      console.log('[Process DeepSeek Parse] Groq Data keys:', Object.keys(groqParsedData));\n      console.log('[Process DeepSeek Parse] Groq Topic:', groqParsedData.topic);\n    } else {\n      console.log('[Process DeepSeek Parse] ⚠️ Kein JSON in Groq Response gefunden');\n    }\n  } else {\n    console.log('[Process DeepSeek Parse] ⚠️ Keine choices in Groq Response');\n  }\n} catch (e) {\n  console.error('[Process DeepSeek Parse] ❌ Parse Error:', e.message);\n}\n\n// Fallback: Regex-Patterns (falls Groq fehlschlägt)\nlet fallbackData = {\n  textType: null,\n  coverImageType: null,\n  chapterCount: null,\n  wordsPerChapter: null,\n  topic: null,\n  imageType: null,\n  style: null,\n  aspectRatio: null,\n  hasText: null,\n  imagesInBook: null,\n  imageCount: null\n};\n\n// FIXED: Verbesserte Regex-Patterns für \"Thema X\" und \"ebook über X\" Format\n// WICHTIG: Nur wenn Chat-Input vorhanden ist\nif (chatInput && chatInput.trim().length > 0) {\n  if (!groqParsedData || !groqParsedData.topic) {\n    console.log('[Process DeepSeek Parse] 🔍 Verwende Regex-Patterns für Topic-Extraktion');\n    const topicPatterns = [\n      // Pattern 1: \"Thema X\" (höchste Priorität - häufigste Eingabe)\n      { pattern: /(?:thema|topic)[\\s:]+([^\\n,.!?]+)/i, name: '\"Thema X\" Format' },\n      // Pattern 2: \"ebook über X\" oder \"ebook über X\"\n      { pattern: /(?:ebook|e-book|buch|book)[\\s]+(?:über|ueber|about|zum|zur|für|zu)[\\s]+([^\\n,.!?]+)/i, name: '\"ebook über X\" Format' },\n      // Pattern 3: \"über X\" (ohne ebook)\n      { pattern: /(?:über|ueber|about)[\\s]+([^\\n,.!?]+)/i, name: '\"über X\" Format' },\n      // Pattern 4: \"X ebook\" oder \"X buch\"\n      { pattern: /([^\\n,.!?]+)[\\s]+(?:ebook|e-book|buch|book)/i, name: '\"X ebook\" Format' }\n    ];\n    \n    for (const { pattern, name } of topicPatterns) {\n      const match = chatInput.match(pattern);\n      if (match && match[1]) {\n        fallbackData.topic = match[1].trim();\n        console.log(`[Process DeepSeek Parse] ✅ Pattern \"${name}\" matched:`, fallbackData.topic);\n        \n        // Entferne Artikel am Anfang\n        const beforeArticle = fallbackData.topic;\n        fallbackData.topic = fallbackData.topic.replace(/^(?:ein|eine|der|die|das|the|a|an)\\s+/i, '');\n        if (beforeArticle !== fallbackData.topic) {\n          console.log('[Process DeepSeek Parse] Artikel entfernt:', beforeArticle, '->', fallbackData.topic);\n        }\n        \n        // Entferne \"ebook\" oder \"buch\" am Ende, falls vorhanden\n        const beforeEbook = fallbackData.topic;\n        fallbackData.topic = fallbackData.topic.replace(/\\s+(?:ebook|e-book|buch|book)$/i, '');\n        if (beforeEbook !== fallbackData.topic) {\n          console.log('[Process DeepSeek Parse] E-Book/Buch am Ende entfernt:', beforeEbook, '->', fallbackData.topic);\n        }\n        \n        // Entferne \"thema\" oder \"topic\" am Anfang, falls vorhanden\n        const beforeThema = fallbackData.topic;\n        fallbackData.topic = fallbackData.topic.replace(/^(?:thema|topic)[\\s:]+/i, '');\n        if (beforeThema !== fallbackData.topic) {\n          console.log('[Process DeepSeek Parse] Thema/Topic am Anfang entfernt:', beforeThema, '->', fallbackData.topic);\n        }\n        \n        console.log('[Process DeepSeek Parse] ✅ Final Topic aus Regex:', fallbackData.topic);\n        break;\n      } else {\n        console.log(`[Process DeepSeek Parse] ❌ Pattern \"${name}\" nicht matched`);\n      }\n    }\n    \n    // FALLBACK: Wenn kein Pattern matcht, verwende den gesamten Chat-Input als Topic\n    if (!fallbackData.topic && chatInput.trim().length > 0) {\n      console.log('[Process DeepSeek Parse] 🔄 Kein Pattern matched, verwende gesamten Chat-Input als Topic');\n      fallbackData.topic = chatInput.trim();\n      // Entferne häufige Präfixe\n      const beforeClean = fallbackData.topic;\n      fallbackData.topic = fallbackData.topic.replace(/^(?:thema|topic|ebook|e-book|buch|book|über|ueber|about)[\\s:]+/i, '');\n      if (beforeClean !== fallbackData.topic) {\n        console.log('[Process DeepSeek Parse] Präfixe entfernt:', beforeClean, '->', fallbackData.topic);\n      }\n      console.log('[Process DeepSeek Parse] ✅ Topic aus gesamten Chat-Input:', fallbackData.topic);\n    }\n  } else {\n    console.log('[Process DeepSeek Parse] ✅ Topic bereits von Groq API erhalten:', groqParsedData.topic);\n  }\n  \n  // Extrahiere chapterCount und wordsPerChapter aus Chat-Input\n  if (!groqParsedData || groqParsedData.chapterCount === null || groqParsedData.chapterCount === undefined) {\n    const chapterPatterns = [\n      /(?:kapitel|chapters)[\\s:]+(\\d+)/i,\n      /(\\d+)[\\s]+kapitel/i,\n      /(\\d+)[\\s]+kapiteln/i,\n      /mit[\\s]+(\\d+)[\\s]+kapitel/i\n    ];\n    \n    for (const pattern of chapterPatterns) {\n      const match = chatInput.match(pattern);\n      if (match) {\n        fallbackData.chapterCount = parseInt(match[1] || match[0], 10);\n        if (fallbackData.chapterCount > 0 && fallbackData.chapterCount <= 20) {\n          console.log('[Process DeepSeek Parse] ✅ ChapterCount aus Regex:', fallbackData.chapterCount);\n          break;\n        }\n      }\n    }\n  }\n  \n  if (!groqParsedData || groqParsedData.wordsPerChapter === null || groqParsedData.wordsPerChapter === undefined) {\n    const wordsPatterns = [\n      /(?:a|à|à|a)[\\s]+(\\d+)[\\s]+wörtern?/i,\n      /(?:pro[\\s]+)?kapitel[\\s]+(?:a|à|à|a)[\\s]+(\\d+)[\\s]+wörtern?/i,\n      /(\\d+)[\\s]+wörtern?[\\s]+(?:pro[\\s]+)?kapitel/i\n    ];\n    \n    for (const pattern of wordsPatterns) {\n      const match = chatInput.match(pattern);\n      if (match) {\n        fallbackData.wordsPerChapter = parseInt(match[1] || match[0], 10);\n        if (fallbackData.wordsPerChapter > 0 && fallbackData.wordsPerChapter <= 5000) {\n          console.log('[Process DeepSeek Parse] ✅ WordsPerChapter aus Regex:', fallbackData.wordsPerChapter);\n          break;\n        }\n      }\n    }\n  }\n} else {\n  console.warn('[Process DeepSeek Parse] ⚠️ KEIN CHAT-INPUT - Kann keine Regex-Extraktion durchführen!');\n}\n\n// Kombiniere Groq-Daten mit Fallback-Daten\n// Priorität: Groq-Daten > Fallback-Daten\n// WICHTIG: null bedeutet, dass Parameter nicht gefunden wurde (kein Standard-Wert!)\nconst finalData = {\n  chatInput: chatInput, // WICHTIG: Chat-Input immer weiterleiten\n  topic: groqParsedData?.topic || fallbackData.topic || null,\n  textType: groqParsedData?.textType || fallbackData.textType || null,\n  coverImageType: groqParsedData?.coverImageType || fallbackData.coverImageType || null,\n  chapterCount: groqParsedData?.chapterCount !== null && groqParsedData?.chapterCount !== undefined ? groqParsedData.chapterCount : (fallbackData.chapterCount !== null ? fallbackData.chapterCount : null),\n  wordsPerChapter: groqParsedData?.wordsPerChapter !== null && groqParsedData?.wordsPerChapter !== undefined ? groqParsedData.wordsPerChapter : (fallbackData.wordsPerChapter !== null ? fallbackData.wordsPerChapter : null),\n  imageType: groqParsedData?.imageType || fallbackData.imageType || null,\n  style: groqParsedData?.style || fallbackData.style || null,\n  aspectRatio: groqParsedData?.aspectRatio || fallbackData.aspectRatio || null,\n  hasText: groqParsedData?.hasText !== null && groqParsedData?.hasText !== undefined ? groqParsedData.hasText : (fallbackData.hasText !== null ? fallbackData.hasText : null),\n  imagesInBook: groqParsedData?.imagesInBook !== null && groqParsedData?.imagesInBook !== undefined ? groqParsedData.imagesInBook : (fallbackData.imagesInBook !== null ? fallbackData.imagesInBook : null),\n  imageCount: groqParsedData?.imageCount || fallbackData.imageCount || null,\n  _fromGroq: !!groqParsedData,\n  _fromFallback: !groqParsedData && (fallbackData.topic || fallbackData.chapterCount || fallbackData.wordsPerChapter),\n  _source: groqParsedData?.topic ? 'groq' : (fallbackData.topic ? 'regex' : 'none')\n};\n\n// Berechne Gesamt-Wortanzahl (nur wenn beide Werte vorhanden)\nif (finalData.chapterCount && finalData.wordsPerChapter) {\n  finalData.totalWords = finalData.chapterCount * finalData.wordsPerChapter;\n  finalData.minWordCount = finalData.totalWords;\n} else {\n  finalData.totalWords = null;\n  finalData.minWordCount = null;\n}\n\nconsole.log('[Process DeepSeek Parse] ===== TOPIC EXTRACTION END =====');\nconsole.log('[Process DeepSeek Parse] ✅ FINAL TOPIC:', finalData.topic);\nconsole.log('[Process DeepSeek Parse] Topic Source:', finalData._source);\nconsole.log('[Process DeepSeek Parse] From Groq:', finalData._fromGroq);\nconsole.log('[Process DeepSeek Parse] From Fallback:', finalData._fromFallback);\nconsole.log('[Process DeepSeek Parse] Final Data:');\nconsole.log('  Chat Input:', finalData.chatInput);\nconsole.log('  Topic:', finalData.topic);\nconsole.log('  Text Type:', finalData.textType);\nconsole.log('  Cover Image Type:', finalData.coverImageType);\nconsole.log('  Chapter Count:', finalData.chapterCount);\nconsole.log('  Words Per Chapter:', finalData.wordsPerChapter);\nconsole.log('  Total Words:', finalData.totalWords);\n\nreturn [{ json: finalData }];"},"id":"process-groq-parse","name":"Process DeepSeek Parse","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2272,-368],"disabled":true},{"parameters":{"jsCode":"// ERWEITERT: Kombiniere gespeicherte Proposal-Daten mit Marktanalyse-Daten\n// Supabase gibt nur die gespeicherten Felder zurück, nicht die zusätzlichen Felder (chapterCount, wordsPerChapter, etc.)\n// Dieser Node kombiniert die gespeicherten Daten mit den Marktanalyse-Daten\n// KRITISCH: Hole topic von Intelligent Market Analysis (Trendanalyse), NICHT vom Chat-Input\nconst savedProposal = $input.first().json || {};\n\nconsole.log('[Merge Proposal] ===== MERGE PROPOSAL WITH MARKET DATA START =====');\nconsole.log('[Merge Proposal] Saved Proposal keys:', Object.keys(savedProposal));\nconsole.log('[Merge Proposal] Saved Proposal topic:', savedProposal.topic);\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (Trendanalyse) - HÖCHSTE PRIORITÄT\nlet marketTopic = null;\nlet marketChapterCount = null;\nlet marketWordsPerChapter = null;\n\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').first().json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  marketChapterCount = marketData.chapterCount !== null && marketData.chapterCount !== undefined ? marketData.chapterCount : null;\n  marketWordsPerChapter = marketData.wordsPerChapter !== null && marketData.wordsPerChapter !== undefined ? marketData.wordsPerChapter : null;\n  console.log('[Merge Proposal] ✅ Intelligent Market Analysis gefunden');\n  console.log('[Merge Proposal] Market-Topic:', marketTopic);\n  console.log('[Merge Proposal] Market-ChapterCount:', marketChapterCount);\n  console.log('[Merge Proposal] Market-WordsPerChapter:', marketWordsPerChapter);\n} catch (e) {\n  console.log('[Merge Proposal] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Fallback: Hole von Generate E-Book Suggestions\nlet suggestionTopic = null;\nlet suggestionChapterCount = null;\nlet suggestionWordsPerChapter = null;\n\ntry {\n  const suggestionData = $('Generate E-Book Suggestions').first().json || {};\n  suggestionTopic = suggestionData.topic || suggestionData.thema || null;\n  suggestionChapterCount = suggestionData.chapterCount !== null && suggestionData.chapterCount !== undefined ? suggestionData.chapterCount : null;\n  suggestionWordsPerChapter = suggestionData.wordsPerChapter !== null && suggestionData.wordsPerChapter !== undefined ? suggestionData.wordsPerChapter : null;\n  console.log('[Merge Proposal] ✅ Generate E-Book Suggestions gefunden');\n  console.log('[Merge Proposal] Suggestion-Topic:', suggestionTopic);\n} catch (e) {\n  console.log('[Merge Proposal] ⚠️ Generate E-Book Suggestions not found');\n}\n\n// Hole Input-Daten (von Add Volume Number to Proposal)\n// Diese enthalten chapterCount, wordsPerChapter, etc.\nlet inputData = {};\ntry {\n  inputData = $('Add Volume Number to Proposal').first().json || {};\n  console.log('[Merge Proposal] ✅ Add Volume Number to Proposal gefunden');\n  console.log('[Merge Proposal] Input Data keys:', Object.keys(inputData));\n  console.log('[Merge Proposal] Input chapterCount:', inputData.chapterCount);\n  console.log('[Merge Proposal] Input wordsPerChapter:', inputData.wordsPerChapter);\n  console.log('[Merge Proposal] Input topic:', inputData.topic);\n} catch (e) {\n  console.log('[Merge Proposal] ⚠️ Add Volume Number to Proposal not found');\n  // Versuche von Filter Empty Proposals\n  try {\n    inputData = $('Filter Empty Proposals').first().json || {};\n    console.log('[Merge Proposal] Filter Empty Proposals gefunden');\n  } catch (e2) {\n    console.log('[Merge Proposal] Filter Empty Proposals not found');\n  }\n}\n\nconsole.log('[Merge Proposal] Topic-Priorität:');\nconsole.log('  Market-Topic (Intelligent Market Analysis):', marketTopic || '(nicht vorhanden)');\nconsole.log('  Suggestion-Topic (Generate E-Book Suggestions):', suggestionTopic || '(nicht vorhanden)');\nconsole.log('  Saved Proposal Topic:', savedProposal.topic || '(nicht vorhanden)');\nconsole.log('  Input Topic:', inputData.topic || '(nicht vorhanden)');\n\n// ERWEITERT: Kombiniere gespeicherte Daten mit Marktanalyse-Daten\n// Priorität für topic: Market Topic (Trendanalyse) > Suggestion Topic > Gespeicherte Daten > Input-Daten\n// KRITISCH: Alle Felder müssen vorhanden sein, da Telegram-Notification danach kommt\nconst mergedData = {\n  ...savedProposal, // Gespeicherte Daten haben Priorität\n  // WICHTIG: Topic hat höchste Priorität von Intelligent Market Analysis\n  topic: marketTopic || suggestionTopic || savedProposal.topic || inputData.topic || null,\n  thema: marketTopic || suggestionTopic || savedProposal.topic || inputData.topic || null, // Auch thema setzen für Konsistenz\n  // ERWEITERT: Füge Marktanalyse-Daten hinzu (werden nicht in Supabase gespeichert, aber durch Kette weitergegeben)\n  chapterCount: marketChapterCount !== null ? marketChapterCount : (suggestionChapterCount !== null ? suggestionChapterCount : (inputData.chapterCount !== undefined ? inputData.chapterCount : (savedProposal.chapterCount !== undefined ? savedProposal.chapterCount : null))),\n  wordsPerChapter: marketWordsPerChapter !== null ? marketWordsPerChapter : (suggestionWordsPerChapter !== null ? suggestionWordsPerChapter : (inputData.wordsPerChapter !== undefined ? inputData.wordsPerChapter : (savedProposal.wordsPerChapter !== undefined ? savedProposal.wordsPerChapter : null))),\n  textType: inputData.textType || savedProposal.textType || null,\n  coverImageType: inputData.coverImageType || savedProposal.coverImageType || null,\n  imageType: inputData.imageType || savedProposal.imageType || null,\n  style: inputData.style || savedProposal.style || null,\n  aspectRatio: inputData.aspectRatio || savedProposal.aspectRatio || null,\n  hasText: inputData.hasText !== undefined ? inputData.hasText : (savedProposal.hasText !== undefined ? savedProposal.hasText : null),\n  imagesInBook: inputData.imagesInBook !== undefined ? inputData.imagesInBook : (savedProposal.imagesInBook !== undefined ? savedProposal.imagesInBook : null),\n  imageCount: inputData.imageCount !== undefined ? inputData.imageCount : (savedProposal.imageCount !== undefined ? savedProposal.imageCount : null),\n  _topicSource: marketTopic ? 'market' : (suggestionTopic ? 'suggestion' : (savedProposal.topic ? 'saved' : (inputData.topic ? 'input' : 'none')))\n};\n\nconsole.log('[Merge Proposal] ===== MERGE PROPOSAL WITH MARKET DATA END =====');\nconsole.log('[Merge Proposal] ✅ Final Topic (Priorität: Market > Suggestion > Saved > Input):', mergedData.topic);\nconsole.log('[Merge Proposal] ✅ Final Thema:', mergedData.thema);\nconsole.log('[Merge Proposal] Topic Source:', mergedData._topicSource);\nconsole.log('[Merge Proposal] Chapter Count:', mergedData.chapterCount);\nconsole.log('[Merge Proposal] Words Per Chapter:', mergedData.wordsPerChapter);\nconsole.log('[Merge Proposal] Volume Number:', mergedData.volume_number);\nconsole.log('[Merge Proposal] ⚠️ WICHTIG: Diese Daten gehen an Telegram-Notification!');\n\nreturn [{ json: mergedData }];"},"id":"merge-proposal-with-chat-data","name":"Merge Proposal with Chat Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[816,288]},{"parameters":{"jsCode":"// Sicherstellen dass alle Daten für Telegram-Notification vorhanden sind\n// KRITISCH: Hole Topic von Trendanalyse (Intelligent Market Analysis), NICHT vom Chat-Input\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Proposal Data] ===== ENSURE PROPOSAL DATA FOR TELEGRAM START =====');\nconsole.log('[Ensure Proposal Data] Input Data keys:', Object.keys(inputData));\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (Trendanalyse) - HÖCHSTE PRIORITÄT\nlet marketTopic = null;\nlet marketChapterCount = null;\nlet marketWordsPerChapter = null;\n\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').first().json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  marketChapterCount = marketData.chapterCount !== null && marketData.chapterCount !== undefined ? marketData.chapterCount : null;\n  marketWordsPerChapter = marketData.wordsPerChapter !== null && marketData.wordsPerChapter !== undefined ? marketData.wordsPerChapter : null;\n  console.log('[Ensure Proposal Data] ✅ Topic von Intelligent Market Analysis:', marketTopic);\n  console.log('[Ensure Proposal Data] ✅ ChapterCount:', marketChapterCount);\n  console.log('[Ensure Proposal Data] ✅ WordsPerChapter:', marketWordsPerChapter);\n} catch (e) {\n  console.log('[Ensure Proposal Data] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Fallback: Hole von Generate E-Book Suggestions\nlet suggestionTopic = null;\nlet suggestionChapterCount = null;\nlet suggestionWordsPerChapter = null;\n\ntry {\n  const suggestionData = $('Generate E-Book Suggestions').first().json || {};\n  suggestionTopic = suggestionData.topic || suggestionData.thema || null;\n  suggestionChapterCount = suggestionData.chapterCount !== null && suggestionData.chapterCount !== undefined ? suggestionData.chapterCount : null;\n  suggestionWordsPerChapter = suggestionData.wordsPerChapter !== null && suggestionData.wordsPerChapter !== undefined ? suggestionData.wordsPerChapter : null;\n  console.log('[Ensure Proposal Data] ✅ Topic von Generate E-Book Suggestions:', suggestionTopic);\n} catch (e) {\n  console.log('[Ensure Proposal Data] ⚠️ Generate E-Book Suggestions not found:', e.message);\n}\n\n// Priorität: Market Topic (Trendanalyse) > Suggestion Topic > Input Data\nconst ensuredData = {\n  ...inputData,\n  topic: marketTopic || suggestionTopic || inputData.topic || inputData.thema || null,\n  thema: marketTopic || suggestionTopic || inputData.thema || inputData.topic || null,\n  chapterCount: marketChapterCount !== null ? marketChapterCount : (suggestionChapterCount !== null ? suggestionChapterCount : (inputData.chapterCount !== undefined && inputData.chapterCount !== null ? inputData.chapterCount : null)),\n  wordsPerChapter: marketWordsPerChapter !== null ? marketWordsPerChapter : (suggestionWordsPerChapter !== null ? suggestionWordsPerChapter : (inputData.wordsPerChapter !== undefined && inputData.wordsPerChapter !== null ? inputData.wordsPerChapter : null)),\n  volume_number: inputData.volume_number || 1,\n  approval_status: inputData.approval_status || 'pending'\n};\n\nconsole.log('[Ensure Proposal Data] ===== ENSURE PROPOSAL DATA FOR TELEGRAM END =====');\nconsole.log('[Ensure Proposal Data] ✅ Final Data:');\nconsole.log('  Topic (von Trendanalyse):', ensuredData.topic);\nconsole.log('  Thema:', ensuredData.thema);\nconsole.log('  ChapterCount:', ensuredData.chapterCount);\nconsole.log('  WordsPerChapter:', ensuredData.wordsPerChapter);\nconsole.log('  Volume Number:', ensuredData.volume_number);\nconsole.log('  Approval Status:', ensuredData.approval_status);\n\nreturn [{ json: ensuredData }];"},"id":"ensure-proposal-data-for-telegram","name":"Ensure Proposal Data for Telegram","type":"n8n-nodes-base.code","typeVersion":2,"position":[1040,288]},{"parameters":{"jsCode":"// Prepare Telegram Data\n// Extract data from input\nconst json = $input.json || {};\n\n// Ensure chatId is available\nconst chatId = json.chatId || json.telegramChatId || json.TELEGRAM_CHAT_ID || json.chat_id || '578345520';\n\n// Prepare output with all data, ensuring chatId is present\nconst output = {\n  ...json, // Keep all original data\n  chatId: chatId,\n  telegramChatId: chatId,\n  TELEGRAM_CHAT_ID: chatId\n};\n\n// Prepare checkpoint data for Supabase Node\n// This will be picked up by the next Supabase Node\nconst checkpointData = {\n  topic: json.topic || json.thema || 'Unbekannt',\n  thema: json.topic || json.thema || 'Unbekannt',\n  chapterCount: json.chapterCount || json.chapters || 0,\n  wordsPerChapter: json.wordsPerChapter || json.words_per_chapter || 0,\n  volume_number: json.volume_number || json.volumeNumber || 1,\n  approval_status: json.approval_status || json.status || 'pending',\n  proposalId: json.proposalId || json.id || json.proposal_id || null,\n  isbn: json.isbn || json.ISBN || null,\n  chatId: chatId,\n  genre: json.genre || null,\n  language: json.language || null,\n  target_audience: json.target_audience || null\n};\n\n// Add checkpoint data to output for Supabase Node\noutput.checkpointData = checkpointData;\noutput.checkpointType = 'proposal';\n\nreturn [{ json: output }];"},"id":"prepare-telegram-data","name":"Prepare Telegram Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[1440,288]},{"parameters":{"jsCode":"// Merge DeepSeek API Response mit Chat Input\n// KRITISCH: DeepSeek Intelligent Parse gibt nur die API-Antwort zurück, nicht den Chat-Input\n// Dieser Node fügt den Chat-Input explizit hinzu, damit Process DeepSeek Parse ihn verwenden kann\nconst apiResponse = $input.first().json || {};\n\nconsole.log('[Merge DeepSeek Response] ===== MERGE DEEPSEEK RESPONSE WITH CHAT INPUT START =====');\nconsole.log('[Merge DeepSeek Response] API Response keys:', Object.keys(apiResponse));\n\n// Hole Chat Input von Extract Chat Input\nlet chatInput = '';\ntry {\n  const extractData = $('Extract Chat Input').item.json || {};\n  chatInput = extractData.chatInput || extractData.message || '';\n  console.log('[Merge DeepSeek Response] ✅ Chat Input von Extract Chat Input:', chatInput);\n} catch (e) {\n  console.log('[Merge DeepSeek Response] Extract Chat Input not found, trying DeepSeek Chat Trigger');\n  // Fallback: DeepSeek Chat Trigger\n  try {\n    const triggerData = $('DeepSeek Chat Trigger').item.json || {};\n    chatInput = triggerData.chatInput || triggerData.message || '';\n    console.log('[Merge DeepSeek Response] ✅ Chat Input von DeepSeek Chat Trigger:', chatInput);\n  } catch (e2) {\n    console.log('[Merge DeepSeek Response] DeepSeek Chat Trigger not found');\n  }\n}\n\nif (!chatInput || chatInput.trim().length === 0) {\n  console.warn('[Merge DeepSeek Response] ⚠️ KEIN CHAT-INPUT GEFUNDEN!');\n}\n\n// Kombiniere API Response mit Chat Input\nconst mergedData = {\n  ...apiResponse,\n  // WICHTIG: Chat Input explizit hinzufügen\n  chatInput: chatInput,\n  message: chatInput\n};\n\nconsole.log('[Merge DeepSeek Response] ===== MERGE DEEPSEEK RESPONSE WITH CHAT INPUT END =====');\nconsole.log('[Merge DeepSeek Response] ✅ Chat Input hinzugefügt:', chatInput);\nconsole.log('[Merge DeepSeek Response] Merged Data keys:', Object.keys(mergedData));\n\nreturn [{ json: mergedData }];"},"id":"merge-deepseek-response-with-chat-input","name":"Merge DeepSeek Response with Chat Input","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2512,-368],"disabled":true},{"parameters":{"jsCode":"// Generiere ISBN-13 Nummer\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\n// Hole Topic für ISBN-Generierung\nconst topic = inputData.topic || inputData.thema || 'ebook';\nconst volumeNumber = inputData.volume_number || inputData.volumeNumber || 1;\n\n// Generiere eine eindeutige ISBN-13 basierend auf Topic und Volume\n// ISBN-13 Format: 978-3-XXXXX-XXX-X (978 = E-Book-Präfix, 3 = Deutschland)\n\n// Erstelle einen Hash aus Topic und Volume für Konsistenz\nfunction simpleHash(str) {\n  let hash = 0;\n  for (let i = 0; i < str.length; i++) {\n    const char = str.charCodeAt(i);\n    hash = ((hash << 5) - hash) + char;\n    hash = hash & hash; // Convert to 32bit integer\n  }\n  return Math.abs(hash);\n}\n\nconst hash = simpleHash(topic + volumeNumber.toString());\n\n// Generiere 9-stellige Nummer aus Hash\nconst baseNumber = (hash % 999999999).toString().padStart(9, '0');\n\n// ISBN-13 Präfix: 978-3 (E-Book, Deutschland)\nconst prefix = '9783';\nconst isbnWithoutCheck = prefix + baseNumber;\n\n// Berechne Prüfziffer (ISBN-13)\nlet sum = 0;\nfor (let i = 0; i < 12; i++) {\n  const digit = parseInt(isbnWithoutCheck[i]);\n  sum += digit * (i % 2 === 0 ? 1 : 3);\n}\nconst checkDigit = (10 - (sum % 10)) % 10;\nconst isbn13 = isbnWithoutCheck + checkDigit.toString();\n\n// Formatiere ISBN mit Bindestrichen: 978-3-XXXXX-XXX-X\nconst formattedISBN = `${isbn13.substring(0, 3)}-${isbn13.substring(3, 4)}-${isbn13.substring(4, 9)}-${isbn13.substring(9, 12)}-${isbn13.substring(12)}`;\n\n// Bereinige ISBN (nur Ziffern) für Dateinamen\nconst isbnClean = isbn13;\n\nconsole.log('[Generate ISBN] Topic:', topic);\nconsole.log('[Generate ISBN] Volume:', volumeNumber);\nconsole.log('[Generate ISBN] ISBN-13:', formattedISBN);\nconsole.log('[Generate ISBN] ISBN Clean:', isbnClean);\n\n// Kombiniere Input-Daten mit ISBN\nreturn {\n  json: {\n    ...inputData,\n    isbn: formattedISBN,\n    isbn13: isbn13,\n    isbnClean: isbnClean,\n    isbnGenerated: true\n  }\n};"},"id":"generate-isbn","name":"Generate ISBN","type":"n8n-nodes-base.code","typeVersion":2,"position":[656,128]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"// Validiere Cover-Größe und Dateiname\n// UND: Stelle sicher, dass alle relevanten Daten weitergegeben werden\n// WICHTIG: Im Modus 'Run Once for Each Item' ist $input direkt das aktuelle Item, kein Array!\n\n// Im 'Run Once for Each Item' Modus ist $input bereits das aktuelle Item\nconst json = $input.json || {};\nconst binary = $input.binary || {};\n\nconsole.log('[Validate Cover Size] ===== START =====');\nconsole.log('[Validate Cover Size] Input keys:', Object.keys(json));\n\n// Hole Cover-Daten\nconst coverBinary = binary.data || binary.cover || null;\nconst imageUrl = json.imageUrl || json.coverUrl || json.url || json.directory || '';\n\n// Generiere oder hole Dateiname\nlet filename = json.filename || json.fileName || 'cover.jpg';\n\n// Wenn kein Dateiname vorhanden, generiere einen basierend auf Title oder ID\nif (filename === 'cover.jpg') {\n  const title = json.title || json.proposal?.title || '';\n  const id = json.id || json.proposalId || json.proposal?.id || Date.now();\n  if (title) {\n    filename = title.toLowerCase().replace(/[^a-z0-9]/g, '-').substring(0, 50) + '.jpg';\n  } else {\n    filename = `cover-${id}.jpg`;\n  }\n}\n\n// Validiere Größe (wenn Binary vorhanden)\nlet isValidSize = true;\nlet sizeInfo = '';\nif (coverBinary) {\n  const sizeInBytes = coverBinary.data ? Buffer.from(coverBinary.data, 'base64').length : 0;\n  const sizeInMB = sizeInBytes / (1024 * 1024);\n  sizeInfo = `${sizeInMB.toFixed(2)} MB`;\n  \n  // Maximale Größe: 10 MB\n  if (sizeInMB > 10) {\n    isValidSize = false;\n    console.warn('[Validate Cover Size] ⚠️ Cover zu groß:', sizeInfo);\n  } else {\n    console.log('[Validate Cover Size] ✅ Cover-Größe OK:', sizeInfo);\n  }\n}\n\n// Hole ISBN und andere Metadaten aus dem Workflow-Kontext\n// Diese sollten durch die Nodes weitergegeben werden\nconst isbn = json.isbn || json.proposal?.isbn || json.ebook?.isbn || 'N/A';\nconst title = json.title || json.proposal?.title || 'E-Book';\nconst proposalId = json.proposalId || json.id || json.proposal?.id || '';\n\nconsole.log('[Validate Cover Size] Extracted:');\nconsole.log('  ISBN:', isbn);\nconsole.log('  Filename:', filename);\nconsole.log('  Size:', sizeInfo || 'N/A');\nconsole.log('  Valid:', isValidSize);\n\n// Output - WICHTIG: Alle Daten weitergeben!\nconst output = {\n  ...json, // Alle vorherigen Daten behalten\n  \n  // Cover-spezifische Daten\n  filename: filename,\n  fileName: filename, // Beide Varianten für Kompatibilität\n  coverFilename: filename,\n  \n  // Cover-Daten\n  imageUrl: imageUrl,\n  coverUrl: imageUrl,\n  \n  // Validierung\n  isValidSize: isValidSize,\n  sizeInfo: sizeInfo,\n  \n  // Metadaten (weitergeben!)\n  isbn: isbn,\n  title: title,\n  proposalId: proposalId,\n  \n  // Binary-Daten behalten (falls vorhanden)\n  ...(coverBinary && { hasBinary: true })\n};\n\nconsole.log('[Validate Cover Size] ===== END =====');\n\n// Return muss ein Array sein, auch im 'Run Once for Each Item' Modus\nreturn [{ json: output, binary: binary }];"},"id":"validate-cover-size","name":"Validate Cover Size & Filename","type":"n8n-nodes-base.code","typeVersion":2,"position":[128,768]},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.chat_id }}","text":"={{ $json.text || $json.message }}","additionalFields":{}},"id":"send-cover-for-validation","name":"Send Cover for Validation (Telegram)","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[592,768],"webhookId":"73790a04-d7d3-4e69-a748-7429274896ce","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const isbn = inputData.isbnClean || inputData.isbn || \"unknown\"; const topic = inputData.topic || inputData.thema || \"Unknown Topic\"; const volumeNumber = inputData.volume_number || 1; const title = inputData.title || topic; const author = \"Salomon F. Owona\"; const publisher = \"Owona Media\"; const publicationDate = new Date().toISOString().split(\"T\")[0]; const language = inputData.sprache || inputData.language || \"ger\"; const genre = inputData.genre || \"General\"; const competitivePrice = 4.99; const onixXML = `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ONIXMessage release=\"3.0\" xmlns=\"http://www.editeur.org/onix/3.0/reference\">\n  <Header>\n    <Sender>\n      <SenderName>${publisher}</SenderName>\n      <ContactName>OWONA Media</ContactName>\n      <EmailAddress>info@owona.de</EmailAddress>\n    </Sender>\n    <SentDateTime>${new Date().toISOString()}</SentDateTime>\n  </Header>\n  <Product>\n    <RecordReference>${isbn}</RecordReference>\n    <NotificationType>03</NotificationType>\n    <ProductIdentifier>\n      <ProductIDType>15</ProductIDType>\n      <IDValue>${isbn}</IDValue>\n    </ProductIdentifier>\n    <DescriptiveDetail>\n      <ProductComposition>00</ProductComposition>\n      <ProductForm>ED</ProductForm>\n      <TitleDetail>\n        <TitleType>01</TitleType>\n        <TitleElement>\n          <TitleElementLevel>01</TitleElementLevel>\n          <TitleText>${title}</TitleText>\n        </TitleElement>\n      </TitleDetail>\n      <Contributor>\n        <ContributorRole>A01</ContributorRole>\n        <PersonName>${author}</PersonName>\n      </Contributor>\n      <Language>\n        <LanguageCode>${language}</LanguageCode>\n      </Language>\n      <Subject>\n        <SubjectSchemeIdentifier>10</SubjectSchemeIdentifier>\n        <SubjectCode>${genre}</SubjectCode>\n      </Subject>\n    </DescriptiveDetail>\n    <PublishingDetail>\n      <Publisher>\n        <PublisherName>${publisher}</PublisherName>\n      </Publisher>\n      <PublishingDate>\n        <PublishingDateRole>01</PublishingDateRole>\n        <Date>${publicationDate}</Date>\n      </PublishingDate>\n    </PublishingDetail>\n    <ProductSupply>\n      <SupplyDetail>\n        <Price>\n          <PriceType>01</PriceType>\n          <PriceAmount>${competitivePrice.toFixed(2)}</PriceAmount>\n          <CurrencyCode>EUR</CurrencyCode>\n        </Price>\n      </SupplyDetail>\n    </ProductSupply>\n  </Product>\n</ONIXMessage>`; return { json: { ...inputData, onixFileName: isbn + \".xml\", onixContent: onixXML, onixNeedsValidation: true, competitivePrice: competitivePrice } };"},"id":"generate-onix-file","name":"Generate ONIX File","type":"n8n-nodes-base.code","typeVersion":2,"position":[544,1072]},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.chat_id }}","text":"={{ $json.text || $json.message }}","additionalFields":{}},"id":"send-onix-for-validation","name":"Send ONIX for Validation (Telegram)","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[1184,1072],"webhookId":"5c14b118-6a00-4907-a94a-db25c854bcb7","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const onixContent = inputData.onixContent || \"\"; const onixFileName = inputData.onixFileName || \"onix.xml\"; const binaryData = Buffer.from(onixContent, \"utf8\"); return { json: { ...inputData, onixFileName: onixFileName }, binary: { data: { data: binaryData.toString(\"base64\"), mimeType: \"application/xml\", fileName: onixFileName } } };"},"id":"convert-onix-to-binary","name":"Convert ONIX to Binary","type":"n8n-nodes-base.code","typeVersion":2,"position":[768,1072]},{"parameters":{"method":"POST","url":"http://151.236.35.202/upload","authentication":"basic","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/xml"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ $binary.data.data }}","options":{}},"id":"upload-to-epuboo","name":"Upload to epuboo (HTTP)","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1776,848],"disabled":true,"notes":"Host: 151.236.35.202\nUser: 1320@epuboo.com\nPass: uJm_p18aDq@l.H6\n\nDeaktiviert - kann später aktiviert werden.\nHinweis: Basic Auth muss in n8n Credentials konfiguriert werden."},{"parameters":{"method":"POST","url":"={{ 'https://ugsezgnkyhcmsdpohuwf.supabase.co/storage/v1/object/ebook-covers/' + ($json.onixFileName || ($json.isbnClean || $json.isbn || 'onix').replace(/[^a-zA-Z0-9]/g, '') + '.xml') }}","sendHeaders":true,"headerParameters":{"parameters":[{"name":"apikey","value":"={{ $('Load Secrets from Supabase').first().json.SUPABASE_ANON_KEY }}"},{"name":"Authorization","value":"=Bearer {{ $('Load Secrets from Supabase').first().json.SUPABASE_SERVICE_KEY }}"},{"name":"Content-Type","value":"application/xml"},{"name":"x-upsert","value":"true"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ Buffer.from($binary.data.data, \"base64\") }}","options":{}},"id":"upload-onix-to-supabase","name":"Upload ONIX to Supabase Storage","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1776,1072],"onError":"continueRegularOutput"},{"parameters":{"resume":"webhook","options":{}},"id":"wait-for-cover-approval","name":"Wait for Cover Approval","type":"n8n-nodes-base.wait","typeVersion":1.1,"position":[736,768],"webhookId":"e47d3fa9-6866-4efa-a14b-a0e5e4bb4e76","notes":"Wartet auf Telegram-Nachricht \"ja\" vom Benutzer. Webhook-URL wird generiert."},{"parameters":{"resume":"webhook","options":{}},"id":"wait-for-onix-approval","name":"Wait for ONIX Approval","type":"n8n-nodes-base.wait","typeVersion":1.1,"position":[1376,1072],"webhookId":"7f2b78c0-2908-4ad5-acbd-e103977f677a","notes":"Wartet auf Telegram-Nachricht \"ja\" vom Benutzer. Webhook-URL wird generiert."},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const binaryData = $input.item.binary || {}; const onixFileName = inputData.onixFileName || (inputData.isbnClean || inputData.isbn || \"onix\").replace(/[^a-zA-Z0-9]/g, \"\") + \".xml\"; let onixBinary = null; if (binaryData.data && binaryData.data.data) { onixBinary = binaryData.data; } else if (inputData.onixContent) { const buffer = Buffer.from(inputData.onixContent, \"utf8\"); onixBinary = { data: buffer.toString(\"base64\"), mimeType: \"application/xml\", fileName: onixFileName }; } return { json: { ...inputData, onixFileName: onixFileName }, binary: onixBinary ? { data: onixBinary } : binaryData };"},"id":"prepare-onix-upload","name":"Prepare ONIX for Upload","type":"n8n-nodes-base.code","typeVersion":2,"position":[1600,1072]},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const chapterText = inputData.chapterText || inputData.text || inputData.content || \"\"; const targetWords = inputData.wordsPerChapter || inputData.targetWords || 1000; const minWords = Math.floor(targetWords * 0.8); const wordCount = chapterText.trim().split(/\\s+/).filter(word => word.length > 0).length; const needsExtension = wordCount < minWords; const wordsNeeded = needsExtension ? minWords - wordCount : 0; return [{ json: { ...inputData, chapterText: chapterText, wordCount: wordCount, targetWords: targetWords, minWords: minWords, needsExtension: needsExtension, wordsNeeded: wordsNeeded } }];"},"id":"check-chapter-word-count","name":"Check Chapter Word Count","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2272,1072]},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict"},"conditions":[{"id":"1","leftValue":"={{ $json.needsExtension }}","rightValue":true,"operator":{"type":"boolean","operation":"true"}}],"combinator":"and"},"options":{}},"id":"check-needs-extension","name":"Check: Needs Extension?","type":"n8n-nodes-base.if","typeVersion":2,"position":[-2096,1072],"onError":"continueErrorOutput"},{"parameters":{"workflowId":"RgISyJGT9LvWYfSi","options":{}},"id":"extend-chapter-content","name":"Extend Chapter Content","type":"n8n-nodes-base.executeWorkflow","typeVersion":1,"position":[-1728,1008]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const inputData = $input.item.json || {}; const extendedText = inputData.chapterText || inputData.text || inputData.content || \"\"; const originalText = inputData.existingContent || \"\"; const mergedText = originalText + \"\\n\\n\" + extendedText; const wordCount = mergedText.trim().split(/\\s+/).filter(word => word.length > 0).length; return [{ json: { ...inputData, chapterText: mergedText, text: mergedText, content: mergedText, wordCount: wordCount, wasExtended: true } }];"},"id":"merge-extended-content","name":"Merge Extended Content","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1520,1008]},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const fullText = inputData.fullText || inputData.content || \"\"; const genre = inputData.genre || \"General\"; const topic = inputData.topic || inputData.thema || \"\"; const expertGuidance = { \"Business\": \"Nutze bewährte Business-Strategien, Fallstudien und praxisorientierte Methoden. Integriere Erkenntnisse erfolgreicher Unternehmer und Management-Experten.\", \"Technology\": \"Nutze aktuelle Technologietrends, Best Practices aus der Software-Entwicklung und Erkenntnisse führender Tech-Experten. Stelle technische Konzepte verständlich dar.\", \"Health\": \"Nutze evidenzbasierte Gesundheitsinformationen, wissenschaftliche Studien und Praktiken erfahrener Mediziner. Stelle medizinische Informationen verständlich und verantwortungsvoll dar.\", \"Self-Help\": \"Nutze bewährte Selbsthilfe-Techniken, psychologische Erkenntnisse und Methoden erfolgreicher Coaches. Fokussiere auf praktische Umsetzbarkeit.\", \"Fiction\": \"Nutze bewährte Erzähltechniken, Charakterentwicklung und Plot-Strukturen erfolgreicher Roman-Autoren. Erschaffe fesselnde und emotionale Geschichten.\", \"Education\": \"Nutze bewährte pädagogische Methoden, didaktische Ansätze und Erkenntnisse erfahrener Pädagogen. Strukturiere Inhalte lernfreundlich.\", \"General\": \"Nutze bewährte Kommunikationstechniken, Strukturierungsmethoden und Erkenntnisse erfolgreicher Sachbuch-Autoren. Stelle Informationen klar und ansprechend dar.\" }; const guidance = expertGuidance[genre] || expertGuidance[\"General\"]; const enhancementPrompt = `Als Experte für ${genre}-Inhalte, prüfe und verbessere den folgenden Text. ${guidance}\\n\\n**Text:**\\n${fullText.substring(0, 5000)}\\n\\n**Thema:** ${topic}\\n\\n**Aufgabe:**\\n- Prüfe die Qualität und Experten-Expertise\\n- Stelle sicher, dass der Text die Erfahrung der besten Autoren dieses Genres widerspiegelt\\n- Verbessere wo nötig, ohne den Stil zu ändern\\n- Gib NUR Verbesserungsvorschläge oder bestätige die Qualität`; return { json: { ...inputData, expertEnhancementPrompt: enhancementPrompt, genre: genre, expertGuidance: guidance } };"},"id":"expert-quality-enhancement","name":"Expert Quality Enhancement","type":"n8n-nodes-base.code","typeVersion":2,"position":[-640,768]},{"parameters":{"jsCode":"const allThemeAreas = [\"Business\", \"Technology\", \"Health\", \"Self-Help\", \"Fiction\", \"Education\", \"Science\", \"History\", \"Travel\", \"Cooking\", \"Sports\", \"Finance\", \"Relationships\", \"Parenting\", \"Career\", \"Marketing\", \"Design\", \"Photography\", \"Music\", \"Art\", \"Philosophy\", \"Psychology\", \"Spirituality\", \"Fitness\", \"Nutrition\", \"Environment\", \"Politics\", \"Law\", \"Real Estate\", \"Investing\"]; const triggerType = $input.first().json._triggerType || \"schedule\"; const lastUsedArea = $input.first().json._lastThemeArea || \"Business\"; const currentIndex = allThemeAreas.indexOf(lastUsedArea); const nextIndex = (currentIndex + 1) % allThemeAreas.length; const selectedArea = allThemeAreas[nextIndex]; const targetAudience = triggerType === \"schedule\" ? [\"young\", \"old\"] : [\"business\", \"private\"]; const style = triggerType === \"schedule\" ? \"professional\" : \"casual\"; return [{ json: { selectedThemeArea: selectedArea, allThemeAreas: allThemeAreas, targetAudience: targetAudience, style: style, _triggerType: triggerType, _lastThemeArea: selectedArea } }];"},"id":"rotate-theme-areas","name":"Rotate Theme Areas","type":"n8n-nodes-base.code","typeVersion":2,"position":[-880,304]},{"parameters":{"jsCode":"return [{ json: { _triggerType: \"schedule\", timestamp: new Date().toISOString() } }];"},"id":"mark-trigger-type-schedule","name":"Mark Trigger Type (Schedule)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-3376,-112]},{"parameters":{"jsCode":"return [{ json: { _triggerType: \"manual\", timestamp: new Date().toISOString() } }];"},"id":"mark-trigger-type-manual","name":"Mark Trigger Type (Manual)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-3360,64]},{"parameters":{"jsCode":"// Prepare Telegram Notification\n// Extract data from input - can come from multiple sources\nconst json = $input.json || {};\n\n// Try to get chatId from multiple possible sources\nconst chatId = json.chatId || json.telegramChatId || json.TELEGRAM_CHAT_ID || json.chat_id || '578345520';\n\n// Check if we have checkpoint data from Supabase Node\n// Supabase Node output structure: { json: { data: {...}, ... } }\nlet checkpointData = null;\n\n// Try to find checkpoint data in input (could be from Supabase Node)\nif (json.data && typeof json.data === 'object') {\n  // This is likely from Supabase Node\n  checkpointData = json.data;\n} else if (json.checkpointData) {\n  // This is from previous Code Node\n  checkpointData = json.checkpointData;\n}\n\n// Merge checkpoint data with input data (checkpoint has priority for missing values)\nconst mergedData = { ...json };\n\nif (checkpointData) {\n  // Remove nested 'data' wrapper if present\n  const actualData = checkpointData.data || checkpointData;\n  \n  if (!mergedData.topic || mergedData.topic === 'Unbekannt') {\n    mergedData.topic = actualData.topic || mergedData.topic;\n  }\n  if (!mergedData.thema || mergedData.thema === 'Unbekannt') {\n    mergedData.thema = actualData.thema || actualData.topic || mergedData.thema;\n  }\n  if (!mergedData.chapterCount || mergedData.chapterCount === 0) {\n    mergedData.chapterCount = actualData.chapterCount || mergedData.chapterCount;\n  }\n  if (!mergedData.wordsPerChapter || mergedData.wordsPerChapter === 0) {\n    mergedData.wordsPerChapter = actualData.wordsPerChapter || mergedData.wordsPerChapter;\n  }\n  if (!mergedData.volume_number) {\n    mergedData.volume_number = actualData.volume_number || mergedData.volume_number;\n  }\n  if (!mergedData.approval_status) {\n    mergedData.approval_status = actualData.approval_status || mergedData.approval_status;\n  }\n}\n\n// Extract proposal data - use merged data\nlet topic = mergedData.topic || mergedData.thema || mergedData.title || 'Unbekannt';\n\n// Volume number\nconst volumeNumber = mergedData.volume_number || mergedData.volumeNumber || mergedData.volume || 1;\n\n// Status\nconst status = mergedData.approval_status || mergedData.status || mergedData.approvalStatus || 'pending';\n\n// Chapter count\nlet chapterCount = mergedData.chapterCount || mergedData.chapters || 0;\nif (typeof chapterCount === 'string') {\n  chapterCount = parseInt(chapterCount) || 0;\n}\nif (Array.isArray(mergedData.chapters)) {\n  chapterCount = mergedData.chapters.length;\n}\n\n// Words per chapter\nlet wordsPerChapter = mergedData.wordsPerChapter || mergedData.words_per_chapter || 0;\nif (typeof wordsPerChapter === 'string') {\n  wordsPerChapter = parseInt(wordsPerChapter) || 0;\n}\n\n// Build telegram message\nconst telegramMessage = `📚 Neues E-Book Proposal erstellt:\n\nThema: ${topic}\nBand: ${volumeNumber}\nStatus: ${status}\n\nKapitel: ${chapterCount}\nWörter pro Kapitel: ${wordsPerChapter}\n\nThis message was sent automatically with n8n`;\n\n// Prepare output with all necessary fields\nconst output = {\n  ...mergedData, // Keep all merged data\n  chatId: chatId,\n  telegramChatId: chatId,\n  TELEGRAM_CHAT_ID: chatId,\n  text: telegramMessage,\n  message: telegramMessage,\n  telegramMessage: telegramMessage,\n  topic: topic,\n  thema: topic,\n  volume_number: volumeNumber,\n  chapterCount: chapterCount,\n  wordsPerChapter: wordsPerChapter\n};\n\nreturn [{ json: output }];"},"id":"prepare-telegram-notification","name":"Prepare Telegram Notification","type":"n8n-nodes-base.code","typeVersion":2,"position":[1760,288]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const inputData = $input.item.json || {}; const topic = inputData.topic || inputData.thema || \"N/A\"; const volumeNumber = inputData.volume_number || 1; const status = inputData.status || \"completed\"; const finalMessage = `✅ E-Book vollständig erstellt:\n\nThema: ${topic}\nBand: ${volumeNumber}\nStatus: ${status}\n\nThis message was sent automatically with n8n`; return { json: { ...inputData, finalTelegramMessage: finalMessage } };"},"id":"prepare-final-notification","name":"Prepare Final Notification","type":"n8n-nodes-base.code","typeVersion":2,"position":[1616,1280]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"// Bereite Telegram-Nachricht für Cover-Validierung vor\n// WICHTIG: Daten sollten von Upload Cover to Supabase Storage kommen\n// Im Modus \"Run Once for Each Item\" ist $input bereits das aktuelle Item\n\n// Im \"Run Once for Each Item\" Modus ist $input bereits das aktuelle Item, kein Array\nconst json = $input.json || {};\nconst binary = $input.binary || {};\n\nconsole.log('[Prepare Cover Validation] ===== START =====');\nconsole.log('[Prepare Cover Validation] All input keys:', Object.keys(json));\nconsole.log('[Prepare Cover Validation] Input sample:', JSON.stringify(json, null, 2).substring(0, 1000));\n\n// Hole ISBN - sollte durch Nodes weitergegeben worden sein\nlet isbn = json.isbn || \n            json.proposal?.isbn || \n            json.ebook?.isbn || \n            json.data?.isbn ||\n            'N/A';\n\n// Hole Dateiname - sollte von Validate Cover Size & Filename kommen\nlet filename = json.filename || \n               json.fileName || \n               json.coverFilename || \n               json.name ||\n               'cover.jpg';\n\n// Hole Cover-URL - Supabase Upload gibt eine public URL zurück\n// Prüfe verschiedene mögliche Felder\nlet coverImage = json.publicUrl || \n                 json.public_url || \n                 json.url || \n                 json.fullPath ||\n                 json.path ||\n                 json.coverUrl || \n                 json.cover_url || \n                 json.imageUrl || \n                 json.image_url ||\n                 json.directory ||\n                 '';\n\n// Wenn path vorhanden ist, konstruiere Supabase Storage URL\nif (!coverImage && json.path) {\n  const bucket = json.bucket || 'ebooks';\n  // Versuche aus JSON oder Environment zu holen\n  const supabaseUrl = json.supabaseUrl || 'https://ugsezgnkyhcmsdpohuwf.supabase.co';\n  coverImage = `${supabaseUrl}/storage/v1/object/public/${bucket}/${json.path}`;\n  console.log('[Prepare Cover Validation] Konstruierte Supabase URL:', coverImage);\n}\n\n// Hole weitere Metadaten\nconst title = json.title || json.proposal?.title || json.ebook?.title || 'E-Book';\nconst proposalId = json.proposalId || json.id || json.proposal?.id || '';\n\nconsole.log('[Prepare Cover Validation] Extracted values:');\nconsole.log('  ISBN:', isbn);\nconsole.log('  Filename:', filename);\nconsole.log('  Cover Image URL:', coverImage ? (coverImage.substring(0, 100) + '...') : 'NICHT GEFUNDEN');\nconsole.log('  Title:', title);\nconsole.log('  Proposal ID:', proposalId);\n\n// Formatiere Telegram-Nachricht\nconst telegramMessage = `📷 E-Book Cover zur Validierung:\n\nISBN: ${isbn}\nDateiname: ${filename}\n\nBitte antworten Sie mit ja zur Bestätigung.\n\n${coverImage ? `📸 Cover-Bild:\n${coverImage}` : '⚠️ Cover-Bild konnte nicht geladen werden'}\n\nDateiname: ${filename}\n\nBitte antworte mit \"Ja\" zum Fortfahren oder \"Nein\" zum Regenerieren.`;\n\n// Output für Telegram Node\nconst output = {\n  // Telegram sendMessage erwartet: chatId, text\n  chatId: json.chatId || json.telegramChatId || json.chat_id || undefined,\n  text: telegramMessage,\n  \n  // Speichere die extrahierten Werte für Debugging und spätere Nodes\n  isbn: isbn,\n  filename: filename,\n  coverImage: coverImage,\n  coverUrl: coverImage,\n  title: title,\n  proposalId: proposalId,\n  \n  // Alle Original-Daten behalten\n  ...(Object.keys(json).reduce((acc, key) => {\n    if (!['chatId', 'telegramChatId', 'chat_id', 'text'].includes(key)) {\n      acc[key] = json[key];\n    }\n    return acc;\n  }, {}))\n};\n\nconsole.log('[Prepare Cover Validation] ===== END =====');\n\nreturn [{ json: output }];"},"id":"prepare-cover-validation","name":"Prepare Cover Validation","type":"n8n-nodes-base.code","typeVersion":2,"position":[352,768]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const inputData = $input.item.json || {}; const isbn = inputData.isbnClean || inputData.isbn || \"N/A\"; const filename = inputData.onixFileName || \"onix.xml\"; const onixMessage = `📄 ONIX-Datei zur Validierung:\n\nISBN: ${isbn}\nDateiname: ${filename}\n\nBitte antworten Sie mit ja zur Bestätigung.`; return { json: { ...inputData, onixValidationMessage: onixMessage } };"},"id":"prepare-onix-validation","name":"Prepare ONIX Validation","type":"n8n-nodes-base.code","typeVersion":2,"position":[976,1072]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"// Check approval response\nconst response = ($input.item.json.body?.message?.text || '').toLowerCase();\nconst inputData = $input.item.json || {};\n\n// Preserve cover URL and filename from previous steps\nconst coverData = {\n  coverImageUrl: inputData.coverImageUrl,\n  coverImageFileName: inputData.coverImageFileName\n};\n\n// Check for approval\nif (response.includes('ja') || response.includes('yes') || response.includes('approved') || response.includes('ok')) {\n  // Approved - route to Output 0 (continue to PDF generation)\n  return { json: { ...inputData, ...coverData, _approved: true }, pairedItem: { item: 0, output: 0 } };\n} else {\n  // Rejected - route to Output 1 for regeneration\n  return { json: { ...inputData, ...coverData, _rejected: true }, pairedItem: { item: 0, output: 1 } };\n}"},"id":"0bc09476-652f-49ba-8c2a-1f916fd0e80a","name":"Check Cover Approval Response","type":"n8n-nodes-base.code","typeVersion":2,"position":[896,560],"onError":"continueErrorOutput"},{"parameters":{"jsCode":"// Prepare for cover regeneration with variation\nconst inputData = $input.item.json || {};\n\n// Note: Old cover is already uploaded to Supabase\n// We'll generate a new one and it will overwrite the old one with same ISBN filename\n\n// Add variation to the prompt\nconst variations = [\n  'alternative composition',\n  'different color scheme',\n  'varied perspective',\n  'modified layout',\n  'alternative style'\n];\n\nconst randomVariation = variations[Math.floor(Math.random() * variations.length)];\n\n// Modify the image generation parameters\nconst modifiedData = {\n  ...inputData,\n  textSummary: (inputData.textSummary || '') + '. ' + randomVariation,\n  regenerationAttempt: (inputData.regenerationAttempt || 0) + 1,\n  _regeneration: true\n};\n\nconsole.log('[Cover Regeneration] Attempt:', modifiedData.regenerationAttempt);\nconsole.log('[Cover Regeneration] Variation:', randomVariation);\nconsole.log('[Cover Regeneration] Old cover will be overwritten');\n\nreturn [{ json: modifiedData }];"},"id":"2f0feb95-52a0-43eb-9165-c515de693586","name":"Prepare Cover Regeneration","type":"n8n-nodes-base.code","typeVersion":2,"position":[1584,608]},{"parameters":{"tableId":"n8n_workflow_checkpoints","fieldsUi":{"fieldValues":[{"fieldId":"workflow_id","fieldValue":"={{ $workflow.id }}"},{"fieldId":"execution_id","fieldValue":"={{ $execution.id }}"},{"fieldId":"data","fieldValue":"={{ $json }}"}]}},"id":"save-proposal-checkpoint","name":"Save Proposal Checkpoint","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[1600,288],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"tableId":"n8n_workflow_checkpoints"},"id":"save-chapter-checkpoint","name":"Save Chapter Checkpoint","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-1504,768],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"tableId":"n8n_workflow_checkpoints"},"id":"save-full-ebook-checkpoint","name":"Save Full E-Book Checkpoint","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-704,768],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}}],"connections":{"Calculate Volume Number":{"main":[[{"node":"Rotate Theme Areas","type":"main","index":0}]]},"Generate E-Book Suggestions":{"main":[[{"node":"Set Volume Number & Title","type":"main","index":0}]]},"Set Volume Number & Title":{"main":[[{"node":"Save Market Analysis","type":"main","index":0}]]},"Save Market Analysis":{"main":[[{"node":"Extract E-Book Suggestions","type":"main","index":0}]]},"Send Telegram Notification":{"main":[[{"node":"Initialize Multi-Chapter Loop","type":"main","index":0}]]},"Initialize Multi-Chapter Loop":{"main":[[{"node":"Split Chapters (Sequential)","type":"main","index":0}]]},"Split Chapters (Sequential)":{"main":[[{"node":"Delay Between Chapters","type":"main","index":0}]]},"Delay Between Chapters":{"main":[[{"node":"Generate Chapter (Text Baustein V2)","type":"main","index":0}]]},"Generate Chapter (Text Baustein V2)":{"main":[[{"node":"Collect Chapter & Update Previous","type":"main","index":0}]]},"Collect Chapter & Update Previous":{"main":[[{"node":"Save Chapter Checkpoint","type":"main","index":0}]]},"Prepare Next Chapter":{"main":[[{"node":"Split Chapters (Sequential)","type":"main","index":0}]]},"Combine & Save Full E-Book":{"main":[[{"node":"Save Full E-Book Checkpoint","type":"main","index":0}]]},"Quality Check":{"main":[[{"node":"Generate Cover (Bild Baustein)","type":"main","index":0}]]},"Generate Cover (Bild Baustein)":{"main":[[{"node":"Convert Cover to Binary","type":"main","index":0}]]},"Upload Cover to Supabase Storage":{"main":[[{"node":"Prepare Cover Validation","type":"main","index":0}]]},"Create Professional PDF":{"main":[[{"node":"Create HTML Binary","type":"main","index":0}]]},"Create HTML Binary":{"main":[[{"node":"Generate ONIX File","type":"main","index":0}]]},"Upload PDF to Supabase Storage":{"main":[[{"node":"Save Full E-Book to DB","type":"main","index":0}]]},"Check: More Chapters?":{"true":[[{"node":"Combine & Save Full E-Book","type":"true","index":0}]],"false":[[{"node":"Prepare Next Chapter","type":"false","index":0}]]},"Convert Done to String":{"main":[[{"node":"Check: More Chapters?","type":"main","index":0}]]},"Check Existing E-Books (Duplikatsprüfung)":{"main":[[{"node":"Query Existing E-Books (Supabase)","type":"main","index":0}]]},"Filter Empty Proposals":{"main":[[{"node":"Add Volume Number to Proposal","type":"main","index":0}]]},"Normalize Query Result":{"main":[[{"node":"Calculate Volume Number","type":"main","index":0}]]},"Query Existing E-Books (Supabase)":{"main":[[{"node":"Ensure Query Item","type":"main","index":0}]]},"Ensure Query Item":{"main":[[{"node":"Normalize Query Result","type":"main","index":0}]]},"Load Secrets from Supabase":{"main":[[{"node":"Analyze Trends","type":"main","index":0},{"node":"DeepSeek Intelligent Parse","type":"main","index":0}]]},"Schedule Trigger":{"main":[[{"node":"Mark Trigger Type (Schedule)","type":"main","index":0}]]},"When clicking ‘Execute workflow’":{"main":[[{"node":"Mark Trigger Type (Manual)","type":"main","index":0}]]},"Fetch Secrets from Supabase":{"main":[[{"node":"Load Secrets from Supabase","type":"main","index":0}]]},"Add Volume Number to Proposal":{"main":[[{"node":"Create E-Book Proposals","type":"main","index":0}]]},"Extract E-Book Suggestions":{"main":[[{"node":"Split into Proposals","type":"main","index":0}]]},"Check: All Proposals Done?":{"true":[[{"node":"Send Telegram Notification","type":"main","index":0}]],"false":[[{"node":"Split into Proposals","type":"loop","index":0}]],"main":[[{"node":"Prepare Telegram Data","type":"main","index":0}],[{"node":"Send Telegram Notification","type":"main","index":0}]]},"Create E-Book Proposals":{"main":[[{"node":"Merge Proposal with Chat Data","type":"main","index":0},{"node":"Generate ISBN","type":"main","index":0}]]},"Split into Proposals":{"loop":[[{"node":"Filter Empty Proposals","type":"main","index":0}]],"main":[[{"node":"Check: All Proposals Done?","type":"main","index":0}],[{"node":"Filter Empty Proposals","type":"main","index":0}]]},"Update Chapter State":{"main":[[{"node":"Check: More Chapters?","type":"main","index":0}]]},"DeepSeek Chat Trigger":{"main":[[{"node":"Extract Chat Input","type":"main","index":0}]]},"Intelligent Market Analysis (MCP)":{"main":[[{"node":"Check Existing E-Books (Duplikatsprüfung)","type":"main","index":0},{"node":"DeepSeek Enhanced Analysis","type":"main","index":0}]]},"Merge Market Analysis Params":{"main":[[{"node":"Check Existing E-Books (Duplikatsprüfung)","type":"main","index":0}]]},"Process Analyze Trends Response":{"main":[[{"node":"Intelligent Market Analysis (MCP)","type":"main","index":0}]]},"Process DeepSeek Enhanced Response":{"main":[[{"node":"Merge Market Analysis Params","type":"main","index":0}]]},"Analyze Trends":{"main":[[{"node":"Ensure Analyze Trends Data","type":"main","index":0}]]},"Ensure Analyze Trends Data":{"main":[[{"node":"Process Analyze Trends Response","type":"main","index":0}]]},"DeepSeek Enhanced Analysis":{"main":[[{"node":"Ensure DeepSeek Enhanced Data","type":"main","index":0}]]},"Ensure DeepSeek Enhanced Data":{"main":[[{"node":"Process DeepSeek Enhanced Response","type":"main","index":0}]]},"Process DeepSeek Parse":{"main":[[{"node":"Check Existing E-Books (Duplikatsprüfung)","type":"main","index":0}]]},"Extract Chat Input":{"main":[[{"node":"Fetch Secrets from Supabase","type":"main","index":0}]]},"Merge Proposal with Chat Data":{"main":[[{"node":"Ensure Proposal Data for Telegram","type":"main","index":0}]]},"Ensure Proposal Data for Telegram":{"main":[[{"node":"Check: All Proposals Done?","type":"main","index":0}]]},"DeepSeek Intelligent Parse":{"main":[[{"node":"Merge DeepSeek Response with Chat Input","type":"main","index":0}]]},"Merge DeepSeek Response with Chat Input":{"main":[[{"node":"Process DeepSeek Parse","type":"main","index":0}]]},"Generate ISBN":{"main":[[{"node":"Merge Proposal with Chat Data","type":"main","index":0}]]},"Convert Cover to Binary":{"main":[[{"node":"Validate Cover Size & Filename","type":"main","index":0}]]},"Generate ONIX File":{"main":[[{"node":"Convert ONIX to Binary","type":"main","index":0}]]},"Upload ONIX to Supabase Storage":{"main":[[{"node":"Upload PDF to Supabase Storage","type":"main","index":0}]]},"Send Cover for Validation (Telegram)":{"main":[[{"node":"Wait for Cover Approval","type":"main","index":0}]]},"Wait for Cover Approval":{"main":[[{"node":"Check Cover Approval Response","type":"main","index":0}]]},"Send ONIX for Validation (Telegram)":{"main":[[{"node":"Wait for ONIX Approval","type":"main","index":0}]]},"Wait for ONIX Approval":{"main":[[{"node":"Prepare ONIX for Upload","type":"main","index":0}]]},"Prepare ONIX for Upload":{"main":[[{"node":"Upload to epuboo (HTTP)","type":"main","index":0},{"node":"Upload ONIX to Supabase Storage","type":"main","index":0}]]},"Check Chapter Word Count":{"main":[[{"node":"Check: Needs Extension?","type":"main","index":0}]]},"Check: Needs Extension?":{"main":[[{"node":"Extend Chapter Content","type":"main","index":0}],[{"node":"Update Chapter State","type":"main","index":0}]]},"Extend Chapter Content":{"main":[[{"node":"Merge Extended Content","type":"main","index":0}]]},"Merge Extended Content":{"main":[[{"node":"Update Chapter State","type":"main","index":0}]]},"Expert Quality Enhancement":{"main":[[{"node":"Quality Check","type":"main","index":0}]]},"Rotate Theme Areas":{"main":[[{"node":"Generate E-Book Suggestions","type":"main","index":0}]]},"Mark Trigger Type (Schedule)":{"main":[[{"node":"Fetch Secrets from Supabase","type":"main","index":0}]]},"Mark Trigger Type (Manual)":{"main":[[{"node":"Fetch Secrets from Supabase","type":"main","index":0}]]},"Prepare Telegram Data":{"main":[[{"node":"Save Proposal Checkpoint","type":"main","index":0}]]},"Prepare Telegram Notification":{"main":[[{"node":"Send Telegram Notification","type":"main","index":0}]]},"Save Full E-Book to DB":{"main":[[{"node":"Prepare Final Notification","type":"main","index":0}]]},"Prepare Final Notification":{"main":[[{"node":"Final Notification (Telegram)","type":"main","index":0}]]},"Validate Cover Size & Filename":{"main":[[{"node":"Upload Cover to Supabase Storage","type":"main","index":0}]]},"Prepare Cover Validation":{"main":[[{"node":"Send Cover for Validation (Telegram)","type":"main","index":0}]]},"Convert ONIX to Binary":{"main":[[{"node":"Prepare ONIX Validation","type":"main","index":0}]]},"Prepare ONIX Validation":{"main":[[{"node":"Send ONIX for Validation (Telegram)","type":"main","index":0}]]},"Check Cover Approval Response":{"main":[[{"node":"Create Professional PDF","type":"main","index":0}],[{"node":"Prepare Cover Regeneration","type":"main","index":0}]]},"Prepare Cover Regeneration":{"main":[[{"node":"Generate Cover (Bild Baustein)","type":"main","index":0}]]},"Save Proposal Checkpoint":{"main":[[{"node":"Prepare Telegram Notification","type":"main","index":0}]]}},"settings":{"executionOrder":"v1","saveDataErrorExecution":"all","saveDataSuccessExecution":"all","saveManualExecutions":true,"saveExecutionProgress":true,"callerPolicy":"workflowsFromSameOwner","availableInMCP":true},"staticData":{"node:Schedule Trigger":{"recurrenceRules":[]}},"meta":{"templateCredsSetupCompleted":true},"pinData":{},"versionId":"21efb13b-b41b-4b8f-8a44-9a7319d12183","activeVersionId":"21efb13b-b41b-4b8f-8a44-9a7319d12183","versionCounter":719,"triggerCount":1,"shared":[{"updatedAt":"2025-12-09T08:25:40.962Z","createdAt":"2025-12-09T08:25:40.962Z","role":"workflow:owner","workflowId":"gwd3P1NQMXjuWzQM","projectId":"ZTRFm4bAECULr2Vd","project":{"updatedAt":"2025-12-10T10:48:57.897Z","createdAt":"2025-12-04T04:10:14.452Z","id":"ZTRFm4bAECULr2Vd","name":"Unnamed Project","type":"personal","icon":null,"description":null,"projectRelations":[{"updatedAt":"2025-12-10T11:34:47.027Z","createdAt":"2025-12-10T11:34:47.027Z","userId":"d0ae2bc8-f28d-410f-a75d-c260f97b01fb","projectId":"ZTRFm4bAECULr2Vd","user":{"updatedAt":"2025-12-15T07:36:20.666Z","createdAt":"2025-12-10T11:02:26.714Z","id":"d0ae2bc8-f28d-410f-a75d-c260f97b01fb","email":"sm@owona.de","firstName":"salomon","lastName":"owona","personalizationAnswers":{"version":"v4","personalization_survey_submitted_at":"2025-12-10T11:36:51.350Z","personalization_survey_n8n_version":"1.122.5","companySize":"<20","companyType":"saas","role":"business-owner","reportedSource":"google"},"settings":{"easyAIWorkflowOnboarded":true,"firstSuccessfulWorkflowId":"gwd3P1NQMXjuWzQM","userActivated":true,"userActivatedAt":1765407624210,"npsSurvey":{"waitingForResponse":true,"ignoredCount":0,"lastShownAt":1765720150629}},"disabled":false,"mfaEnabled":false,"lastActiveAt":"2025-12-14","isPending":false}}]}}],"tags":[],"activeVersion":{"updatedAt":"2025-12-15T08:35:52.222Z","createdAt":"2025-12-15T08:35:52.222Z","versionId":"21efb13b-b41b-4b8f-8a44-9a7319d12183","workflowId":"gwd3P1NQMXjuWzQM","nodes":[{"parameters":{"rule":{"interval":[{"field":"cronExpression","expression":"* * * * *"}]}},"id":"schedule-trigger-v2","name":"Schedule Trigger","type":"n8n-nodes-base.scheduleTrigger","typeVersion":1.3,"position":[-3568,-112]},{"parameters":{"method":"POST","url":"https://api.deepseek.com/v1/chat/completions","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Authorization","value":"={{ $('Load Secrets from Supabase').first().json.DEEPSEEK_API_KEY ? 'Bearer ' + $('Load Secrets from Supabase').first().json.DEEPSEEK_API_KEY : 'Bearer sk-fd178bb87e1240b19786ce816c77d07f' }}"},{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ JSON.stringify({ model: 'deepseek-chat', messages: [{ role: 'system', content: 'Du bist ein Experte für Marktanalyse und E-Book-Trends. Analysiere aktuelle Topseller und Trends aus ALLEN Stilrichtungen (Fiction, Non-Fiction, Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch, Handwerk, Kreativ, Design) und ALLEN Bereichen (Business, Privat, Hobby, Bildung, Gesundheit, Finanzen, Technik, Lifestyle, Handwerk, Kreativität) für verschiedene Zielgruppen: JUNG und ALT, BUSINESS und PRIVAT. Identifiziere profitable E-Book-Themen im DACH-Markt mit hohem Marktpotenzial. Antworte IMMER im JSON-Format mit folgender Struktur: { trends: [{ topic: string (Thema des E-Books, z.B. \"Künstliche Intelligenz im Business\", \"Gesundheit für Senioren\", \"Handwerk für Privatpersonen\"), genre: string (Fiction, Non-Fiction, Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch, Handwerk, Kreativ), target_audience: string (z.B. \"Junge Erwachsene\", \"Senioren\", \"Unternehmer\", \"Privatpersonen\", \"Berufstätige\", \"Handwerker\", \"Kreative\"), popularity: number (1-10), reasoning: string (Warum ist dieses Thema profitabel? Welche Zielgruppe spricht es an?) }], market_insights: string (Zusammenfassung der Marktanalyse) }' }, { role: 'user', content: 'Analysiere die aktuellen E-Book-Topseller und Trends für den DACH-Markt im Jahr 2025. Überprüfe ALLE Stilrichtungen (Fiction, Non-Fiction, Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch, Handwerk, Kreativ, Design) und ALLE Bereiche (Business, Privat, Hobby, Bildung, Gesundheit, Finanzen, Technik, Lifestyle, Handwerk, Kreativität). Berücksichtige verschiedene Zielgruppen: JUNG und ALT, BUSINESS und PRIVAT. Identifiziere 5-7 profitable Themen mit hohem Marktpotenzial aus verschiedenen Kategorien. Fokussiere auf aktuelle Topseller und Trends. Stelle sicher, dass die Themen eine gute Mischung aus verschiedenen Stilrichtungen, Bereichen und Zielgruppen darstellen.' }], temperature: 0.7 }) }}","options":{}},"id":"analyze-trends-v2","name":"Analyze Trends","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[-3152,288],"alwaysOutputData":true,"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Verbesserte Duplikatsprüfung - FIXED VERSION\n// Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Verwendet Topic aus Chat Input, falls vorhanden\n// ERWEITERT: Funktioniert direkt mit Process DeepSeek Parse (intelligent geparst)\n// ERWEITERT: Leitet ALLE Daten weiter, auch wenn sie null sind\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nfunction extractTrendsData(aiResponse) {\n  try {\n    // DeepSeek Response-Struktur\n    if (aiResponse.choices?.[0]?.message?.content) {\n      const content = aiResponse.choices[0].message.content;\n      const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        const parsed = JSON.parse(jsonMatch[0]);\n        return {\n          trends: parsed.trends || [],\n          marketInsights: parsed.market_insights || '',\n          firstTopic: parsed.trends?.[0]?.topic || ''\n        };\n      }\n    }\n  } catch (e) {\n    console.error('[Check Existing] Parse error:', e);\n  }\n  \n  return {\n    trends: [],\n    marketInsights: '',\n    firstTopic: ''\n  };\n}\n\n// WICHTIG: Verwende Input-Daten (kann von Process DeepSeek Parse ODER Intelligent Market Analysis kommen)\nconst inputData = $input.item.json || {};\n\nconsole.log('[Check Existing] Input Data keys:', Object.keys(inputData));\nconsole.log('[Check Existing] Input Data chapterCount:', inputData.chapterCount);\nconsole.log('[Check Existing] Input Data wordsPerChapter:', inputData.wordsPerChapter);\nconsole.log('[Check Existing] Input Data topic:', inputData.topic);\n\n// ERWEITERT: Prüfe ob Input von Process DeepSeek Parse kommt (intelligent geparst)\nconst isFromDeepSeekParse = !!(inputData._fromDeepSeek || inputData._fromFallback || inputData.chatInput);\n\n// ERWEITERT: Prüfe ob Input direkt von Process DeepSeek Parse kommt\nconst isFromChatInput = isFromDeepSeekParse || !!(inputData.chatInput || (inputData.topic && (inputData.chapterCount !== undefined || inputData.wordsPerChapter !== undefined)));\n\n// NEU: Versuche Topic und Parameter aus Chat Input zu holen (hat Priorität)\nlet chatTopic = '';\nlet chatInputData = {};\n\nif (isFromChatInput || isFromDeepSeekParse) {\n  // Input kommt direkt von Process DeepSeek Parse oder Extract Chat Input\n  chatInputData = inputData;\n  chatTopic = inputData.topic || '';\n  console.log('[Check Existing] Input direkt von Process DeepSeek Parse/Extract Chat Input');\n  console.log('[Check Existing] Chat Topic:', chatTopic);\n  console.log('[Check Existing] Chat chapterCount:', chatInputData.chapterCount);\n  console.log('[Check Existing] Chat wordsPerChapter:', chatInputData.wordsPerChapter);\n} else {\n  // Input kommt von Marktanalyse - versuche Chat-Eingaben zu holen\n  try {\n    // Versuche zuerst Process DeepSeek Parse (intelligent geparst)\n    chatInputData = $('Process DeepSeek Parse').item.json || {};\n    chatTopic = chatInputData.topic || '';\n    console.log('[Check Existing] Process DeepSeek Parse gefunden:', chatTopic);\n    console.log('[Check Existing] Process DeepSeek Parse chapterCount:', chatInputData.chapterCount);\n    console.log('[Check Existing] Process DeepSeek Parse wordsPerChapter:', chatInputData.wordsPerChapter);\n  } catch (e) {\n    try {\n      // Fallback: Extract Chat Input\n      chatInputData = $('Extract Chat Input').item.json || {};\n      chatTopic = chatInputData.topic || '';\n      console.log('[Check Existing] Extract Chat Input gefunden:', chatTopic);\n    } catch (e2) {\n      console.log('[Check Existing] Extract Chat Input not found');\n    }\n  }\n}\n\n// Versuche Trends-Daten aus Input zu extrahieren (nur wenn nicht von Chat Input)\nlet trendsData = inputData;\n\nif (!isFromChatInput && !isFromDeepSeekParse) {\n  // Falls Input keine Trends-Daten enthält, versuche von Analyze Trends zu holen (Fallback)\n  if (!trendsData.choices && !trendsData.trends) {\n    try {\n      trendsData = $('Analyze Trends').item.json || inputData;\n    } catch (e) {\n      console.log('[Check Existing] Analyze Trends not found, using input data');\n      trendsData = inputData;\n    }\n  }\n  \n  const extracted = extractTrendsData(trendsData);\n  \n  // WICHTIG: Priorität: Chat Topic > Marktanalyse Topic\n  const finalTopic = chatTopic || extracted.firstTopic || '';\n  \n  console.log('[Check Existing] Chat Topic:', chatTopic);\n  console.log('[Check Existing] Market Analysis Topic:', extracted.firstTopic);\n  console.log('[Check Existing] Final Topic:', finalTopic);\n  console.log('[Check Existing] Has Topic:', !!finalTopic);\n  \n  // Kombiniere Input-Daten mit extrahierten Trends\n  // ERWEITERT: Füge Chat-Daten hinzu, falls vorhanden\n  return {\n    json: {\n      ...inputData,\n      ...trendsData,\n      // ERWEITERT: Füge Chat-Daten hinzu (auch wenn null)\n      topic: chatTopic || finalTopic || inputData.topic || null,\n      chapterCount: chatInputData.chapterCount !== undefined ? chatInputData.chapterCount : (inputData.chapterCount !== undefined ? inputData.chapterCount : null),\n      wordsPerChapter: chatInputData.wordsPerChapter !== undefined ? chatInputData.wordsPerChapter : (inputData.wordsPerChapter !== undefined ? inputData.wordsPerChapter : null),\n      textType: chatInputData.textType || inputData.textType || null,\n      coverImageType: chatInputData.coverImageType || inputData.coverImageType || null,\n      hasTopic: !!finalTopic,\n      trends: extracted.trends || inputData.trends || [],\n      marketInsights: extracted.marketInsights || inputData.marketInsights || inputData.market_insights || ''\n    }\n  };\n} else {\n  // Input kommt direkt von Process DeepSeek Parse/Extract Chat Input - verwende Chat-Daten direkt\n  const finalTopic = chatTopic || inputData.topic || null;\n  \n  console.log('[Check Existing] Direkt von Process DeepSeek Parse/Extract Chat Input');\n  console.log('[Check Existing] Final Topic:', finalTopic);\n  console.log('[Check Existing] Has Topic:', !!finalTopic);\n  console.log('[Check Existing] chapterCount:', inputData.chapterCount);\n  console.log('[Check Existing] wordsPerChapter:', inputData.wordsPerChapter);\n  \n  // ERWEITERT: Leite ALLE Chat-Daten weiter (auch wenn null)\n  return {\n    json: {\n      ...inputData, // WICHTIG: Behalte ALLE Daten vom Process DeepSeek Parse\n      topic: finalTopic,\n      hasTopic: !!finalTopic,\n      trends: [], // Keine Trends von Marktanalyse\n      marketInsights: '', // Keine Market Insights\n      _fromChatInput: true, // Flag für Debugging\n      _fromDeepSeekParse: isFromDeepSeekParse // Flag für Debugging\n    }\n  };\n}"},"id":"check-existing-ebooks","name":"Check Existing E-Books (Duplikatsprüfung)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1456,48]},{"parameters":{"jsCode":"// Vereinfachte Volume-Berechnung - FIXED VERSION\n// WICHTIG: Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\nconsole.log('[Volume Calc] Input Data keys:', Object.keys(inputData));\nconsole.log('[Volume Calc] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Volume Calc] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Trends-Daten aus Input zu holen\nlet trendsData = inputData;\n\n// Falls Input keine Trends-Daten enthält, versuche von Check Existing E-Books zu holen (Fallback)\nif (!trendsData.topic && !trendsData.trends) {\n  try {\n    trendsData = $('Check Existing E-Books (Duplikatsprüfung)').item.json || inputData;\n  } catch (e) {\n    console.log('[Volume Calc] Check Existing E-Books not found, using input data');\n    trendsData = inputData;\n  }\n}\n\n// Versuche normalisierte Daten zu holen\nlet normalizedData = {};\ntry {\n  normalizedData = $('Normalize Query Result').item.json || {};\n} catch (e) {\n  console.log('[Volume Calc] Normalize Query Result not found');\n  normalizedData = {};\n}\n\n// Hole maxVolume aus normalisierten Daten\nconst maxVolume = normalizedData.maxVolume || 0;\nconst nextVolumeNumber = maxVolume + 1;\nconst isContinuation = nextVolumeNumber > 1;\n\nconsole.log('[Volume Calc] Max:', maxVolume, 'Next:', nextVolumeNumber, 'Continuation:', isContinuation);\n\n// ERWEITERT: Kombiniere Input-Daten mit Volume-Daten und leite ALLE Daten weiter\nreturn {\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n    ...trendsData, // Behalte Trends-Daten\n    volumeNumber: nextVolumeNumber,\n    isContinuation: isContinuation,\n    maxExistingVolume: maxVolume,\n    querySuccess: normalizedData.querySuccess || false\n  }\n};"},"id":"calculate-volume-number","name":"Calculate Volume Number","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1040,304]},{"parameters":{"jsCode":"// Generiere E-Book-Vorschläge basierend auf Marktanalyse\n// WICHTIG: Topic hat höchste Priorität von Intelligent Market Analysis\n// ERWEITERT: Berücksichtigt Topseller aus allen Stilrichtungen und Bereichen\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\nconsole.log('[Generate Suggestions] ===== E-BOOK SUGGESTIONS GENERATION START =====');\nconsole.log('[Generate Suggestions] Input Data keys:', Object.keys(inputData));\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (hat IMMER Priorität)\nlet marketTopic = null;\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').item.json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  console.log('[Generate Suggestions] ✅ Topic von Intelligent Market Analysis:', marketTopic);\n} catch (e) {\n  console.log('[Generate Suggestions] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Hole Trends von Intelligent Market Analysis\nlet trends = [];\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').item.json || {};\n  trends = marketData.trends || inputData.trends || [];\n  console.log('[Generate Suggestions] ✅ Trends gefunden:', trends.length);\n} catch (e) {\n  console.log('[Generate Suggestions] ⚠️ Trends nicht gefunden, verwende Input-Daten');\n  trends = inputData.trends || [];\n}\n\n// WICHTIG: Topic-Priorität: Market Topic > Input Topic\nconst finalTopic = marketTopic || inputData.topic || inputData.thema || null;\n\nconsole.log('[Generate Suggestions] ✅ Final Topic (Market > Input):', finalTopic);\n\n// Erstelle E-Book-Vorschläge basierend auf Trends\n// WICHTIG: Wenn Topic vorhanden ist, verwende es als Basis\nlet suggestions = [];\n\nif (finalTopic && trends.length > 0) {\n  // Verwende Topic von Marktanalyse und kombiniere mit Trends\n  for (let i = 0; i < Math.min(trends.length, 5); i++) {\n    const trend = trends[i];\n    suggestions.push({\n      topic: trend.topic || finalTopic,\n      genre: trend.genre || 'non-fiction',\n      target_audience: trend.target_audience || 'Berufstätige und Unternehmer',\n      popularity: trend.popularity || 7,\n      reasoning: trend.reasoning || `Basierend auf Marktanalyse: ${finalTopic}`\n    });\n  }\n} else if (trends.length > 0) {\n  // Verwende nur Trends\n  for (let i = 0; i < Math.min(trends.length, 5); i++) {\n    const trend = trends[i];\n    suggestions.push({\n      topic: trend.topic || 'Aktuelle Markttrends',\n      genre: trend.genre || 'non-fiction',\n      target_audience: trend.target_audience || 'Berufstätige und Unternehmer',\n      popularity: trend.popularity || 7,\n      reasoning: trend.reasoning || 'Basierend auf Marktanalyse'\n    });\n  }\n} else if (finalTopic) {\n  // Fallback: Verwende Topic direkt\n  suggestions.push({\n    topic: finalTopic,\n    genre: 'non-fiction',\n    target_audience: 'Berufstätige und Unternehmer',\n    popularity: 7,\n    reasoning: 'Basierend auf Marktanalyse'\n  });\n} else {\n  // Letzter Fallback: Standard-Vorschlag\n  suggestions.push({\n    topic: 'Aktuelle Markttrends',\n    genre: 'non-fiction',\n    target_audience: 'Berufstätige und Unternehmer',\n    popularity: 7,\n    reasoning: 'Standard-Vorschlag basierend auf Marktanalyse'\n  });\n}\n\nconsole.log('[Generate Suggestions] ✅ Suggestions generiert:', suggestions.length);\nconsole.log('[Generate Suggestions] Suggestions:', suggestions.map(s => s.topic));\n\n// WICHTIG: Kombiniere Input-Daten mit Suggestions und Topic\nconst outputData = {\n  ...inputData,\n  // WICHTIG: Topic immer weiterleiten\n  topic: finalTopic,\n  thema: finalTopic,\n  // Suggestions\n  suggestions: suggestions,\n  // Für Kompatibilität\n  trends: trends\n};\n\nconsole.log('[Generate Suggestions] ===== E-BOOK SUGGESTIONS GENERATION END =====');\nconsole.log('[Generate Suggestions] ✅ Final Topic:', outputData.topic);\nconsole.log('[Generate Suggestions] ✅ Suggestions count:', outputData.suggestions.length);\n\nreturn { json: outputData }; // FIXED: Einzelnes Objekt zurückgeben statt Array"},"id":"generate-ebook-suggestions-v2","name":"Generate E-Book Suggestions","type":"n8n-nodes-base.code","typeVersion":2,"position":[-768,48]},{"parameters":{"jsCode":"// Setze Volume Number & Title basierend auf Duplikatsprüfung\n// WICHTIG: Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\n// WICHTIG: volume_number gehört NICHT zu ebook_market_analyses, sondern zu ebook_proposals\n// Dieser Node bereitet Daten für 'Save Market Analysis' vor, der in ebook_market_analyses speichert\n// volume_number wird später in 'Create E-Book Proposals' hinzugefügt\nconst inputData = $input.first().json || {};\n\nconsole.log('[Set Volume] Input Data keys:', Object.keys(inputData));\nconsole.log('[Set Volume] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Set Volume] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Volume-Daten zu holen\nlet volumeData = {};\ntry {\n  volumeData = $('Calculate Volume Number').item.json || {};\n} catch (e) {\n  console.log('[Set Volume] Calculate Volume Number not found, using input data');\n  volumeData = inputData;\n}\n\nconst volumeNumber = volumeData.volumeNumber || inputData.volumeNumber || 1;\nconst isContinuation = volumeData.isContinuation || false;\n\n// Erstelle sauberes Objekt für ebook_market_analyses (OHNE volume_number)\n// Nur Felder, die in ebook_market_analyses existieren:\n// - analysis_date\n// - data_sources\n// - trends\n// - niches\n// - ebook_suggestions\nconst marketAnalysisData = {\n  analysis_date: inputData.analysis_date || new Date().toISOString(),\n  data_sources: inputData.data_sources || {},\n  trends: inputData.trends || [],\n  niches: inputData.niches || [],\n  ebook_suggestions: inputData.ebook_suggestions || []\n};\n\n// volume_number wird NICHT gesendet (existiert nicht in ebook_market_analyses)\n// volume_number wird später in 'Create E-Book Proposals' hinzugefügt\n\n// ERWEITERT: Kombiniere Input-Daten mit Market Analysis Data und leite ALLE Daten weiter\nreturn [{\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n    ...marketAnalysisData, // Market Analysis Data\n    volumeNumber: volumeNumber, // Für spätere Verwendung\n    isContinuation: isContinuation // Für spätere Verwendung\n  }\n}];"},"id":"set-volume-number-title","name":"Set Volume Number & Title","type":"n8n-nodes-base.code","typeVersion":2,"position":[-592,48]},{"parameters":{"tableId":"ebook_market_analyses","fieldsUi":{"fieldValues":[{"fieldId":"analysis_date","fieldValue":"={{ $json.analysis_date }}"},{"fieldId":"data_sources","fieldValue":"={{ $json.data_sources }}"},{"fieldId":"trends","fieldValue":"={{ $json.trends }}"},{"fieldId":"niches","fieldValue":"={{ $json.niches }}"},{"fieldId":"ebook_suggestions","fieldValue":"={{ $json.ebook_suggestions }}"}]}},"id":"save-market-analysis","name":"Save Market Analysis","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-432,48],"alwaysOutputData":true,"retryOnFail":false,"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"options":{}},"id":"split-into-proposals-v2","name":"Split into Proposals","type":"n8n-nodes-base.splitInBatches","typeVersion":3,"position":[-48,48],"onError":"continueErrorOutput"},{"parameters":{"tableId":"ebook_proposals","fieldsUi":{"fieldValues":[{"fieldId":"topic","fieldValue":"={{ $json.topic }}"},{"fieldId":"genre","fieldValue":"={{ $json.genre }}"},{"fieldId":"language","fieldValue":"={{ $json.language }}"},{"fieldId":"target_audience","fieldValue":"={{ $json.target_audience }}"},{"fieldId":"length","fieldValue":"={{ $json.length }}"},{"fieldId":"volume_number","fieldValue":"={{ $json.volume_number }}"}]}},"id":"create-ebook-proposals-v2","name":"Create E-Book Proposals","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[480,288],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.TELEGRAM_CHAT_ID || $json.chat_id || \"578345520\" }}","text":"={{ $json.text || $json.message || $json.telegramMessage || \"No message content available\" }}","additionalFields":{}},"id":"send-telegram-notification-v2","name":"Send Telegram Notification","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[1936,128],"webhookId":"13082362-7fe7-48bf-b577-fe004a3c13c7","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Initialisiere Multi-Kapitel-Loop basierend auf Marktanalyse ODER Input-Daten\n// Priorität: Marktanalyse > Input-Daten > Fallback-Werte\n// KRITISCH: Hole Topic von Intelligent Market Analysis (Trendanalyse), NICHT vom Chat-Input\n// ERWEITERT: Dynamische Kapitel-Titel basierend auf Topic\nconst inputData = $input.first().json || {};\n\nconsole.log('[Init Loop] ===== INITIALIZE MULTI-CHAPTER LOOP START =====');\nconsole.log('[Init Loop] Input Data keys:', Object.keys(inputData));\nconsole.log('[Init Loop] Input Data chapterCount:', inputData.chapterCount);\nconsole.log('[Init Loop] Input Data wordsPerChapter:', inputData.wordsPerChapter);\nconsole.log('[Init Loop] Input Data topic:', inputData.topic);\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (Trendanalyse) - HÖCHSTE PRIORITÄT\nlet marketTopic = null;\nlet marketChapterCount = null;\nlet marketWordsPerChapter = null;\n\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').first().json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  marketChapterCount = marketData.chapterCount !== null && marketData.chapterCount !== undefined ? marketData.chapterCount : null;\n  marketWordsPerChapter = marketData.wordsPerChapter !== null && marketData.wordsPerChapter !== undefined ? marketData.wordsPerChapter : null;\n  console.log('[Init Loop] ✅ Intelligent Market Analysis gefunden');\n  console.log('[Init Loop] Market-Topic:', marketTopic);\n  console.log('[Init Loop] Market-ChapterCount:', marketChapterCount);\n  console.log('[Init Loop] Market-WordsPerChapter:', marketWordsPerChapter);\n} catch (e) {\n  console.log('[Init Loop] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Fallback: Hole von Generate E-Book Suggestions\nlet suggestionTopic = null;\nlet suggestionChapterCount = null;\nlet suggestionWordsPerChapter = null;\n\ntry {\n  const suggestionData = $('Generate E-Book Suggestions').first().json || {};\n  suggestionTopic = suggestionData.topic || suggestionData.thema || null;\n  suggestionChapterCount = suggestionData.chapterCount !== null && suggestionData.chapterCount !== undefined ? suggestionData.chapterCount : null;\n  suggestionWordsPerChapter = suggestionData.wordsPerChapter !== null && suggestionData.wordsPerChapter !== undefined ? suggestionData.wordsPerChapter : null;\n  console.log('[Init Loop] ✅ Generate E-Book Suggestions gefunden');\n  console.log('[Init Loop] Suggestion-Topic:', suggestionTopic);\n} catch (e) {\n  console.log('[Init Loop] ⚠️ Generate E-Book Suggestions not found');\n}\n\n// Versuche Marktanalyse-Parameter zu holen\nlet marketAnalysisParams = {};\ntry {\n  const marketData = $('Merge Market Analysis Params').first().json || {};\n  if (marketData.hasMarketAnalysisParams) {\n    marketAnalysisParams = {\n      textType: marketData.textType,\n      coverImageType: marketData.coverImageType,\n      chapterCount: marketData.chapterCount,\n      wordsPerChapter: marketData.wordsPerChapter,\n      totalWords: marketData.totalWords\n    };\n    console.log('[Init Loop] Found market analysis params');\n    console.log('[Init Loop] Market Analysis chapterCount:', marketAnalysisParams.chapterCount);\n    console.log('[Init Loop] Market Analysis wordsPerChapter:', marketAnalysisParams.wordsPerChapter);\n  }\n} catch (e) {\n  console.log('[Init Loop] Market analysis params not found');\n}\n\n// Versuche Daten von verschiedenen Quellen zu holen\nlet proposalData = {};\n\n// Fall 1: Input-Daten enthalten Proposal-Informationen (von Send Telegram Notification)\nif (inputData.topic || inputData.volume_number) {\n  proposalData = inputData;\n  console.log('[Init Loop] Using Input Data as Proposal Data');\n}\n// Fall 2: Versuche von 'Create E-Book Proposals' zu holen (wenn ausgeführt)\nelse {\n  try {\n    proposalData = $('Create E-Book Proposals').first().json || {};\n    console.log('[Init Loop] Create E-Book Proposals gefunden');\n  } catch (e) {\n    console.log('[Init Loop] Create E-Book Proposals not executed, using input data');\n    proposalData = inputData;\n  }\n}\n\n// WICHTIG: Topic-Priorität: Market Topic (Trendanalyse) > Suggestion Topic > Proposal > Input\nconst topic = marketTopic || suggestionTopic || proposalData.topic || inputData.topic || null;\nconst genre = proposalData.genre || inputData.genre || 'non-fiction';\nconst targetAudience = proposalData.target_audience || inputData.target_audience || 'Berufstaetige und Unternehmer';\nconst proposalId = proposalData.id || inputData.id || '';\nconst volumeNumber = proposalData.volume_number || inputData.volume_number || 1;\n\nconsole.log('[Init Loop] Topic-Priorität:');\nconsole.log('  Market-Topic (Intelligent Market Analysis):', marketTopic || '(nicht vorhanden)');\nconsole.log('  Suggestion-Topic (Generate E-Book Suggestions):', suggestionTopic || '(nicht vorhanden)');\nconsole.log('  Proposal Topic:', proposalData.topic || '(nicht vorhanden)');\nconsole.log('  Input Topic:', inputData.topic || '(nicht vorhanden)');\nconsole.log('  ✅ Final Topic:', topic || '(KEIN TOPIC)');\n\n// Bestimme E-Book-Parameter: Priorität Market > Input > Fallback\nlet chapterCount, wordsPerChapter, totalTargetWords, coverImageType, textType;\n\nif (marketChapterCount !== null && marketWordsPerChapter !== null) {\n  // Marktanalyse-Parameter haben höchste Priorität\n  chapterCount = marketChapterCount;\n  wordsPerChapter = marketWordsPerChapter;\n  coverImageType = inputData.coverImageType || null;\n  textType = inputData.textType || null;\n  console.log('[Init Loop] Using Market Analysis parameters (highest priority)');\n} else if (suggestionChapterCount !== null && suggestionWordsPerChapter !== null) {\n  // Suggestion-Parameter\n  chapterCount = suggestionChapterCount;\n  wordsPerChapter = suggestionWordsPerChapter;\n  coverImageType = inputData.coverImageType || null;\n  textType = inputData.textType || null;\n  console.log('[Init Loop] Using Suggestion parameters');\n} else if (inputData.chapterCount !== undefined && inputData.chapterCount !== null && \n    inputData.wordsPerChapter !== undefined && inputData.wordsPerChapter !== null) {\n  // Input-Daten direkt\n  chapterCount = inputData.chapterCount;\n  wordsPerChapter = inputData.wordsPerChapter;\n  coverImageType = inputData.coverImageType || null;\n  textType = inputData.textType || null;\n  console.log('[Init Loop] Using Input Data parameters');\n} else if (marketAnalysisParams.chapterCount !== undefined && marketAnalysisParams.chapterCount !== null && \n           marketAnalysisParams.wordsPerChapter !== undefined && marketAnalysisParams.wordsPerChapter !== null) {\n  // Marktanalyse-Parameter (von Merge Market Analysis Params)\n  chapterCount = marketAnalysisParams.chapterCount;\n  wordsPerChapter = marketAnalysisParams.wordsPerChapter;\n  coverImageType = marketAnalysisParams.coverImageType || null;\n  textType = marketAnalysisParams.textType || null;\n  console.log('[Init Loop] Using Market Analysis Params');\n} else {\n  // FIXED: Verwende Fallback-Werte statt Fehler zu werfen\n  console.warn('[Init Loop] ⚠️ KEINE E-BOOK-PARAMETER GEFUNDEN - Verwende Fallback-Werte');\n  \n  // Fallback-Werte: Standard E-Book-Parameter\n  chapterCount = 5;\n  wordsPerChapter = 500;\n  coverImageType = null;\n  textType = null;\n  console.log('[Init Loop] Using Fallback Values:', { chapterCount, wordsPerChapter });\n}\n\ntotalTargetWords = chapterCount * wordsPerChapter;\n\nconsole.log('[Init Loop] Final Parameters:');\nconsole.log('  ✅ Topic:', topic);\nconsole.log('  Chapter Count:', chapterCount);\nconsole.log('  Words Per Chapter:', wordsPerChapter);\nconsole.log('  Total Target Words:', totalTargetWords);\nconsole.log('  Cover Image Type:', coverImageType);\nconsole.log('  Text Type:', textType);\n\n// ERWEITERT: Dynamische Kapitel-Titel basierend auf Topic\n// Generiere themenspezifische Kapitel-Titel (nicht mehr hardcodiert)\nconst chapters = [];\nfor (let i = 1; i <= chapterCount; i++) {\n  let title = '';\n  let description = '';\n  \n  // Generiere themenspezifische Titel basierend auf Topic\n  if (topic) {\n    if (i === 1) {\n      title = `Kapitel 1: Einführung in ${topic}`;\n      description = `Einführung in das Thema ${topic}, Problemstellung, Relevanz für die Zielgruppe`;\n    } else if (i === 2) {\n      title = `Kapitel 2: Grundlagen von ${topic}`;\n      description = `Grundlegende Konzepte und Definitionen zu ${topic}, theoretischer Hintergrund`;\n    } else if (i === chapterCount) {\n      title = `Kapitel ${i}: Fazit zu ${topic}`;\n      description = `Zusammenfassung der wichtigsten Punkte zu ${topic}, Handlungsempfehlungen, Ausblick`;\n    } else {\n      title = `Kapitel ${i}: ${topic} - Praktische Anwendung`;\n      description = `Praktische Ansätze und Methoden zu ${topic}, Schritt-für-Schritt-Anleitungen`;\n    }\n  } else {\n    // Fallback nur wenn kein Topic vorhanden\n    if (i === 1) {\n      title = 'Kapitel 1: Einleitung';\n      description = 'Einführung in das Thema';\n    } else if (i === 2) {\n      title = 'Kapitel 2: Grundlagen';\n      description = 'Grundlegende Konzepte und Definitionen';\n    } else if (i === chapterCount) {\n      title = `Kapitel ${i}: Fazit`;\n      description = 'Zusammenfassung der wichtigsten Punkte';\n    } else {\n      title = `Kapitel ${i}: Praktische Anwendung`;\n      description = 'Praktische Ansätze und Methoden';\n    }\n  }\n  \n  chapters.push({\n    chapterNumber: i,\n    title: title,\n    targetWords: wordsPerChapter,\n    description: description\n  });\n}\n\nconsole.log('[Init Loop] ===== INITIALIZE MULTI-CHAPTER LOOP END =====');\nconsole.log('[Init Loop] ✅ Generated', chapters.length, 'chapters');\nconsole.log('[Init Loop] ✅ First Chapter Topic:', topic);\n\nreturn chapters.map(chapter => ({\n  json: {\n    ...chapter,\n    topic: topic, // WICHTIG: Verwendet Market-Topic (Trendanalyse)\n    genre: genre,\n    target_audience: targetAudience,\n    proposal_id: proposalId,\n    volume_number: volumeNumber,\n    previousChapters: [],\n    totalTargetWords: totalTargetWords,\n    minWordCount: totalTargetWords,\n    wordsPerChapter: wordsPerChapter,\n    coverImageType: coverImageType,\n    textType: textType\n  }\n}));"},"id":"init-multi-chapter-loop-v2","name":"Initialize Multi-Chapter Loop","type":"n8n-nodes-base.code","typeVersion":2,"position":[2096,288]},{"parameters":{"options":{}},"id":"split-chapters-sequential-v2","name":"Split Chapters (Sequential)","type":"n8n-nodes-base.splitInBatches","typeVersion":3,"position":[-2304,768],"onError":"continueErrorOutput"},{"parameters":{},"id":"delay-between-chapters-v2","name":"Delay Between Chapters","type":"n8n-nodes-base.wait","typeVersion":1.1,"position":[-2064,768],"webhookId":"45196287-7eff-449d-870e-051183a5a654"},{"parameters":{"workflowId":{"__rl":true,"value":"RgISyJGT9LvWYfSi","mode":"list","cachedResultUrl":"/workflow/RgISyJGT9LvWYfSi","cachedResultName":"Text Baustein V2"},"workflowInputs":{"mappingMode":"defineBelow","value":{},"matchingColumns":[],"schema":[],"attemptToConvertTypes":false,"convertFieldsToString":true},"options":{}},"id":"generate-chapter-text-baustein-v2","name":"Generate Chapter (Text Baustein V2)","type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[-1856,768]},{"parameters":{"jsCode":"// Collect Chapter & Update Previous\n// Collects generated chapters\n\nconst json = $input.json || {};\nconst binary = $input.binary || {};\n\n// Extract chapter data\nconst chapterData = {\n  chapterText: json.chapterText || json.text || json.content || '',\n  chapterTitle: json.chapterTitle || json.title || 'Kapitel',\n  chapterNumber: json.chapterNumber || json.number || 1,\n  wordCount: json.wordCount || json.words || 0\n};\n\n// Get existing chapters from previous iterations (if any)\nconst existingChapters = json.chapters || json.chapterArray || json.collectedChapters || [];\n\n// Add current chapter\nconst allChapters = [...existingChapters, chapterData];\n\n// Prepare output\nconst output = {\n  ...json,\n  chapters: allChapters,\n  chapterArray: allChapters,\n  collectedChapters: allChapters,\n  chapterCount: allChapters.length,\n  currentChapter: chapterData,\n  // Prepare checkpoint data for Supabase Node\n  checkpointData: {\n    chapters: allChapters,\n    chapterCount: allChapters.length,\n    lastChapter: chapterData\n  },\n  checkpointType: 'chapter'\n};\n\nreturn [{ json: output, binary: binary }];"},"id":"collect-chapter-v2","name":"Collect Chapter & Update Previous","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1648,768]},{"parameters":{"jsCode":"// Aktualisiere previousChapters für nächstes Kapitel\n// WICHTIG: done muss als Boolean zurückgegeben werden, nicht als String\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// ERWEITERT: Topic-Feld-Konsistenz (topic ↔ thema)\nconst chapterData = $input.first().json || {};\nconst currentChapters = chapterData.previousChapters || [];\n\nconsole.log('[Update Chapter State] ===== UPDATE CHAPTER STATE START =====');\nconsole.log('[Update Chapter State] Topic:', chapterData.topic || chapterData.thema);\nconsole.log('[Update Chapter State] Chapter Number:', chapterData.chapterNumber);\nconsole.log('[Update Chapter State] Previous Chapters count:', currentChapters.length);\n\n// Hole Split In Batches Context für done-Status\nconst splitContext = $('Split Chapters (Sequential)').context || {};\nconst done = splitContext.noItemsLeft === true;\n\n// WICHTIG: Topic normalisieren (topic ↔ thema)\nconst topic = chapterData.topic || chapterData.thema || '';\n\n// Füge aktuelles Kapitel zu previousChapters hinzu\nconst updatedPreviousChapters = [\n  ...currentChapters,\n  {\n    chapterNumber: chapterData.chapterNumber,\n    title: chapterData.title,\n    content: chapterData.content,\n    wordCount: chapterData.wordCount\n  }\n];\n\nconst result = {\n  ...chapterData,\n  previousChapters: updatedPreviousChapters,\n  done: done,  // WICHTIG: Boolean, nicht String\n  // WICHTIG: Beide Felder setzen für Konsistenz\n  topic: topic,\n  thema: topic\n};\n\nconsole.log('[Update Chapter State] ===== UPDATE CHAPTER STATE END =====');\nconsole.log('[Update Chapter State] ✅ Final Topic:', result.topic);\nconsole.log('[Update Chapter State] Updated Previous Chapters count:', result.previousChapters.length);\nconsole.log('[Update Chapter State] Done:', result.done);\n\nreturn [{\n  json: result\n}];"},"id":"update-chapter-state-v2","name":"Update Chapter State","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1328,1136]},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict","version":1},"conditions":[{"id":"check-done","leftValue":"={{ $json.done.toBoolean() }}","rightValue":true,"operator":{"type":"boolean","operation":"equals"}}],"combinator":"and"},"options":{}},"id":"check-more-chapters-v2","name":"Check: More Chapters?","type":"n8n-nodes-base.if","typeVersion":2,"position":[-1008,960]},{"parameters":{"jsCode":"// Bereite nächstes Kapitel vor (für Loop-Rückführung)\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// ERWEITERT: Topic-Feld-Konsistenz (topic ↔ thema)\nconst chapterData = $input.first().json || {};\n\nconsole.log('[Prepare Next Chapter] ===== PREPARE NEXT CHAPTER START =====');\nconsole.log('[Prepare Next Chapter] Topic:', chapterData.topic || chapterData.thema);\nconsole.log('[Prepare Next Chapter] Chapter Number:', chapterData.chapterNumber);\n\n// WICHTIG: Topic normalisieren (topic ↔ thema)\nconst topic = chapterData.topic || chapterData.thema || '';\n\n// Die previousChapters wurden bereits aktualisiert\n// Jetzt müssen wir zurück zu Split Chapters (Sequential)\n// Der Split In Batches Node wird automatisch das nächste Kapitel ausgeben\n\nconst result = {\n  ...chapterData,\n  readyForNextChapter: true,\n  // WICHTIG: Beide Felder setzen für Konsistenz\n  topic: topic,\n  thema: topic\n};\n\nconsole.log('[Prepare Next Chapter] ===== PREPARE NEXT CHAPTER END =====');\nconsole.log('[Prepare Next Chapter] ✅ Final Topic:', result.topic);\n\nreturn [{ json: result }];"},"id":"prepare-next-chapter-v2","name":"Prepare Next Chapter","type":"n8n-nodes-base.code","typeVersion":2,"position":[-720,1088]},{"parameters":{"jsCode":"// Combine & Save Full E-Book\n// This node combines all chapters and prepares the full ebook data\n// Also prepares checkpoint data for Supabase Node\n// FIXED: Sicherstellt, dass immer ein Objekt zurückgegeben wird (nie primitiver Wert)\n\ntry {\n  // Get input data - handle all edge cases safely\n  let json = {};\n  let binary = {};\n  \n  // Safely extract input data\n  if ($input && typeof $input === 'object') {\n    if ($input.json && typeof $input.json === 'object') {\n      json = $input.json;\n    } else if (Array.isArray($input) && $input.length > 0) {\n      json = $input[0].json || {};\n      binary = $input[0].binary || {};\n    } else if (typeof $input.item === 'object' && $input.item.json) {\n      json = $input.item.json || {};\n      binary = $input.item.binary || {};\n    }\n  }\n  \n  // Ensure json is an object, never null or undefined\n  if (!json || typeof json !== 'object' || Array.isArray(json)) {\n    json = {};\n  }\n  \n  // Ensure binary is an object if present\n  if (binary && typeof binary !== 'object') {\n    binary = {};\n  }\n  \n  // Extract chapter data and other necessary fields\n  let chapters = json.chapters || json.chapterArray || json.collectedChapters || [];\n  if (!Array.isArray(chapters)) {\n    chapters = [];\n  }\n  \n  const fullText = json.fullText || json.combinedText || json.text || '';\n  \n  // Extract proposal/ebook metadata\n  const proposalId = json.proposalId || json.id || json.proposal_id || null;\n  const isbn = json.isbn || json.ISBN || null;\n  const title = json.title || json.topic || json.thema || 'E-Book';\n  const topic = json.topic || json.thema || title || 'E-Book';\n  const volumeNumber = json.volume_number || json.volumeNumber || json.volume || 1;\n  \n  // Calculate chapter count safely\n  let chapterCount = 0;\n  if (Array.isArray(chapters)) {\n    chapterCount = chapters.length;\n  } else if (json.chapterCount && typeof json.chapterCount === 'number') {\n    chapterCount = json.chapterCount;\n  }\n  \n  // Combine all chapters into full text if not already combined\n  let combinedText = fullText || '';\n  if (!combinedText && Array.isArray(chapters) && chapters.length > 0) {\n    combinedText = chapters\n      .map(function(ch, idx) {\n        if (!ch || typeof ch !== 'object') {\n          return '';\n        }\n        const chapterText = ch.chapterText || ch.text || ch.content || '';\n        const chapterTitle = ch.chapterTitle || ch.title || 'Kapitel ' + (idx + 1);\n        return '# ' + chapterTitle + '\\n\\n' + (chapterText || '');\n      })\n      .filter(function(text) { return text.length > 0; })\n      .join('\\n\\n---\\n\\n');\n  }\n  \n  // Prepare output data object - ALWAYS an object\n  const output = {};\n  \n  // Copy all original data safely\n  for (const key in json) {\n    if (json.hasOwnProperty(key)) {\n      try {\n        output[key] = json[key];\n      } catch (e) {\n        // Skip problematic keys\n        console.log('[Combine & Save] Skipped key:', key, e.message);\n      }\n    }\n  }\n  \n  // Set combined ebook data\n  output.fullText = combinedText || '';\n  output.combinedText = combinedText || '';\n  output.text = combinedText || '';\n  \n  // Set chapter information\n  output.chapters = chapters;\n  output.chapterArray = chapters;\n  output.collectedChapters = chapters;\n  output.chapterCount = chapterCount;\n  \n  // Set metadata\n  output.proposalId = proposalId;\n  output.isbn = isbn;\n  output.title = title || 'E-Book';\n  output.topic = topic || 'E-Book';\n  output.thema = topic || 'E-Book';\n  output.volume_number = volumeNumber;\n  output.volumeNumber = volumeNumber;\n  \n  // Set status flags\n  output.isCombined = true;\n  output.readyForQualityCheck = true;\n  \n  // Set timestamp\n  output.combinedAt = new Date().toISOString();\n  \n  // Prepare checkpoint data for Supabase Node\n  output.checkpointData = {\n    fullText: combinedText || '',\n    chapters: chapters,\n    chapterCount: chapterCount,\n    proposalId: proposalId,\n    isbn: isbn,\n    title: title || 'E-Book',\n    topic: topic || 'E-Book',\n    volumeNumber: volumeNumber\n  };\n  output.checkpointType = 'full_ebook';\n  \n  // Prepare return object - ALWAYS return an array with objects\n  const returnItem = { json: output };\n  \n  // Include binary data if present and valid\n  if (binary && typeof binary === 'object' && !Array.isArray(binary)) {\n    const binaryKeys = Object.keys(binary);\n    if (binaryKeys.length > 0) {\n      returnItem.binary = binary;\n    }\n  }\n  \n  // FIXED: Always return array with object, never primitive\n  return [returnItem];\n  \n} catch (error) {\n  // Error handling - return error information instead of crashing\n  // ALWAYS return an object in an array, never primitive\n  const errorOutput = {\n    error: true,\n    errorMessage: error.message || String(error) || 'Unknown error',\n    errorType: error.name || 'UnknownError',\n    isCombined: false,\n    readyForQualityCheck: false\n  };\n  \n  // Try to keep original data if available\n  try {\n    if ($input && typeof $input === 'object') {\n      let inputJson = {};\n      if ($input.json && typeof $input.json === 'object') {\n        inputJson = $input.json;\n      } else if (Array.isArray($input) && $input.length > 0 && $input[0].json) {\n        inputJson = $input[0].json || {};\n      } else if ($input.item && $input.item.json) {\n        inputJson = $input.item.json || {};\n      }\n      \n      // Copy safe properties\n      for (const key in inputJson) {\n        if (inputJson.hasOwnProperty(key)) {\n          try {\n            errorOutput[key] = inputJson[key];\n          } catch (e) {\n            // Skip problematic keys\n          }\n        }\n      }\n    }\n  } catch (e) {\n    // Ignore errors when trying to preserve input data\n    console.log('[Combine & Save] Error preserving input data:', e.message);\n  }\n  \n  // FIXED: Always return array with object, never primitive\n  return [{ json: errorOutput }];\n}"},"id":"combine-save-full-ebook-v2","name":"Combine & Save Full E-Book","type":"n8n-nodes-base.code","typeVersion":2,"position":[-848,768]},{"parameters":{"jsCode":"// Quality Check (Spelling, Plagiarism, SEO)\n// Verwendet dynamische Mindest-Wortanzahl aus Chat-Eingaben ODER Marktanalyse\nconst ebookData = $input.first().json || {};\nconst totalWordCount = ebookData.totalWordCount || 0;\nconst fullContent = ebookData.fullContent || '';\n\n// Hole Mindest-Wortanzahl und Mindest-Kapitelanzahl: Priorität Chat > Marktanalyse > Standard\nlet MIN_WORD_COUNT = 1500; // Fallback\nlet MIN_CHAPTERS = 3; // Fallback\n\n// Versuche Chat-Eingaben\nlet chatInputData = {};\ntry {\n  chatInputData = $('Extract Chat Input').item.json || {};\n  if (chatInputData.chapterCount && chatInputData.wordsPerChapter) {\n    MIN_WORD_COUNT = chatInputData.chapterCount * chatInputData.wordsPerChapter;\n    MIN_CHAPTERS = chatInputData.chapterCount;\n    console.log('[Quality Check] Using Chat Input parameters');\n  }\n} catch (e) {\n  // Versuche Marktanalyse\n  try {\n    const marketData = $('Merge Market Analysis Params').item.json || {};\n    if (marketData.chapterCount && marketData.wordsPerChapter) {\n      MIN_WORD_COUNT = marketData.chapterCount * marketData.wordsPerChapter;\n      MIN_CHAPTERS = marketData.chapterCount;\n      console.log('[Quality Check] Using Market Analysis parameters');\n    }\n  } catch (e2) {\n    // Fallback: Verwende minWordCount aus ebookData\n    MIN_WORD_COUNT = ebookData.min_word_count || ebookData.minWordCount || 1500;\n    MIN_CHAPTERS = (ebookData.chapters || []).length || 3;\n    console.log('[Quality Check] Using E-Book Data parameters');\n  }\n}\n\n// Basis-Quality-Checks\nconst checks = {\n  wordCount: {\n    passed: totalWordCount >= MIN_WORD_COUNT,\n    actual: totalWordCount,\n    required: MIN_WORD_COUNT,\n    message: totalWordCount >= MIN_WORD_COUNT \n      ? `Wortanzahl OK: ${totalWordCount} Wörter` \n      : `Wortanzahl zu niedrig: ${totalWordCount} < ${MIN_WORD_COUNT}`\n  },\n  contentLength: {\n    passed: fullContent.length > 0,\n    actual: fullContent.length,\n    required: 1,\n    message: fullContent.length > 0 ? 'Inhalt vorhanden' : 'Kein Inhalt'\n  },\n  chapters: {\n    passed: (ebookData.chapters || []).length >= MIN_CHAPTERS,\n    actual: (ebookData.chapters || []).length,\n    required: MIN_CHAPTERS,\n    message: (ebookData.chapters || []).length >= MIN_CHAPTERS \n      ? `Kapitel OK: ${(ebookData.chapters || []).length} Kapitel` \n      : `Zu wenige Kapitel: ${(ebookData.chapters || []).length} < ${MIN_CHAPTERS}`\n  }\n};\n\nconst allPassed = Object.values(checks).every(check => check.passed);\n\nreturn [{\n  json: {\n    ...ebookData,\n    quality_check: allPassed ? 'PASSED' : 'REJECTED',\n    quality_checks: checks,\n    overall: {\n      status: allPassed ? 'success' : 'error',\n      message: allPassed ? 'Alle Quality Checks bestanden' : 'Quality Checks fehlgeschlagen'\n    }\n  }\n}];"},"id":"quality-check-v2","name":"Quality Check","type":"n8n-nodes-base.code","typeVersion":2,"position":[-464,768]},{"parameters":{"workflowId":{"__rl":true,"value":"cK5mek0by9ihHGDI","mode":"list","cachedResultUrl":"/workflow/cK5mek0by9ihHGDI","cachedResultName":"Bild Baustein"},"workflowInputs":{"mappingMode":"defineBelow","value":{},"matchingColumns":[],"schema":[],"attemptToConvertTypes":false,"convertFieldsToString":true},"options":{}},"id":"generate-cover-bild-baustein-v2","name":"Generate Cover (Bild Baustein)","type":"n8n-nodes-base.executeWorkflow","typeVersion":1.3,"position":[-256,768]},{"parameters":{"jsCode":"// Konvertiere Cover-Bild von Bild Baustein zu Binary\n// FIXED: Generate Cover gibt Daten im dritten Output-Array zurück (output[2])\n// WICHTIG: Prüfe alle Input-Items und Output-Arrays\nconst allInputs = $input.all();\n\nconsole.log('[Convert Cover] ===== CONVERT COVER TO BINARY START =====');\nconsole.log('[Convert Cover] Input items count:', allInputs.length);\n\n// WICHTIG: Generate Cover gibt Daten in verschiedenen Output-Arrays zurück\n// Prüfe alle Input-Items systematisch\nlet bildBausteinOutput = null;\nlet inputData = {};\n\n// Durchsuche alle Input-Items\nfor (let i = 0; i < allInputs.length; i++) {\n  const item = allInputs[i];\n  const json = item.json || {};\n  const binary = item.binary || {};\n  \n  console.log(`[Convert Cover] Input item ${i}:`);\n  console.log(`  JSON keys:`, Object.keys(json));\n  console.log(`  Binary keys:`, Object.keys(binary));\n  console.log(`  Has bestImage:`, !!json.bestImage);\n  console.log(`  Has allImages:`, !!json.allImages);\n  console.log(`  Has imageUrl:`, !!json.imageUrl);\n  console.log(`  Status:`, json.status);\n  \n  // Prüfe ob dieses Item Bild-Daten enthält\n  if (json.bestImage && Object.keys(json.bestImage).length > 0) {\n    bildBausteinOutput = json;\n    console.log(`[Convert Cover] ✅ Bild-Daten in Input item ${i} gefunden (bestImage)`);\n    break;\n  }\n  \n  if (json.allImages && Array.isArray(json.allImages) && json.allImages.length > 0) {\n    bildBausteinOutput = json;\n    console.log(`[Convert Cover] ✅ Bild-Daten in Input item ${i} gefunden (allImages)`);\n    break;\n  }\n  \n  if (json.imageUrl || json.url) {\n    bildBausteinOutput = json;\n    console.log(`[Convert Cover] ✅ Bild-Daten in Input item ${i} gefunden (imageUrl)`);\n    break;\n  }\n  \n  // Prüfe Binary-Daten\n  if (binary.data && binary.data.data) {\n    bildBausteinOutput = { ...json, _hasBinary: true, binary: binary };\n    console.log(`[Convert Cover] ✅ Binary-Daten in Input item ${i} gefunden`);\n    break;\n  }\n  \n  // Fallback: Verwende erstes Item mit Daten\n  if (Object.keys(json).length > 0 && !inputData.topic) {\n    inputData = json;\n  }\n}\n\n// Wenn keine Bild-Daten in Input gefunden, versuche von Generate Cover Node zu holen\nif (!bildBausteinOutput || (!bildBausteinOutput.bestImage && !bildBausteinOutput.allImages && !bildBausteinOutput.imageUrl && !bildBausteinOutput._hasBinary)) {\n  console.log('[Convert Cover] ⚠️ Keine Bild-Daten in Input gefunden, versuche von Generate Cover Node');\n  \n  try {\n    // Generate Cover gibt Daten im dritten Output-Array zurück\n    // Versuche alle Output-Arrays zu prüfen\n    const generateCoverOutputs = $('Generate Cover (Bild Baustein)').all();\n    console.log('[Convert Cover] Generate Cover outputs count:', generateCoverOutputs.length);\n    \n    for (let i = 0; i < generateCoverOutputs.length; i++) {\n      const output = generateCoverOutputs[i];\n      const json = output.json || {};\n      \n      console.log(`[Convert Cover] Generate Cover output ${i} keys:`, Object.keys(json));\n      \n      if (json.bestImage || json.allImages || json.imageUrl || json.status === 'success') {\n        bildBausteinOutput = json;\n        console.log(`[Convert Cover] ✅ Daten von Generate Cover Node output ${i} geholt`);\n        break;\n      }\n    }\n  } catch (e) {\n    console.log('[Convert Cover] ⚠️ Generate Cover Node nicht gefunden:', e.message);\n  }\n}\n\n// Wenn immer noch keine Daten, verwende Input-Daten\nif (!bildBausteinOutput && Object.keys(inputData).length > 0) {\n  bildBausteinOutput = inputData;\n  console.log('[Convert Cover] ⚠️ Verwende Input-Daten als Fallback');\n}\n\n// Wenn immer noch keine Daten, erstelle leeres Objekt\nif (!bildBausteinOutput) {\n  bildBausteinOutput = {};\n  console.warn('[Convert Cover] ⚠️ KEINE INPUT-DATEN GEFUNDEN!');\n  console.warn('[Convert Cover] Alle Input-Items:', allInputs.map((item, i) => ({ \n    index: i, \n    jsonKeys: Object.keys(item.json || {}),\n    binaryKeys: Object.keys(item.binary || {})\n  })));\n}\n\n// Hole auch E-Book-Daten von Quality Check (falls vorhanden)\nlet ebookData = {};\ntry {\n  ebookData = $('Quality Check').first().json || {};\n  console.log('[Convert Cover] ✅ E-Book-Daten von Quality Check geholt');\n} catch (e) {\n  console.log('[Convert Cover] ⚠️ Quality Check Node nicht gefunden');\n  // Fallback: Verwende Input-Daten\n  ebookData = inputData;\n}\n\nconsole.log('[Convert Cover] Bild Baustein Output keys:', Object.keys(bildBausteinOutput));\nconsole.log('[Convert Cover] bestImage:', bildBausteinOutput.bestImage);\nconsole.log('[Convert Cover] allImages:', bildBausteinOutput.allImages);\nconsole.log('[Convert Cover] imageUrl:', bildBausteinOutput.imageUrl);\nconsole.log('[Convert Cover] status:', bildBausteinOutput.status);\nconsole.log('[Convert Cover] Has Binary:', bildBausteinOutput._hasBinary);\n\n// Prüfe zuerst Binary-Daten (höchste Priorität)\nif (bildBausteinOutput._hasBinary && bildBausteinOutput.binary && bildBausteinOutput.binary.data) {\n  const binaryData = bildBausteinOutput.binary.data;\n  const base64Data = binaryData.data || '';\n  const mimeType = binaryData.mimeType || 'image/jpeg';\n  \n  if (base64Data) {\n    console.log('[Convert Cover] ✅ Binary-Daten gefunden, verwende direkt');\n    \n    // Erstelle Dateiname\n    const topic = (ebookData.topic || ebookData.thema || 'ebook').replace(/[^a-zA-Z0-9]/g, '-');\n    const volumeNumber = ebookData.volume_number || 1;\n    const fileExtension = mimeType.includes('png') ? 'png' : 'jpg';\n    const fileName = `cover-${topic}-${volumeNumber}.${fileExtension}`;\n    \n    console.log('[Convert Cover] ===== CONVERT COVER TO BINARY END =====');\n    console.log('[Convert Cover] ✅ Binary-Daten direkt verwendet');\n    console.log('[Convert Cover] File Name:', fileName);\n    \n    return [{\n      json: {\n        ...ebookData,\n        ...bildBausteinOutput,\n        ...inputData,\n        coverImageUrl: `data:${mimeType};base64,${base64Data}`,\n        coverImageMimeType: mimeType,\n        coverImageSize: Buffer.from(base64Data, 'base64').length,\n        coverImageFileName: fileName\n      },\n      binary: {\n        data: {\n          data: base64Data,\n          mimeType: mimeType,\n          fileName: fileName\n        }\n      }\n    }];\n  }\n}\n\n// Extrahiere Bild-URL vom Bild Baustein\n// Prüfe verschiedene mögliche Felder\nlet imageUrl = bildBausteinOutput.bestImage?.imageUrl || \n               bildBausteinOutput.bestImage?.url ||\n               bildBausteinOutput.imageUrl || \n               bildBausteinOutput.url ||\n               '';\n\n// Prüfe auch in allImages Array\nif (!imageUrl && Array.isArray(bildBausteinOutput.allImages) && bildBausteinOutput.allImages.length > 0) {\n  const firstImage = bildBausteinOutput.allImages[0];\n  imageUrl = firstImage.imageUrl || firstImage.url || '';\n  console.log('[Convert Cover] ✅ Bild-URL aus allImages Array gefunden:', imageUrl);\n}\n\n// Wenn immer noch keine URL, prüfe ob es Base64-Daten gibt\nif (!imageUrl) {\n  const base64Data = bildBausteinOutput.bestImage?.base64 || \n                    bildBausteinOutput.base64 ||\n                    bildBausteinOutput.imageData ||\n                    '';\n  \n  if (base64Data) {\n    // Konvertiere Base64 zu Data URL\n    const mimeType = bildBausteinOutput.bestImage?.mimeType || 'image/jpeg';\n    imageUrl = `data:image/${mimeType.replace('image/', '')};base64,${base64Data}`;\n    console.log('[Convert Cover] ✅ Base64-Daten gefunden, konvertiert zu Data URL');\n  }\n}\n\n// Wenn immer noch keine Bild-Daten vorhanden, gib Warnung zurück aber stoppe nicht den Workflow\nif (!imageUrl && !bildBausteinOutput._hasBinary) {\n  console.warn('[Convert Cover] ⚠️ KEIN COVER-BILD GEFUNDEN!');\n  console.warn('[Convert Cover] Bild Baustein Output:', JSON.stringify(bildBausteinOutput, null, 2));\n  console.warn('[Convert Cover] Input Data:', JSON.stringify(inputData, null, 2));\n  \n  // Gib Daten weiter, aber ohne Binary-Daten\n  return [{\n    json: {\n      ...ebookData,\n      ...bildBausteinOutput,\n      ...inputData,\n      coverImageUrl: null,\n      coverImageMimeType: null,\n      coverImageSize: 0,\n      coverImageError: 'Kein Cover-Bild von Bild Baustein erhalten',\n      coverImageNeedsDownload: false\n    }\n  }];\n}\n\nconsole.log('[Convert Cover] ✅ Bild-URL gefunden:', imageUrl.substring(0, 100));\n\n// Wenn Base64 Data URL, extrahiere die Daten\nlet imageData = null;\nif (imageUrl.startsWith('data:image/')) {\n  const base64Match = imageUrl.match(/data:image\\/([^;]+);base64,(.+)/);\n  if (base64Match) {\n    const mimeType = base64Match[1];\n    const base64Data = base64Match[2];\n    imageData = Buffer.from(base64Data, 'base64');\n    \n    console.log('[Convert Cover] ✅ Base64-Daten extrahiert');\n    console.log('[Convert Cover] MIME Type:', mimeType);\n    console.log('[Convert Cover] Image Size:', imageData.length, 'bytes');\n    \n    // Erstelle Dateiname\n    const topic = (ebookData.topic || ebookData.thema || 'ebook').replace(/[^a-zA-Z0-9]/g, '-');\n    const volumeNumber = ebookData.volume_number || 1;\n    const fileExtension = mimeType === 'png' ? 'png' : 'jpg';\n    const fileName = `cover-${topic}-${volumeNumber}.${fileExtension}`;\n    \n    console.log('[Convert Cover] ===== CONVERT COVER TO BINARY END =====');\n    console.log('[Convert Cover] ✅ Binary-Daten erstellt');\n    console.log('[Convert Cover] File Name:', fileName);\n    \n    return [{\n      json: {\n        ...ebookData,\n        ...bildBausteinOutput,\n        ...inputData,\n        coverImageUrl: imageUrl,\n        coverImageMimeType: `image/${mimeType}`,\n        coverImageSize: imageData.length,\n        coverImageFileName: fileName\n      },\n      binary: {\n        data: {\n          data: base64Data,\n          mimeType: `image/${mimeType}`,\n          fileName: fileName\n        }\n      }\n    }];\n  }\n}\n\n// Falls HTTP URL, muss später heruntergeladen werden\nconsole.log('[Convert Cover] ⚠️ HTTP URL erkannt, muss später heruntergeladen werden');\nconsole.log('[Convert Cover] ===== CONVERT COVER TO BINARY END =====');\n\nreturn [{\n  json: {\n    ...ebookData,\n    ...bildBausteinOutput,\n    ...inputData,\n    coverImageUrl: imageUrl,\n    coverImageMimeType: 'image/jpeg',\n    coverImageNeedsDownload: true\n  }\n}];"},"id":"convert-cover-to-binary-v2","name":"Convert Cover to Binary","type":"n8n-nodes-base.code","typeVersion":2,"position":[-64,768]},{"parameters":{"method":"POST","url":"={{ $json.supabaseUrl || 'https://ugsezgnkyhcmsdpohuwf.supabase.co/storage/v1/object/ebooks/' + ($json.filename || 'cover.jpg') }}","sendHeaders":true,"specifyHeaders":"json","sendBody":true,"contentType":"binaryData","options":{"response":{"response":{"fullResponse":true}}}},"id":"upload-cover-to-supabase-v2","name":"Upload Cover to Supabase Storage","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1040,816],"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Erstelle professionelles PDF aus E-Book-Inhalt\n// Vereinfachte Version: Erstellt HTML, das später zu PDF konvertiert werden kann\nconst ebookData = $input.first().json || {};\nconst fullContent = ebookData.fullContent || '';\nconst topic = ebookData.topic || 'E-Book';\nconst volumeNumber = ebookData.volume_number || 1;\nconst coverImageUrl = ebookData.coverImageUrl || '';\n\n// Erstelle HTML-Struktur für PDF\nconst htmlContent = `<!DOCTYPE html>\n<html lang=\"de\">\n<head>\n  <meta charset=\"UTF-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n  <title>${topic} - Band ${volumeNumber}</title>\n  <style>\n    @page {\n      size: A4;\n      margin: 2cm;\n    }\n    body {\n      font-family: 'Georgia', 'Times New Roman', serif;\n      line-height: 1.6;\n      color: #333;\n      max-width: 800px;\n      margin: 0 auto;\n      padding: 20px;\n    }\n    .cover {\n      text-align: center;\n      margin-bottom: 40px;\n      page-break-after: always;\n    }\n    .cover img {\n      max-width: 100%;\n      height: auto;\n      margin-bottom: 20px;\n    }\n    .cover h1 {\n      font-size: 2.5em;\n      margin: 20px 0;\n      color: #2c3e50;\n    }\n    .cover .subtitle {\n      font-size: 1.2em;\n      color: #7f8c8d;\n      margin-top: 10px;\n    }\n    h1, h2, h3 {\n      color: #2c3e50;\n      margin-top: 30px;\n      margin-bottom: 15px;\n    }\n    h1 {\n      font-size: 2em;\n      border-bottom: 2px solid #3498db;\n      padding-bottom: 10px;\n    }\n    h2 {\n      font-size: 1.5em;\n    }\n    h3 {\n      font-size: 1.2em;\n    }\n    p {\n      margin-bottom: 15px;\n      text-align: justify;\n    }\n    .chapter-separator {\n      page-break-before: always;\n      border-top: 3px solid #3498db;\n      margin-top: 40px;\n      padding-top: 20px;\n    }\n  </style>\n</head>\n<body>\n  <div class=\"cover\">\n    ${coverImageUrl ? `<img src=\"${coverImageUrl}\" alt=\"Cover\" />` : ''}\n    <h1>${topic}</h1>\n    ${volumeNumber > 1 ? `<div class=\"subtitle\">Band ${volumeNumber}</div>` : ''}\n  </div>\n  \n  ${fullContent.replace(/\\n\\n---\\n\\n/g, '</div><div class=\"chapter-separator\">').replace(/\\n/g, '<br>').replace(/^# (.+)$/gm, '<h1>$1</h1>').replace(/^## (.+)$/gm, '<h2>$1</h2>').replace(/^### (.+)$/gm, '<h3>$1</h3>')}\n  \n</body>\n</html>`;\n\nreturn [{\n  json: {\n    ...ebookData,\n    htmlContent: htmlContent,\n    pdfReady: true\n  }\n}];"},"id":"create-professional-pdf-v2","name":"Create Professional PDF","type":"n8n-nodes-base.code","typeVersion":2,"position":[1216,816]},{"parameters":{"jsCode":"// Erstelle HTML Binary für PDF-Konvertierung\nconst ebookData = $input.first().json || {};\nconst htmlContent = ebookData.htmlContent || '';\nconst topic = ebookData.topic || 'E-Book';\nconst volumeNumber = ebookData.volume_number || 1;\n\nif (!htmlContent) {\n  throw new Error('Kein HTML-Content vorhanden');\n}\n\n// Konvertiere HTML zu Base64\nconst htmlBuffer = Buffer.from(htmlContent, 'utf-8');\nconst htmlBase64 = htmlBuffer.toString('base64');\n\nreturn [{\n  json: {\n    ...ebookData,\n    htmlFileName: `${topic}-Band-${volumeNumber}.html`,\n    htmlSize: htmlBuffer.length\n  },\n  binary: {\n    html: {\n      data: htmlBase64,\n      mimeType: 'text/html',\n      fileName: `${topic}-Band-${volumeNumber}.html`\n    }\n  }\n}];"},"id":"create-html-binary-v2","name":"Create HTML Binary","type":"n8n-nodes-base.code","typeVersion":2,"position":[352,1072]},{"parameters":{"url":"={{ 'https://ugsezgnkyhcmsdpohuwf.supabase.co/storage/v1/object/ebook-covers/' + ($json.pdfFileName || ($json.isbnClean || $json.isbn || 'ebook').replace(/[^a-zA-Z0-9]/g, '') + '.pdf') }}","options":{}},"id":"upload-pdf-to-supabase-v2","name":"Upload PDF to Supabase Storage","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1184,1280],"onError":"continueRegularOutput"},{"parameters":{"tableId":"ebooks","dataToSend":"autoMapInputData"},"id":"save-full-ebook-to-db-v2","name":"Save Full E-Book to DB","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[1392,1280],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.chat_id }}","text":"={{ $json.text || $json.message }}","additionalFields":{}},"id":"final-notification-v2","name":"Final Notification (Telegram)","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[1792,1280],"webhookId":"4e55ad09-6500-4885-8bd6-c92fa48337fc","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Konvertiere boolean 'done' zu String für IF Node\nconst chapterData = $input.first().json || {};\nconst done = chapterData.done || false;\n\nreturn [{\n  json: {\n    ...chapterData,\n    done: done,\n    doneString: done ? 'true' : 'false'\n  }\n}];"},"id":"convert-done-to-string","name":"Convert Done to String","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1168,768],"disabled":true},{"parameters":{},"type":"n8n-nodes-base.manualTrigger","typeVersion":1,"position":[-3568,64],"id":"e84070ce-03fa-4b5e-889c-7ba27d8330db","name":"When clicking ‘Execute workflow’"},{"parameters":{"operation":"getAll","tableId":"ebook_proposals","matchType":"allFilters","filters":{"conditions":[{"keyName":"topic","condition":"eq","keyValue":"={{ $('Check Existing E-Books (Duplikatsprüfung)').item.json.topic || '' }}"},{"keyName":"approval_status","condition":"eq","keyValue":"approved"}]}},"id":"query-existing-ebooks-code","name":"Query Existing E-Books (Supabase)","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-1232,48],"alwaysOutputData":true,"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"// Filtere leere Proposals heraus\n// ERWEITERT: Prüft auch genre und target_audience als Fallback\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\nconst inputData = $input.first().json || {};\n\nconsole.log('[Filter Proposals] Input Data keys:', Object.keys(inputData));\nconsole.log('[Filter Proposals] Input topic:', inputData.topic);\nconsole.log('[Filter Proposals] Input genre:', inputData.genre);\nconsole.log('[Filter Proposals] Input target_audience:', inputData.target_audience);\n\n// ERWEITERT: Prüfe ob Proposal leer ist - auch genre/target_audience als Fallback\nconst hasTopic = inputData.topic && inputData.topic.trim() !== '' && inputData.topic !== 'Kein Thema gefunden' && inputData.topic !== 'N/A';\nconst hasGenre = inputData.genre && inputData.genre.trim() !== '';\nconst hasTargetAudience = inputData.target_audience && inputData.target_audience.trim() !== '';\n\n// Proposal ist leer wenn weder topic noch genre/target_audience vorhanden\nconst isEmpty = !hasTopic && !hasGenre && !hasTargetAudience;\n\nif (isEmpty) {\n  console.log('[Filter Proposals] Proposal ist leer, wird herausgefiltert');\n  return []; // Leeres Array = Proposal wird herausgefiltert\n}\n\nconsole.log('[Filter Proposals] Proposal ist gültig, wird weitergegeben');\nconsole.log('[Filter Proposals] Has Topic:', hasTopic);\nconsole.log('[Filter Proposals] Has Genre:', hasGenre);\nconsole.log('[Filter Proposals] Has Target Audience:', hasTargetAudience);\n\n// ERWEITERT: Leite ALLE Input-Daten weiter (auch chapterCount, wordsPerChapter, etc.)\nreturn [{\n  json: {\n    ...inputData // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n  }\n}];"},"id":"filter-empty-proposals","name":"Filter Empty Proposals","type":"n8n-nodes-base.code","typeVersion":2,"position":[144,288]},{"parameters":{"jsCode":"// Vereinfachte Normalisierung - Ensure Query Item macht jetzt die Arbeit\n// WICHTIG: Verwendet Input-Daten statt auf andere Nodes zuzugreifen\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\nconst inputData = $input.first().json || {};\n\nconsole.log('[Normalize] Input Data keys:', Object.keys(inputData));\nconsole.log('[Normalize] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Normalize] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Trends-Daten zu holen\nlet trendsData = inputData;\n\n// Falls Input keine Trends-Daten enthält, versuche von Check Existing E-Books zu holen (Fallback)\nif (!trendsData.topic && !trendsData.trends) {\n  try {\n    trendsData = $('Check Existing E-Books (Duplikatsprüfung)').item.json || inputData;\n  } catch (e) {\n    console.log('[Normalize] Check Existing E-Books not found, using input data');\n    trendsData = inputData;\n  }\n}\n\n// Versuche Query-Item zu holen\nlet queryItem = {};\ntry {\n  queryItem = $('Ensure Query Item').item.json || {};\n} catch (e) {\n  console.log('[Normalize] Ensure Query Item not found');\n  queryItem = {};\n}\n\nconsole.log('[Normalize] Query isEmpty:', queryItem.isEmpty);\nconsole.log('[Normalize] Query maxVolume:', queryItem.maxVolume);\n\n// Ensure Query Item gibt jetzt immer vollständige Daten zurück\nconst maxVolume = queryItem.maxVolume || 0;\nconst isEmpty = queryItem.isEmpty !== false;\n\n// ERWEITERT: Kombiniere Input-Daten mit Query-Daten und leite ALLE Daten weiter\nreturn [{\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten (chapterCount, wordsPerChapter, topic, etc.)\n    ...trendsData, // Behalte Trends-Daten\n    queryResult: isEmpty ? [] : [queryItem],\n    maxVolume: maxVolume,\n    hasTopic: trendsData.hasTopic || trendsData.topic ? true : false,\n    querySuccess: true,\n    isEmpty: isEmpty\n  }\n}];"},"id":"normalize-query-result","name":"Normalize Query Result","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1232,304]},{"parameters":{"jsCode":"// GARANTIERT ein Item zurückgeben - FIXED VERSION\n// ERWEITERT: Leitet ALLE Input-Daten weiter, einschließlich chapterCount, wordsPerChapter, etc.\nconst items = $input.all();\n\n// Hole Input-Daten (von Query Existing E-Books)\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Query] Input Data keys:', Object.keys(inputData));\nconsole.log('[Ensure Query] Input chapterCount:', inputData.chapterCount);\nconsole.log('[Ensure Query] Input wordsPerChapter:', inputData.wordsPerChapter);\n\n// Versuche Trends-Daten zu holen\nlet trendsData = {};\ntry {\n  trendsData = $('Check Existing E-Books (Duplikatsprüfung)').item.json || {};\n} catch (e) {\n  console.log('[Ensure Query] Check Existing E-Books not found');\n  trendsData = inputData;\n}\n\n// Fallback-Werte\nconst defaultResult = {\n  topic: trendsData.topic || inputData.topic || '',\n  volume_number: null,\n  isEmpty: true,\n  maxVolume: 0\n};\n\n// Wenn keine Items vorhanden\nif (!items || items.length === 0) {\n  console.log('[Ensure Query] No items, returning default');\n  return [{ \n    json: {\n      ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n      ...trendsData, // Behalte Trends-Daten\n      ...defaultResult\n    }\n  }];\n}\n\n// Parse Query-Response\nconst firstItem = items[0];\nlet queryData = firstItem.json;\n\nconsole.log('[Ensure Query] Raw data type:', typeof queryData);\n\n// Wenn Response ein String ist (body), parse ihn\nif (typeof queryData === 'string') {\n  try {\n    queryData = JSON.parse(queryData);\n  } catch (e) {\n    console.error('[Ensure Query] JSON Parse Error:', e);\n    return [{ \n      json: {\n        ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n        ...trendsData, // Behalte Trends-Daten\n        ...defaultResult\n      }\n    }];\n  }\n} else if (queryData.body) {\n  try {\n    queryData = JSON.parse(queryData.body);\n  } catch (e) {\n    console.error('[Ensure Query] Body Parse Error:', e);\n    return [{ \n      json: {\n        ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n        ...trendsData, // Behalte Trends-Daten\n        ...defaultResult\n      }\n    }];\n  }\n}\n\n// Wenn Array zurückkommt (Supabase Standard)\nif (Array.isArray(queryData)) {\n  console.log('[Ensure Query] Array with', queryData.length, 'items');\n  \n  if (queryData.length === 0) {\n    // Leeres Array = kein Duplikat gefunden\n    return [{\n      json: {\n        ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n        ...trendsData, // Behalte Trends-Daten\n        ...defaultResult,\n        isEmpty: true,\n        maxVolume: 0\n      }\n    }];\n  }\n  \n  // Erstes Element zurückgeben\n  const firstResult = queryData[0];\n  return [{\n    json: {\n      ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n      ...trendsData, // Behalte Trends-Daten\n      ...firstResult,\n      isEmpty: false,\n      maxVolume: firstResult.volume_number || 0\n    }\n  }];\n}\n\n// Wenn Objekt, direkt zurückgeben\nconsole.log('[Ensure Query] Object returned');\nreturn [{\n  json: {\n    ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n    ...trendsData, // Behalte Trends-Daten\n    ...queryData,\n    isEmpty: !queryData.volume_number,\n    maxVolume: queryData.volume_number || 0\n  }\n}];"},"id":"ensure-query-item","name":"Ensure Query Item","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1040,48]},{"parameters":{"jsCode":"// Formatiere Secrets vom nativen Supabase Node für nachfolgende Nodes\n// Der Supabase Node gibt direkt ein Array von {key_name, key_value} zurück\nconst items = $input.all();\n\n// Konvertiere Array zu Objekt für einfachen Zugriff\nconst secrets = {};\nitems.forEach(item => {\n  const json = item.json || {};\n  if (json.key_name && json.key_value) {\n    secrets[json.key_name] = json.key_value;\n  }\n});\n\n// Fallback-Werte falls Secrets fehlen\nconst fallbackSecrets = {\n  DEEPSEEK_API_KEY: 'sk-fd178bb87e1240b19786ce816c77d07f',\n  SUPABASE_ANON_KEY: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVnc2V6Z25reWhjbXNkcG9odXdmIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTcxMDI2NDAsImV4cCI6MjA3MjY3ODY0MH0.H7s5PSdTDOiHyeic61lcIGFjVITW-ikz8y6c5_bn6Ao',\n  SUPABASE_SERVICE_KEY: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InVnc2V6Z25reWhjbXNkcG9odXdmIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NzEwMjY0MCwiZXhwIjoyMDcyNjc4NjQwfQ.PEG6Z3WVpfHgxZIpuLL4aSenbWVVTmYypCvO8knahPM',\n  TELEGRAM_BOT_TOKEN: '',\n  TELEGRAM_CHAT_ID: ''\n};\n\n// Verwende Secrets aus Supabase, falls vorhanden, sonst Fallback\nconst finalSecrets = {\n  DEEPSEEK_API_KEY: secrets.DEEPSEEK_API_KEY || fallbackSecrets.DEEPSEEK_API_KEY,\n  SUPABASE_ANON_KEY: secrets.SUPABASE_ANON_KEY || fallbackSecrets.SUPABASE_ANON_KEY,\n  SUPABASE_SERVICE_KEY: secrets.SUPABASE_SERVICE_KEY || fallbackSecrets.SUPABASE_SERVICE_KEY,\n  TELEGRAM_BOT_TOKEN: secrets.TELEGRAM_BOT_TOKEN || fallbackSecrets.TELEGRAM_BOT_TOKEN,\n  TELEGRAM_CHAT_ID: secrets.TELEGRAM_CHAT_ID || fallbackSecrets.TELEGRAM_CHAT_ID\n};\n\nconsole.log('[Load Secrets] Loaded', Object.keys(secrets).length, 'secrets from Supabase');\nconsole.log('[Load Secrets] Using fallback for', Object.keys(finalSecrets).filter(k => !secrets[k]).length, 'missing keys');\n\n// Gib Secrets als JSON zurück, damit nachfolgende Nodes darauf zugreifen können\nreturn [{\n  json: {\n    secrets: finalSecrets,\n    DEEPSEEK_API_KEY: finalSecrets.DEEPSEEK_API_KEY,\n    SUPABASE_ANON_KEY: finalSecrets.SUPABASE_ANON_KEY,\n    SUPABASE_SERVICE_KEY: finalSecrets.SUPABASE_SERVICE_KEY,\n    TELEGRAM_BOT_TOKEN: finalSecrets.TELEGRAM_BOT_TOKEN,\n    TELEGRAM_CHAT_ID: finalSecrets.TELEGRAM_CHAT_ID\n  }\n}];"},"id":"load-secrets-from-supabase","name":"Load Secrets from Supabase","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2912,48]},{"parameters":{"operation":"getAll","tableId":"app_secrets","returnAll":true,"filterType":"none"},"id":"fetch-secrets-supabase","name":"Fetch Secrets from Supabase","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-3152,48],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"jsCode":"// Füge Volume Number zu Proposal hinzu\n// WICHTIG: Verwendet Input-Daten von Filter Empty Proposals\n// ERWEITERT: Holt topic von Process DeepSeek Parse, falls nicht in Input-Daten\n// ERWEITERT: Generiert topic aus genre/target_audience, falls nicht vorhanden\n// ERWEITERT: Setzt language auf 'de' als Standard, falls nicht vorhanden\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\nconsole.log('[Add Volume] ===== ADD VOLUME NUMBER START =====');\nconsole.log('[Add Volume] Input Data keys:', Object.keys(inputData));\nconsole.log('[Add Volume] Input topic:', inputData.topic);\nconsole.log('[Add Volume] Input genre:', inputData.genre);\nconsole.log('[Add Volume] Input target_audience:', inputData.target_audience);\nconsole.log('[Add Volume] Input language:', inputData.language);\n\n// WICHTIG: Hole Chat-Topic von Process DeepSeek Parse (hat IMMER Priorität)\nlet chatTopic = '';\ntry {\n  const deepSeekParseData = $('Process DeepSeek Parse').item.json || {};\n  chatTopic = deepSeekParseData.topic || '';\n  console.log('[Add Volume] ✅ Process DeepSeek Parse gefunden');\n  console.log('[Add Volume] Chat-Topic von Process DeepSeek Parse:', chatTopic);\n  console.log('[Add Volume] Chat-Topic Source:', deepSeekParseData._source || 'unknown');\n} catch (e) {\n  console.log('[Add Volume] ⚠️ Process DeepSeek Parse not found:', e.message);\n}\n\n// Versuche Volume-Daten zu holen\nlet volumeData = {};\ntry {\n  volumeData = $('Calculate Volume Number').item.json || {};\n  console.log('[Add Volume] Calculate Volume Number gefunden');\n} catch (e) {\n  console.log('[Add Volume] Calculate Volume Number not found, using input data');\n  volumeData = inputData;\n}\n\nconst volumeNumber = volumeData.volumeNumber || inputData.volumeNumber || 1;\n\n// ERWEITERT: Generiere topic, falls nicht vorhanden\nlet finalTopic = chatTopic || inputData.topic || null;\n\n// Wenn kein topic vorhanden, generiere es aus genre und target_audience\nif (!finalTopic || finalTopic.trim() === '' || finalTopic === 'N/A') {\n  const genre = inputData.genre || 'Allgemein';\n  const targetAudience = inputData.target_audience || 'Leser';\n  \n  // Generiere ein sinnvolles topic basierend auf genre und target_audience\n  finalTopic = `${genre} für ${targetAudience}`;\n  \n  console.log('[Add Volume] ⚠️ Topic fehlt, generiert aus genre/target_audience:', finalTopic);\n} else {\n  console.log('[Add Volume] ✅ Topic vorhanden:', finalTopic);\n}\n\n// ERWEITERT: Setze language auf 'de' als Standard, falls nicht vorhanden\nlet finalLanguage = inputData.language || inputData.sprache || 'de';\n\nif (!finalLanguage || finalLanguage.trim() === '' || finalLanguage === 'N/A') {\n  finalLanguage = 'de'; // Standard: Deutsch\n  console.log('[Add Volume] ⚠️ Language fehlt, setze auf Standard:', finalLanguage);\n} else {\n  console.log('[Add Volume] ✅ Language vorhanden:', finalLanguage);\n}\n\nconsole.log('[Add Volume] Topic-Priorität:');\nconsole.log('  Chat-Topic (Process DeepSeek Parse):', chatTopic || '(nicht vorhanden)');\nconsole.log('  Input-Topic:', inputData.topic || '(nicht vorhanden)');\nconsole.log('  ✅ Final Topic (Chat > Input > Generated):', finalTopic);\nconsole.log('[Add Volume] Volume Number:', volumeNumber);\nconsole.log('[Add Volume] Language:', finalLanguage);\n\n// ERWEITERT: Kombiniere Input-Daten mit Volume-Daten\n// Priorität für topic: Chat-Topic (Process DeepSeek Parse) > Input-Daten > Generiert\nconst result = {\n  ...inputData, // WICHTIG: Behalte ALLE Input-Daten\n  volume_number: volumeNumber,\n  // WICHTIG: Topic hat höchste Priorität von Process DeepSeek Parse, dann Input, dann generiert\n  topic: finalTopic,\n  language: finalLanguage,\n  sprache: finalLanguage, // Auch als 'sprache' für Kompatibilität\n  _topicSource: chatTopic ? 'chat' : (inputData.topic ? 'input' : 'generated')\n};\n\nconsole.log('[Add Volume] ===== ADD VOLUME NUMBER END =====');\nconsole.log('[Add Volume] ✅ Final Topic:', result.topic);\nconsole.log('[Add Volume] ✅ Volume Number:', result.volume_number);\nconsole.log('[Add Volume] ✅ Language:', result.language);\n\nreturn { json: result }; // FIXED: Einzelnes Objekt zurückgeben statt Array"},"id":"add-volume-number-to-proposal","name":"Add Volume Number to Proposal","type":"n8n-nodes-base.code","typeVersion":2,"position":[336,288]},{"parameters":{"jsCode":"// Extrahiere ebook_suggestions aus dem Market Analysis Objekt\n// ROBUST: Verwendet Daten aus 'Set Volume Number & Title' falls 'Save Market Analysis' keine Daten zurückgibt\n// FALLBACK: Verwendet trends direkt, falls ebook_suggestions leer ist\n// ERWEITERT: Verwendet Chat-Topic falls vorhanden\n// ERWEITERT: Leitet ALLE Daten weiter (chapterCount, wordsPerChapter, etc.), auch wenn sie nicht in ebook_proposals gespeichert werden\n// WICHTIG: Nur Felder senden, die tatsächlich in ebook_proposals existieren\n// Existierende Spalten: topic, genre, language, target_audience, length, volume_number\n// NICHT existierende Spalten (werden entfernt): popularity_score, total_score, recommendation, priority, reasoning, analysis_date, data_sources\n// Konvertiere Array von Suggestions zu einzelnen Items für Split In Batches\nconst saveMarketAnalysisOutput = $input.first().json || {};\n\nconsole.log('[Extract Suggestions] Input Data keys:', Object.keys(saveMarketAnalysisOutput));\nconsole.log('[Extract Suggestions] Input chapterCount:', saveMarketAnalysisOutput.chapterCount);\nconsole.log('[Extract Suggestions] Input wordsPerChapter:', saveMarketAnalysisOutput.wordsPerChapter);\n\n// ERWEITERT: Hole Chat-Daten (chapterCount, wordsPerChapter, topic, etc.)\nlet chatInputData = {};\nlet chatTopic = '';\n\ntry {\n  // Versuche zuerst Process DeepSeek Parse (intelligent geparst)\n  chatInputData = $('Process DeepSeek Parse').item.json || {};\n  chatTopic = chatInputData.topic || '';\n  console.log('[Extract Suggestions] Process DeepSeek Parse gefunden');\n  console.log('[Extract Suggestions] Process DeepSeek Parse chapterCount:', chatInputData.chapterCount);\n  console.log('[Extract Suggestions] Process DeepSeek Parse wordsPerChapter:', chatInputData.wordsPerChapter);\n} catch (e) {\n  try {\n    // Fallback: Extract Chat Input\n    chatInputData = $('Extract Chat Input').item.json || {};\n    chatTopic = chatInputData.topic || '';\n    console.log('[Extract Suggestions] Extract Chat Input gefunden');\n  } catch (e2) {\n    console.log('[Extract Suggestions] Extract Chat Input not found');\n  }\n}\n\n// Prüfe ob Save Market Analysis Daten zurückgegeben hat\n// Falls nicht, hole Daten vom vorherigen Node 'Set Volume Number & Title'\nlet marketAnalysis = saveMarketAnalysisOutput;\n\n// Wenn Save Market Analysis keine ebook_suggestions hat, hole vom vorherigen Node\nif (!marketAnalysis.ebook_suggestions || (Array.isArray(marketAnalysis.ebook_suggestions) && marketAnalysis.ebook_suggestions.length === 0)) {\n  console.log('[Extract Suggestions] No suggestions in Save Market Analysis output, trying previous node');\n  try {\n    const previousNodeData = $('Set Volume Number & Title').item.json || {};\n    if (previousNodeData.ebook_suggestions && Array.isArray(previousNodeData.ebook_suggestions) && previousNodeData.ebook_suggestions.length > 0) {\n      console.log('[Extract Suggestions] Found suggestions in previous node');\n      marketAnalysis = previousNodeData;\n    }\n  } catch (e) {\n    console.error('[Extract Suggestions] Error accessing previous node:', e);\n  }\n}\n\nconsole.log('[Extract Suggestions] Market Analysis keys:', Object.keys(marketAnalysis));\nconsole.log('[Extract Suggestions] ebook_suggestions type:', typeof marketAnalysis.ebook_suggestions);\nconsole.log('[Extract Suggestions] ebook_suggestions length:', Array.isArray(marketAnalysis.ebook_suggestions) ? marketAnalysis.ebook_suggestions.length : 'N/A');\n\n// Prüfe verschiedene mögliche Datenstrukturen\nlet ebookSuggestions = [];\n\n// Fall 1: ebook_suggestions ist direkt ein Array\nif (Array.isArray(marketAnalysis.ebook_suggestions)) {\n  ebookSuggestions = marketAnalysis.ebook_suggestions;\n}\n// Fall 2: ebook_suggestions ist ein String (JSON)\nelse if (typeof marketAnalysis.ebook_suggestions === 'string') {\n  try {\n    ebookSuggestions = JSON.parse(marketAnalysis.ebook_suggestions);\n  } catch (e) {\n    console.error('[Extract Suggestions] JSON Parse Error:', e);\n  }\n}\n\nconsole.log('[Extract Suggestions] Found', ebookSuggestions.length, 'suggestions from ebook_suggestions');\n\n// FALLBACK: Wenn ebook_suggestions leer ist, verwende trends direkt\nif (!Array.isArray(ebookSuggestions) || ebookSuggestions.length === 0) {\n  console.log('[Extract Suggestions] ebook_suggestions empty, using trends as fallback');\n  const trends = marketAnalysis.trends || [];\n  \n  if (Array.isArray(trends) && trends.length > 0) {\n    // Konvertiere trends zu Suggestions-Format (NUR existierende Felder)\n    ebookSuggestions = trends.map(trend => ({\n      topic: trend.topic || 'Unbekanntes Thema',\n      genre: trend.genre || 'non-fiction',\n      language: 'de',\n      target_audience: trend.target_audience || 'Berufstaetige und Unternehmer',\n      length: 'medium'\n      // Entfernt: popularity_score, total_score, recommendation, priority, reasoning\n    }));\n    \n    console.log('[Extract Suggestions] Created', ebookSuggestions.length, 'suggestions from trends');\n  }\n}\n\n// NEU: Wenn Chat-Topic vorhanden ist, erstelle ein Suggestion mit Chat-Topic\nif (chatTopic && chatTopic.trim().length > 0) {\n  console.log('[Extract Suggestions] Chat Topic vorhanden, erstelle Suggestion mit Chat-Topic:', chatTopic);\n  \n  // Prüfe ob Chat-Topic bereits in Suggestions vorhanden ist\n  const topicExists = ebookSuggestions.some(s => s.topic && s.topic.toLowerCase().includes(chatTopic.toLowerCase()));\n  \n  if (!topicExists) {\n    // Erstelle neues Suggestion mit Chat-Topic (an erster Stelle für Priorität)\n    ebookSuggestions.unshift({\n      topic: chatTopic,\n      genre: 'non-fiction',\n      language: 'de',\n      target_audience: 'Berufstaetige und Unternehmer',\n      length: 'medium',\n      _fromChatInput: true // Flag für Debugging\n    });\n    console.log('[Extract Suggestions] Chat-Topic Suggestion hinzugefügt');\n  } else {\n    // Aktualisiere erstes Suggestion mit Chat-Topic\n    const firstSuggestion = ebookSuggestions[0];\n    if (firstSuggestion) {\n      firstSuggestion.topic = chatTopic;\n      firstSuggestion._fromChatInput = true;\n      console.log('[Extract Suggestions] Erstes Suggestion mit Chat-Topic aktualisiert');\n    }\n  }\n}\n\n// ERWEITERT: Kombiniere Chat-Daten mit Market Analysis Daten\n// Diese Daten werden durch die gesamte Kette weitergegeben, auch wenn sie nicht in ebook_proposals gespeichert werden\nconst chatDataToPass = {\n  chapterCount: chatInputData.chapterCount !== undefined ? chatInputData.chapterCount : (saveMarketAnalysisOutput.chapterCount !== undefined ? saveMarketAnalysisOutput.chapterCount : null),\n  wordsPerChapter: chatInputData.wordsPerChapter !== undefined ? chatInputData.wordsPerChapter : (saveMarketAnalysisOutput.wordsPerChapter !== undefined ? saveMarketAnalysisOutput.wordsPerChapter : null),\n  topic: chatTopic || saveMarketAnalysisOutput.topic || null,\n  textType: chatInputData.textType || saveMarketAnalysisOutput.textType || null,\n  coverImageType: chatInputData.coverImageType || saveMarketAnalysisOutput.coverImageType || null,\n  imageType: chatInputData.imageType || saveMarketAnalysisOutput.imageType || null,\n  style: chatInputData.style || saveMarketAnalysisOutput.style || null,\n  aspectRatio: chatInputData.aspectRatio || saveMarketAnalysisOutput.aspectRatio || null,\n  hasText: chatInputData.hasText !== undefined ? chatInputData.hasText : (saveMarketAnalysisOutput.hasText !== undefined ? saveMarketAnalysisOutput.hasText : null),\n  imagesInBook: chatInputData.imagesInBook !== undefined ? chatInputData.imagesInBook : (saveMarketAnalysisOutput.imagesInBook !== undefined ? saveMarketAnalysisOutput.imagesInBook : null),\n  imageCount: chatInputData.imageCount !== undefined ? chatInputData.imageCount : (saveMarketAnalysisOutput.imageCount !== undefined ? saveMarketAnalysisOutput.imageCount : null)\n};\n\nconsole.log('[Extract Suggestions] Chat Data to Pass:', chatDataToPass);\n\n// Wenn immer noch keine Suggestions vorhanden sind, gib ein leeres Item zurück (Workflow stoppt nicht)\nif (!Array.isArray(ebookSuggestions) || ebookSuggestions.length === 0) {\n  console.warn('[Extract Suggestions] No suggestions found after fallback, returning empty item');\n  return [{\n    json: {\n      topic: chatTopic || 'Kein Thema gefunden', // WICHTIG: Verwendet Chat-Topic falls vorhanden\n      genre: 'non-fiction',\n      target_audience: 'Berufstaetige und Unternehmer',\n      // ERWEITERT: Füge Chat-Daten hinzu\n      ...chatDataToPass,\n      _warning: 'Keine Suggestions gefunden',\n      _debug: {\n        hasEbookSuggestions: !!marketAnalysis.ebook_suggestions,\n        ebookSuggestionsType: typeof marketAnalysis.ebook_suggestions,\n        hasTrends: !!(marketAnalysis.trends && Array.isArray(marketAnalysis.trends) && marketAnalysis.trends.length > 0),\n        trendsLength: Array.isArray(marketAnalysis.trends) ? marketAnalysis.trends.length : 0,\n        marketAnalysisKeys: Object.keys(marketAnalysis),\n        chatTopic: chatTopic || '(nicht vorhanden)'\n      }\n    }\n  }];\n}\n\n// Konvertiere jedes Suggestion zu einem Item\n// WICHTIG: Nur Felder senden, die in ebook_proposals existieren\n// ERWEITERT: Füge Chat-Daten hinzu, die durch die Kette weitergegeben werden\nconst items = ebookSuggestions.map(suggestion => {\n  // Erstelle sauberes Suggestion-Objekt mit NUR existierenden Feldern für ebook_proposals\n  const cleanSuggestion = {\n    topic: suggestion.topic || '',\n    genre: suggestion.genre || 'non-fiction',\n    language: suggestion.language || 'de',\n    target_audience: suggestion.target_audience || 'Berufstaetige und Unternehmer',\n    length: suggestion.length || 'medium'\n    // Entfernt: popularity_score, total_score, recommendation, priority, reasoning\n    // Diese Felder existieren nicht in ebook_proposals\n  };\n  \n  // ERWEITERT: Füge Chat-Daten hinzu (werden nicht in ebook_proposals gespeichert, aber durch Kette weitergegeben)\n  return { \n    json: {\n      ...cleanSuggestion,\n      ...chatDataToPass // WICHTIG: Diese Daten werden durch die gesamte Kette weitergegeben\n    }\n  };\n});\n\nconsole.log('[Extract Suggestions] Returning', items.length, 'items (nur existierende Felder für ebook_proposals + Chat-Daten)');\nif (chatTopic) {\n  console.log('[Extract Suggestions] Chat-Topic wird verwendet:', chatTopic);\n}\nif (chatDataToPass.chapterCount || chatDataToPass.wordsPerChapter) {\n  console.log('[Extract Suggestions] Chat-Daten werden weitergegeben:', { chapterCount: chatDataToPass.chapterCount, wordsPerChapter: chatDataToPass.wordsPerChapter });\n}\nreturn items;"},"id":"extract-ebook-suggestions","name":"Extract E-Book Suggestions","type":"n8n-nodes-base.code","typeVersion":2,"position":[-240,48]},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"loose","version":1},"conditions":[{"id":"check-done","leftValue":"={{ $('Split into Proposals').context?.noItemsLeft === true }}","rightValue":"true","operator":{"type":"boolean","operation":"equals"}}],"combinator":"and"},"options":{"looseTypeValidation":true}},"id":"check-proposals-done","name":"Check: All Proposals Done?","type":"n8n-nodes-base.if","typeVersion":2,"position":[1296,32],"onError":"continueErrorOutput"},{"parameters":{"options":{}},"id":"groq-chat-trigger","name":"DeepSeek Chat Trigger","type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.4,"position":[-3216,-368],"webhookId":"02f6c8d3-7e63-432a-9b7a-de7615de11f9","disabled":true},{"parameters":{"jsCode":"// NEU: Intelligenter Extract Chat Input\n// Leitet Chat Input an DeepSeek API weiter für intelligente Analyse\n// Dieser Node bereitet nur die Daten vor und leitet sie weiter\nconst chatInput = $input.first().json.chatInput || $input.first().json.message || '';\n\nconsole.log('[Extract Chat Input] Chat Input erhalten:', chatInput);\n\n// Leite Chat Input direkt an DeepSeek Intelligent Parse weiter\n// Die eigentliche Analyse erfolgt in DeepSeek Intelligent Parse Node\nreturn [{\n  json: {\n    chatInput: chatInput,\n    message: chatInput,\n    _needsIntelligentParse: true\n  }\n}];"},"id":"extract-chat-input","name":"Extract Chat Input","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2992,-368],"disabled":true},{"parameters":{"jsCode":"// Intelligente Marktanalyse: Extrahiert E-Book-Parameter aus Marktanalyse-Daten\n// ERWEITERT: Fokus auf Topseller aus allen Stilrichtungen und Bereichen\n// WICHTIG: Verwendet Input-Daten von Process Analyze Trends Response\nconst inputData = $input.first().json || {};\n\nconsole.log('[Market Analysis] ===== INTELLIGENT MARKET ANALYSIS START =====');\nconsole.log('[Market Analysis] Input keys:', Object.keys(inputData));\nconsole.log('[Market Analysis] Has trends:', !!inputData.trends);\nconsole.log('[Market Analysis] Has marketInsights:', !!inputData.marketInsights);\n\n// Extrahiere Marktanalyse-Daten aus Input (von Process Analyze Trends Response)\nfunction extractTrendsData(data) {\n  try {\n    // Falls bereits geparste Trends vorhanden\n    if (data.trends && Array.isArray(data.trends)) {\n      return {\n        trends: data.trends,\n        market_insights: data.marketInsights || data.market_insights || ''\n      };\n    }\n    \n    // Falls noch in Response-Format\n    if (data.choices?.[0]?.message?.content) {\n      const content = data.choices[0].message.content;\n      const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]);\n      }\n    }\n  } catch (e) {\n    console.error('[Market Analysis] Parse error:', e);\n  }\n  return { trends: [], market_insights: '' };\n}\n\n// Verwende Input-Daten (von Process Analyze Trends Response)\nconst parsedData = extractTrendsData(inputData);\nconst trends = parsedData.trends || inputData.trends || [];\nconst marketInsights = parsedData.market_insights || parsedData.marketInsights || inputData.marketInsights || inputData.market_insights || '';\n\nconsole.log('[Market Analysis] Trends count:', trends.length);\nconsole.log('[Market Analysis] Market insights length:', marketInsights.length);\n\n// WICHTIG: Wähle den besten Trend basierend auf Popularität und Vielfalt\n// Priorisiere Trends mit hoher Popularität und verschiedenen Zielgruppen\nlet bestTrend = null;\nlet bestPopularity = 0;\n\nfor (const trend of trends) {\n  const popularity = trend.popularity || 0;\n  if (popularity > bestPopularity) {\n    bestPopularity = popularity;\n    bestTrend = trend;\n  }\n}\n\n// Falls kein Trend gefunden, verwende ersten Trend\nif (!bestTrend && trends.length > 0) {\n  bestTrend = trends[0];\n}\n\n// Falls immer noch kein Trend, erstelle Standard-Trend\nif (!bestTrend) {\n  bestTrend = {\n    topic: 'Aktuelle Markttrends',\n    genre: 'non-fiction',\n    target_audience: 'Berufstätige und Unternehmer',\n    popularity: 7\n  };\n}\n\nconsole.log('[Market Analysis] Best Trend:', bestTrend);\n\n// Bestimme optimale E-Book-Parameter basierend auf Marktanalyse\n// ERWEITERT: Berücksichtigt verschiedene Stilrichtungen und Zielgruppen\nconst genre = (bestTrend.genre || 'non-fiction').toLowerCase();\nconst popularity = bestTrend.popularity || 7;\nconst targetAudience = (bestTrend.target_audience || '').toLowerCase();\nconst topic = bestTrend.topic || '';\n\nlet ebookParams = {\n  textType: 'Ratgeber',\n  coverImageType: 'Bilder im eBook',\n  chapterCount: 5,\n  wordsPerChapter: 600,\n  topic: topic, // WICHTIG: Topic von Trend übernehmen\n  reasoning: `Basierend auf Marktanalyse: ${bestTrend.reasoning || 'Topseller-Trend aus Marktanalyse'}`\n};\n\n// ERWEITERT: Bild-Parameter\nlet imageParams = {\n  imageType: 'cover',\n  style: 'modern',\n  aspectRatio: '16:9',\n  hasText: false,\n  imagesInBook: true,\n  imageCount: 3\n};\n\n// Bestimme Parameter basierend auf Genre und Zielgruppe\nif (genre.includes('fiction') || genre.includes('story') || genre.includes('roman')) {\n  ebookParams.textType = 'Story';\n  ebookParams.chapterCount = 8;\n  ebookParams.wordsPerChapter = 800;\n  ebookParams.coverImageType = 'Modern';\n  imageParams.imageType = 'cover';\n  imageParams.style = 'artistic';\n  imageParams.aspectRatio = '9:16';\n  imageParams.hasText = false;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 5;\n} else if (genre.includes('tutorial') || genre.includes('anleitung') || genre.includes('guide')) {\n  ebookParams.textType = 'Tutorial';\n  ebookParams.chapterCount = 6;\n  ebookParams.wordsPerChapter = 500;\n  ebookParams.coverImageType = 'Bilder im eBook';\n  imageParams.imageType = 'title-with-text';\n  imageParams.style = 'professional';\n  imageParams.aspectRatio = '16:9';\n  imageParams.hasText = true;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 8;\n} else if (genre.includes('handwerk') || targetAudience.includes('handwerk')) {\n  ebookParams.textType = 'Anleitung';\n  ebookParams.chapterCount = 7;\n  ebookParams.wordsPerChapter = 600;\n  ebookParams.coverImageType = 'AllesHandwerknzahl';\n  imageParams.imageType = 'cover';\n  imageParams.style = 'classic';\n  imageParams.aspectRatio = '4:3';\n  imageParams.hasText = false;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 10;\n} else {\n  // Non-fiction / Ratgeber\n  ebookParams.textType = 'Ratgeber';\n  ebookParams.chapterCount = 5;\n  ebookParams.wordsPerChapter = 600;\n  ebookParams.coverImageType = 'Bilder im eBook';\n  imageParams.imageType = 'cover';\n  imageParams.style = 'modern';\n  imageParams.aspectRatio = '16:9';\n  imageParams.hasText = false;\n  imageParams.imagesInBook = true;\n  imageParams.imageCount = 3;\n}\n\n// Anpassung basierend auf Popularität\nif (popularity >= 9) {\n  ebookParams.chapterCount = Math.min(ebookParams.chapterCount + 2, 10);\n  ebookParams.wordsPerChapter = Math.min(ebookParams.wordsPerChapter + 100, 1000);\n  imageParams.imageCount = Math.min(imageParams.imageCount + 2, 15);\n} else if (popularity <= 6) {\n  ebookParams.chapterCount = Math.max(ebookParams.chapterCount - 1, 3);\n  ebookParams.wordsPerChapter = Math.max(ebookParams.wordsPerChapter - 100, 300);\n  imageParams.imageCount = Math.max(imageParams.imageCount - 1, 1);\n}\n\n// Anpassung basierend auf Zielgruppe\nif (targetAudience.includes('unternehmer') || targetAudience.includes('business')) {\n  imageParams.style = 'professional';\n  imageParams.aspectRatio = '16:9';\n  imageParams.hasText = true;\n} else if (targetAudience.includes('handwerk') || targetAudience.includes('handwerker')) {\n  imageParams.style = 'classic';\n  imageParams.aspectRatio = '4:3';\n  imageParams.hasText = false;\n} else if (targetAudience.includes('kreativ') || targetAudience.includes('design')) {\n  imageParams.style = 'artistic';\n  imageParams.aspectRatio = '1:1';\n  imageParams.hasText = false;\n} else if (targetAudience.includes('jung') || targetAudience.includes('junge')) {\n  imageParams.style = 'modern';\n  imageParams.aspectRatio = '9:16';\n  imageParams.hasText = false;\n} else if (targetAudience.includes('alt') || targetAudience.includes('senior')) {\n  imageParams.style = 'classic';\n  imageParams.aspectRatio = '4:3';\n  imageParams.hasText = true;\n}\n\n// Bestimme imageType basierend auf coverImageType\nif (ebookParams.coverImageType === 'AllesHandwerknzahl') {\n  imageParams.imageType = 'cover';\n  imageParams.style = 'classic';\n} else if (ebookParams.coverImageType === 'Bilder im eBook') {\n  imageParams.imageType = 'title-with-text';\n  imageParams.hasText = true;\n} else if (ebookParams.coverImageType === 'Modern') {\n  imageParams.imageType = 'cover';\n  imageParams.style = 'modern';\n}\n\n// Berechne Gesamt-Wortanzahl\nconst totalWords = ebookParams.chapterCount * ebookParams.wordsPerChapter;\n\nconsole.log('[Market Analysis] ===== INTELLIGENT MARKET ANALYSIS END =====');\nconsole.log('[Market Analysis] E-Book Parameters:');\nconsole.log('  Topic:', ebookParams.topic);\nconsole.log('  Text Type:', ebookParams.textType);\nconsole.log('  Cover Image Type:', ebookParams.coverImageType);\nconsole.log('  Chapter Count:', ebookParams.chapterCount);\nconsole.log('  Words Per Chapter:', ebookParams.wordsPerChapter);\nconsole.log('  Total Words:', totalWords);\nconsole.log('[Market Analysis] Image Parameters:');\nconsole.log('  Image Type:', imageParams.imageType);\nconsole.log('  Style:', imageParams.style);\nconsole.log('  Aspect Ratio:', imageParams.aspectRatio);\nconsole.log('  Has Text:', imageParams.hasText);\nconsole.log('  Images In Book:', imageParams.imagesInBook);\nconsole.log('  Image Count:', imageParams.imageCount);\n\n// WICHTIG: Kombiniere ALLE Input-Daten mit neuen Parametern und leite sie weiter\n// KRITISCH: Topic muss immer vorhanden sein!\nreturn [{\n  json: {\n    ...inputData, // Behalte alle ursprünglichen Daten\n    // WICHTIG: Topic von Trend übernehmen (höchste Priorität)\n    topic: ebookParams.topic || inputData.topic || null,\n    thema: ebookParams.topic || inputData.thema || inputData.topic || null,\n    // E-Book-Parameter aus Marktanalyse\n    marketAnalysisEbookParams: {\n      textType: ebookParams.textType,\n      coverImageType: ebookParams.coverImageType,\n      chapterCount: ebookParams.chapterCount,\n      wordsPerChapter: ebookParams.wordsPerChapter,\n      totalWords: totalWords,\n      reasoning: ebookParams.reasoning,\n      topic: ebookParams.topic\n    },\n    // ERWEITERT: Bild-Parameter aus Marktanalyse\n    marketAnalysisImageParams: {\n      imageType: imageParams.imageType,\n      style: imageParams.style,\n      aspectRatio: imageParams.aspectRatio,\n      hasText: imageParams.hasText,\n      imagesInBook: imageParams.imagesInBook,\n      imageCount: imageParams.imageCount\n    },\n    // Für Kompatibilität mit nachfolgenden Nodes\n    textType: ebookParams.textType,\n    coverImageType: ebookParams.coverImageType,\n    chapterCount: ebookParams.chapterCount,\n    wordsPerChapter: ebookParams.wordsPerChapter,\n    totalWords: totalWords,\n    minWordCount: totalWords,\n    // Bild-Parameter für Kompatibilität\n    imageType: imageParams.imageType,\n    style: imageParams.style,\n    aspectRatio: imageParams.aspectRatio,\n    hasText: imageParams.hasText,\n    imagesInBook: imageParams.imagesInBook,\n    imageCount: imageParams.imageCount,\n    // Trends-Daten für nachfolgende Nodes\n    trends: trends,\n    marketInsights: marketInsights,\n    market_insights: marketInsights\n  }\n}];"},"id":"intelligent-market-analysis","name":"Intelligent Market Analysis (MCP)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2464,48]},{"parameters":{"method":"POST","url":"https://api.deepseek.com/v1/chat/completions","authentication":"predefinedCredentialType","nodeCredentialType":"deepSeekApi","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Authorization","value":"Bearer sk-fd178bb87e1240b19786ce816c77d07f"},{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ JSON.stringify({ model: 'deepseek-chat', messages: [{ role: 'system', content: 'Du bist ein Experte für E-Book-Optimierung und Marktanalyse. Analysiere Marktdaten und bestimme optimale E-Book-Parameter inklusive Bild-Parameter. Antworte IMMER im JSON-Format.' }, { role: 'user', content: 'Basierend auf folgenden Marktanalyse-Daten:\\n\\nMarkt-Insights: ' + ($json.marketInsights || $json.market_insights || '') + '\\nTop-Trend: ' + ($json.trends?.[0]?.topic || 'Unbekannt') + '\\nGenre: ' + ($json.trends?.[0]?.genre || 'non-fiction') + '\\nZielgruppe: ' + ($json.trends?.[0]?.target_audience || 'Berufstätige und Unternehmer') + '\\nPopularität: ' + ($json.trends?.[0]?.popularity || 7) + '/10\\n\\nBestimme die optimalen E-Book-Parameter:\\n1. Text-Art (Ratgeber, Tutorial, Story, Anleitung, Guide)\\n2. Titelbild-Style (Bilder im eBook, AllesHandwerknzahl, Modern, Klassisch)\\n3. Kapitelanzahl (3-10)\\n4. Worte pro Kapitel (300-1000)\\n\\nERWEITERT: Bild-Parameter:\\n5. imageType (cover, title, in-book, title-with-text)\\n6. style (modern, classic, minimalist, professional, artistic)\\n7. aspectRatio (16:9, 9:16, 1:1, 4:3, 3:4)\\n8. hasText (boolean - Titelbild mit Text?)\\n9. imagesInBook (boolean - Bilder im eBook selbst?)\\n10. imageCount (number - Anzahl Bilder im eBook)\\n\\nAntworte im JSON-Format: {\\\"textType\\\": \\\"string\\\", \\\"coverImageType\\\": \\\"string\\\", \\\"chapterCount\\\": number, \\\"wordsPerChapter\\\": number, \\\"imageType\\\": \\\"string\\\", \\\"style\\\": \\\"string\\\", \\\"aspectRatio\\\": \\\"string\\\", \\\"hasText\\\": boolean, \\\"imagesInBook\\\": boolean, \\\"imageCount\\\": number, \\\"reasoning\\\": \\\"string\\\"}' }], temperature: 0.7 }) }}","options":{}},"id":"groq-enhanced-analysis","name":"DeepSeek Enhanced Analysis","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[-2288,304],"alwaysOutputData":true,"credentials":{"httpHeaderAuth":{"id":"u3Sgkv5o7BSKcUY2","name":"X.AI (Grok)"},"deepSeekApi":{"id":"ZDG2m0jA1qkyUnC3","name":"DeepSeek"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const items = $input.all(); const result = items.map(item => ({ json: item.json })); return result.length > 0 ? result : [{ json: {} }];"},"id":"merge-market-analysis-params","name":"Merge Market Analysis Params","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1744,304]},{"parameters":{"jsCode":"// Verarbeite Analyze Trends Response\n// KRITISCH: DeepSeek API gibt JSON in Code-Block zurück (```json ... ```)\n// Dieser Node extrahiert das JSON und formatiert es für nachfolgende Nodes\nconst inputData = $input.first().json || {};\n\nconsole.log('[Process Analyze Trends] ===== PROCESS ANALYZE TRENDS RESPONSE START =====');\nconsole.log('[Process Analyze Trends] Input keys:', Object.keys(inputData));\n\n// Extrahiere JSON aus API Response\nlet trendsData = null;\n\ntry {\n  // Prüfe ob choices vorhanden sind\n  if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n    const content = inputData.choices[0].message.content || '';\n    console.log('[Process Analyze Trends] Content length:', content.length);\n    console.log('[Process Analyze Trends] Content preview:', content.substring(0, 200));\n    \n    // Entferne Code-Block-Markierungen (```json ... ```)\n    let jsonContent = content.trim();\n    \n    // Entferne ```json am Anfang\n    if (jsonContent.startsWith('```json')) {\n      jsonContent = jsonContent.substring(7).trim();\n    } else if (jsonContent.startsWith('```')) {\n      jsonContent = jsonContent.substring(3).trim();\n    }\n    \n    // Entferne ``` am Ende\n    if (jsonContent.endsWith('```')) {\n      jsonContent = jsonContent.substring(0, jsonContent.length - 3).trim();\n    }\n    \n    console.log('[Process Analyze Trends] Cleaned JSON content length:', jsonContent.length);\n    \n    // Parse JSON\n    trendsData = JSON.parse(jsonContent);\n    console.log('[Process Analyze Trends] ✅ JSON erfolgreich geparst');\n    console.log('[Process Analyze Trends] Trends count:', trendsData.trends ? trendsData.trends.length : 0);\n    console.log('[Process Analyze Trends] Market insights length:', trendsData.market_insights ? trendsData.market_insights.length : 0);\n  } else {\n    console.log('[Process Analyze Trends] ⚠️ Keine choices in Response');\n    // Fallback: Versuche direkt zu parsen\n    if (typeof inputData === 'object' && inputData.trends) {\n      trendsData = inputData;\n      console.log('[Process Analyze Trends] ✅ Direktes Parsing erfolgreich');\n    }\n  }\n} catch (e) {\n  console.error('[Process Analyze Trends] ❌ Parse Error:', e.message);\n  console.error('[Process Analyze Trends] Stack:', e.stack);\n  \n  // Fallback: Versuche JSON direkt aus Input zu extrahieren\n  try {\n    if (inputData.trends && Array.isArray(inputData.trends)) {\n      trendsData = {\n        trends: inputData.trends,\n        market_insights: inputData.market_insights || inputData.market_insights || ''\n      };\n      console.log('[Process Analyze Trends] ✅ Fallback: Direktes Parsing aus Input');\n    }\n  } catch (e2) {\n    console.error('[Process Analyze Trends] ❌ Fallback auch fehlgeschlagen:', e2.message);\n  }\n}\n\nif (!trendsData || !trendsData.trends || !Array.isArray(trendsData.trends)) {\n  console.error('[Process Analyze Trends] ❌ KEINE TRENDS GEFUNDEN!');\n  console.error('[Process Analyze Trends] TrendsData:', JSON.stringify(trendsData, null, 2));\n  console.error('[Process Analyze Trends] Input Data:', JSON.stringify(inputData, null, 2));\n  \n  // Fallback: Leere Trends-Struktur\n  trendsData = {\n    trends: [],\n    market_insights: 'Keine Trends gefunden'\n  };\n}\n\n// Formatiere Daten für nachfolgende Nodes\nconst outputData = {\n  ...inputData, // Behalte alle ursprünglichen Daten\n  // WICHTIG: Extrahiertes JSON\n  trends: trendsData.trends || [],\n  market_insights: trendsData.market_insights || trendsData.marketInsights || '',\n  marketInsights: trendsData.market_insights || trendsData.marketInsights || ''\n};\n\nconsole.log('[Process Analyze Trends] ===== PROCESS ANALYZE TRENDS RESPONSE END =====');\nconsole.log('[Process Analyze Trends] ✅ Output Data:');\nconsole.log('  Trends count:', outputData.trends.length);\nconsole.log('  Market insights length:', outputData.market_insights.length);\nif (outputData.trends.length > 0) {\n  console.log('  First trend topic:', outputData.trends[0].topic);\n  console.log('  First trend popularity:', outputData.trends[0].popularity);\n}\n\nreturn [{ json: outputData }];"},"id":"process-analyze-trends-response","name":"Process Analyze Trends Response","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2656,288]},{"parameters":{"jsCode":"const items = $input.all(); const result = items.map(item => ({ json: item.json })); return result.length > 0 ? result : [{ json: {} }];"},"id":"process-groq-enhanced-response","name":"Process DeepSeek Enhanced Response","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1936,304]},{"parameters":{"jsCode":"// Stelle sicher, dass Analyze Trends immer Daten hat\n// Dieser Node wird NACH Analyze Trends ausgeführt und stellt sicher, dass Daten vorhanden sind\n// Falls Analyze Trends leer ist, werden Standard-Trends erstellt\n// FIXED: Erstellt Fallback-Trends basierend auf Marktanalyse, wenn Analyze Trends leer ist\n\n// Hole Input-Daten (von Analyze Trends)\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Analyze Trends] ===== ENSURE ANALYZE TRENDS DATA START =====');\nconsole.log('[Ensure Analyze Trends] Input keys:', Object.keys(inputData));\nconsole.log('[Ensure Analyze Trends] Input length:', Object.keys(inputData).length);\nconsole.log('[Ensure Analyze Trends] Has choices:', !!inputData.choices);\n\n// Hole Daten vom vorherigen Node (Load Secrets)\nlet secretsData = {};\ntry {\n  secretsData = $('Load Secrets from Supabase').first().json || {};\n  console.log('[Ensure Analyze Trends] ✅ Secrets data found');\n} catch (e) {\n  console.log('[Ensure Analyze Trends] ⚠️ Secrets data not found:', e.message);\n}\n\n// Prüfe ob Analyze Trends Daten hat\nconst hasAnalyzeTrendsData = inputData.choices && inputData.choices.length > 0 && inputData.choices[0].message && inputData.choices[0].message.content;\n\nif (hasAnalyzeTrendsData) {\n  console.log('[Ensure Analyze Trends] ✅ Analyze Trends hat Daten, verwende diese');\n  const output = { ...secretsData, ...inputData };\n  console.log('[Ensure Analyze Trends] Output keys:', Object.keys(output));\n  return [{ json: output }];\n}\n\n// Falls Analyze Trends leer ist, erstelle Fallback-Daten mit Standard-Trends\nconsole.warn('[Ensure Analyze Trends] ⚠️ Analyze Trends ist leer, erstelle Fallback-Daten mit Standard-Trends');\n\n// Standard-Trends: Topseller aus verschiedenen Stilrichtungen und Bereichen\nconst fallbackTrends = [\n  {\n    topic: 'Künstliche Intelligenz im Business',\n    genre: 'Ratgeber',\n    target_audience: 'Unternehmer',\n    popularity: 9,\n    reasoning: 'Hohe Nachfrage nach KI-Anwendungen im Business-Bereich, aktuelle Topseller-Thematik'\n  },\n  {\n    topic: 'Gesundheit und Wohlbefinden für Senioren',\n    genre: 'Ratgeber',\n    target_audience: 'Senioren',\n    popularity: 8,\n    reasoning: 'Wachsende Zielgruppe, hohe Relevanz für Gesundheitsthemen'\n  },\n  {\n    topic: 'Nachhaltigkeit und Umweltschutz',\n    genre: 'Sachbuch',\n    target_audience: 'Junge Erwachsene',\n    popularity: 9,\n    reasoning: 'Aktuelles Trend-Thema mit hoher gesellschaftlicher Relevanz'\n  },\n  {\n    topic: 'Finanzielle Unabhängigkeit für Privatpersonen',\n    genre: 'Ratgeber',\n    target_audience: 'Privatpersonen',\n    popularity: 8,\n    reasoning: 'Hohe Nachfrage nach Finanzthemen, praktische Anwendbarkeit'\n  },\n  {\n    topic: 'Handwerk und DIY-Projekte',\n    genre: 'Anleitung',\n    target_audience: 'Privatpersonen',\n    popularity: 7,\n    reasoning: 'Wachsende Beliebtheit von Handwerk und DIY, praktische Anleitungen'\n  },\n  {\n    topic: 'Produktivität und Zeitmanagement',\n    genre: 'Ratgeber',\n    target_audience: 'Berufstätige',\n    popularity: 8,\n    reasoning: 'Immer relevante Thematik für Berufstätige, hohe Nachfrage'\n  },\n  {\n    topic: 'Kreativität und Design',\n    genre: 'Kreativ',\n    target_audience: 'Kreative',\n    popularity: 7,\n    reasoning: 'Wachsende Kreativwirtschaft, hohe Nachfrage nach Design-Themen'\n  }\n];\n\nconst fallbackData = {\n  ...secretsData,\n  choices: [{\n    message: {\n      content: JSON.stringify({\n        trends: fallbackTrends,\n        market_insights: 'Standard-Trends basierend auf aktuellen Topsellern aus verschiedenen Stilrichtungen und Bereichen (Business, Privat, jung, alt). Diese Trends wurden verwendet, da die Marktanalyse-API keine Daten zurückgegeben hat.'\n      })\n    }\n  }],\n  _fallback: true,\n  _analyzeTrendsEmpty: true,\n  _standardTrends: true\n};\n\nconsole.log('[Ensure Analyze Trends] ✅ Fallback-Daten erstellt mit', fallbackTrends.length, 'Trends');\nconsole.log('[Ensure Analyze Trends] Trends:', fallbackTrends.map(t => t.topic));\nconsole.log('[Ensure Analyze Trends] ===== ENSURE ANALYZE TRENDS DATA END =====');\n\nreturn [{ json: fallbackData }];"},"id":"ensure-analyze-trends-data","name":"Ensure Analyze Trends Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2912,288]},{"parameters":{"jsCode":"// Stelle sicher, dass Groq Enhanced Analysis immer Daten hat\n// Dieser Node wird NACH Groq Enhanced Analysis ausgeführt und stellt sicher, dass Daten vorhanden sind\n// Falls Groq Enhanced Analysis leer ist, werden die Daten vom vorherigen Node weitergeleitet\n\n// Hole Input-Daten (von Groq Enhanced Analysis)\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Groq Enhanced] Input keys:', Object.keys(inputData));\nconsole.log('[Ensure Groq Enhanced] Input length:', Object.keys(inputData).length);\n\n// Hole Daten vom vorherigen Node (Intelligent Market Analysis)\nlet marketAnalysisData = {};\ntry {\n  marketAnalysisData = $('Intelligent Market Analysis (MCP)').item.json || {};\n  console.log('[Ensure Groq Enhanced] Market Analysis data found');\n} catch (e) {\n  console.log('[Ensure Groq Enhanced] Market Analysis data not found');\n}\n\n// Prüfe ob Groq Enhanced Analysis Daten hat\nconst hasGroqData = inputData.choices || (Object.keys(inputData).length > 2 && !inputData.error);\n\nif (hasGroqData) {\n  console.log('[Ensure Groq Enhanced] Groq Enhanced Analysis hat Daten, verwende diese');\n  return [{ json: { ...marketAnalysisData, ...inputData } }];\n}\n\n// Falls Groq Enhanced Analysis leer ist, erstelle Fallback-Daten basierend auf Market Analysis\nconsole.warn('[Ensure Groq Enhanced] Groq Enhanced Analysis ist leer, erstelle Fallback-Daten');\n\nconst marketParams = marketAnalysisData.marketAnalysisEbookParams || {};\nconst imageParams = marketAnalysisData.marketAnalysisImageParams || {};\n\nconst fallbackData = {\n  ...marketAnalysisData,\n  choices: [{\n    message: {\n      content: JSON.stringify({\n        textType: marketParams.textType || 'Ratgeber',\n        coverImageType: marketParams.coverImageType || 'Bilder im eBook',\n        chapterCount: marketParams.chapterCount || 5,\n        wordsPerChapter: marketParams.wordsPerChapter || 600,\n        imageType: imageParams.imageType || 'cover',\n        style: imageParams.style || 'modern',\n        aspectRatio: imageParams.aspectRatio || '16:9',\n        hasText: imageParams.hasText !== undefined ? imageParams.hasText : false,\n        imagesInBook: imageParams.imagesInBook !== undefined ? imageParams.imagesInBook : true,\n        imageCount: imageParams.imageCount || 3,\n        reasoning: marketParams.reasoning || 'Standard-Parameter basierend auf Marktanalyse'\n      })\n    }\n  }],\n  _fallback: true,\n  _groqEnhancedEmpty: true\n};\n\nconsole.log('[Ensure Groq Enhanced] Fallback-Daten erstellt');\nreturn [{ json: fallbackData }];"},"id":"ensure-groq-enhanced-data","name":"Ensure DeepSeek Enhanced Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2112,304]},{"parameters":{"method":"POST","url":"https://api.deepseek.com/v1/chat/completions","authentication":"predefinedCredentialType","nodeCredentialType":"deepSeekApi","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Authorization","value":"Bearer sk-fd178bb87e1240b19786ce816c77d07f"},{"name":"Content-Type","value":"application/json"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ JSON.stringify({ model: 'deepseek-chat', messages: [{ role: 'system', content: 'Du bist ein Experte für die Analyse von E-Book-Anfragen. Analysiere die Benutzeranfrage und extrahiere alle relevanten Parameter. Antworte IMMER im JSON-Format mit folgender Struktur: { topic: string (Thema des E-Books, z.B. \"Mäuse\"), textType: string (Ratgeber, Tutorial, Story, Anleitung, Guide, Sachbuch), coverImageType: string (Bilder im eBook, AllesHandwerknzahl, Modern, Klassisch), chapterCount: number (Anzahl Kapitel, z.B. 2), wordsPerChapter: number (Wörter pro Kapitel, z.B. 400), imageType: string (cover, title, in-book, title-with-text), style: string (modern, classic, minimalist, professional, artistic), aspectRatio: string (16:9, 9:16, 1:1, 4:3, 3:4), hasText: boolean (Titelbild mit Text?), imagesInBook: boolean (Bilder im eBook?), imageCount: number (Anzahl Bilder im eBook) }. Wenn ein Parameter nicht im Text erwähnt wird, verwende null (nicht einen Standard-Wert).' }, { role: 'user', content: (() => { try { const extractData = $('Extract Chat Input').item.json || {}; const chatInput = extractData.chatInput || extractData.message || ''; return 'Analysiere folgende E-Book-Anfrage und extrahiere alle Parameter: ' + chatInput; } catch (e) { return 'Analysiere folgende E-Book-Anfrage und extrahiere alle Parameter: ' + ($json.chatInput || $json.message || ''); } })() }], temperature: 0.3 }) }}","options":{}},"id":"groq-intelligent-parse","name":"DeepSeek Intelligent Parse","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[-2672,-368],"alwaysOutputData":true,"credentials":{"httpHeaderAuth":{"id":"Y6Cp0o6zzWX3U7sx","name":"Deepgram TTS"},"deepSeekApi":{"id":"ZDG2m0jA1qkyUnC3","name":"DeepSeek"}},"disabled":true},{"parameters":{"jsCode":"// Verarbeite Groq Intelligent Parse Response\n// Extrahiert strukturierte Daten aus Groq API Response\n// Fallback auf Regex-Patterns, falls Groq fehlschlägt\n// FIXED: Verbesserte Regex-Patterns für \"Thema X\" und \"ebook über X\" Format\n// ERWEITERT: Verbessertes Logging für Topic-Tracking\n// KRITISCH: Chat-Input muss IMMER vorhanden sein - hole von mehreren Quellen\nconst inputData = $input.first().json || {};\n\nconsole.log('[Process DeepSeek Parse] ===== TOPIC EXTRACTION START =====');\nconsole.log('[Process DeepSeek Parse] Input Data keys:', Object.keys(inputData));\nconsole.log('[Process DeepSeek Parse] Input Data chatInput:', inputData.chatInput);\nconsole.log('[Process DeepSeek Parse] Input Data message:', inputData.message);\n\n// KRITISCH: Hole Chat Input von MEHREREN Quellen (Priorität: Input > Extract Chat Input > DeepSeek Chat Trigger)\nlet chatInput = '';\n\n// Priorität 1: Input-Daten direkt (von DeepSeek Intelligent Parse)\nif (inputData.chatInput || inputData.message) {\n  chatInput = inputData.chatInput || inputData.message || '';\n  console.log('[Process DeepSeek Parse] ✅ Chat Input von Input Data:', chatInput);\n}\n\n// Priorität 2: Extract Chat Input Node\nif (!chatInput || chatInput.trim().length === 0) {\n  try {\n    const extractData = $('Extract Chat Input').item.json || {};\n    chatInput = extractData.chatInput || extractData.message || '';\n    if (chatInput && chatInput.trim().length > 0) {\n      console.log('[Process DeepSeek Parse] ✅ Chat Input von Extract Chat Input:', chatInput);\n    }\n  } catch (e) {\n    console.log('[Process DeepSeek Parse] Extract Chat Input not found:', e.message);\n  }\n}\n\n// Priorität 3: DeepSeek Chat Trigger (falls alles andere fehlschlägt)\nif (!chatInput || chatInput.trim().length === 0) {\n  try {\n    const triggerData = $('DeepSeek Chat Trigger').item.json || {};\n    chatInput = triggerData.chatInput || triggerData.message || '';\n    if (chatInput && chatInput.trim().length > 0) {\n      console.log('[Process DeepSeek Parse] ✅ Chat Input von DeepSeek Chat Trigger:', chatInput);\n    }\n  } catch (e) {\n    console.log('[Process DeepSeek Parse] DeepSeek Chat Trigger not found:', e.message);\n  }\n}\n\nif (!chatInput || chatInput.trim().length === 0) {\n  console.warn('[Process DeepSeek Parse] ⚠️ KEIN CHAT-INPUT GEFUNDEN!');\n  console.warn('[Process DeepSeek Parse] Input Data:', JSON.stringify(inputData, null, 2));\n}\n\nconsole.log('[Process DeepSeek Parse] Chat Input (raw):', chatInput);\nconsole.log('[Process DeepSeek Parse] Chat Input length:', chatInput.length);\n\n// Versuche Groq Response zu parsen\nlet groqParsedData = null;\n\ntry {\n  if (inputData.choices && inputData.choices[0] && inputData.choices[0].message) {\n    const content = inputData.choices[0].message.content || '';\n    console.log('[Process DeepSeek Parse] Groq Response Content length:', content.length);\n    const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n    if (jsonMatch) {\n      groqParsedData = JSON.parse(jsonMatch[0]);\n      console.log('[Process DeepSeek Parse] ✅ Groq Response erfolgreich geparst');\n      console.log('[Process DeepSeek Parse] Groq Data keys:', Object.keys(groqParsedData));\n      console.log('[Process DeepSeek Parse] Groq Topic:', groqParsedData.topic);\n    } else {\n      console.log('[Process DeepSeek Parse] ⚠️ Kein JSON in Groq Response gefunden');\n    }\n  } else {\n    console.log('[Process DeepSeek Parse] ⚠️ Keine choices in Groq Response');\n  }\n} catch (e) {\n  console.error('[Process DeepSeek Parse] ❌ Parse Error:', e.message);\n}\n\n// Fallback: Regex-Patterns (falls Groq fehlschlägt)\nlet fallbackData = {\n  textType: null,\n  coverImageType: null,\n  chapterCount: null,\n  wordsPerChapter: null,\n  topic: null,\n  imageType: null,\n  style: null,\n  aspectRatio: null,\n  hasText: null,\n  imagesInBook: null,\n  imageCount: null\n};\n\n// FIXED: Verbesserte Regex-Patterns für \"Thema X\" und \"ebook über X\" Format\n// WICHTIG: Nur wenn Chat-Input vorhanden ist\nif (chatInput && chatInput.trim().length > 0) {\n  if (!groqParsedData || !groqParsedData.topic) {\n    console.log('[Process DeepSeek Parse] 🔍 Verwende Regex-Patterns für Topic-Extraktion');\n    const topicPatterns = [\n      // Pattern 1: \"Thema X\" (höchste Priorität - häufigste Eingabe)\n      { pattern: /(?:thema|topic)[\\s:]+([^\\n,.!?]+)/i, name: '\"Thema X\" Format' },\n      // Pattern 2: \"ebook über X\" oder \"ebook über X\"\n      { pattern: /(?:ebook|e-book|buch|book)[\\s]+(?:über|ueber|about|zum|zur|für|zu)[\\s]+([^\\n,.!?]+)/i, name: '\"ebook über X\" Format' },\n      // Pattern 3: \"über X\" (ohne ebook)\n      { pattern: /(?:über|ueber|about)[\\s]+([^\\n,.!?]+)/i, name: '\"über X\" Format' },\n      // Pattern 4: \"X ebook\" oder \"X buch\"\n      { pattern: /([^\\n,.!?]+)[\\s]+(?:ebook|e-book|buch|book)/i, name: '\"X ebook\" Format' }\n    ];\n    \n    for (const { pattern, name } of topicPatterns) {\n      const match = chatInput.match(pattern);\n      if (match && match[1]) {\n        fallbackData.topic = match[1].trim();\n        console.log(`[Process DeepSeek Parse] ✅ Pattern \"${name}\" matched:`, fallbackData.topic);\n        \n        // Entferne Artikel am Anfang\n        const beforeArticle = fallbackData.topic;\n        fallbackData.topic = fallbackData.topic.replace(/^(?:ein|eine|der|die|das|the|a|an)\\s+/i, '');\n        if (beforeArticle !== fallbackData.topic) {\n          console.log('[Process DeepSeek Parse] Artikel entfernt:', beforeArticle, '->', fallbackData.topic);\n        }\n        \n        // Entferne \"ebook\" oder \"buch\" am Ende, falls vorhanden\n        const beforeEbook = fallbackData.topic;\n        fallbackData.topic = fallbackData.topic.replace(/\\s+(?:ebook|e-book|buch|book)$/i, '');\n        if (beforeEbook !== fallbackData.topic) {\n          console.log('[Process DeepSeek Parse] E-Book/Buch am Ende entfernt:', beforeEbook, '->', fallbackData.topic);\n        }\n        \n        // Entferne \"thema\" oder \"topic\" am Anfang, falls vorhanden\n        const beforeThema = fallbackData.topic;\n        fallbackData.topic = fallbackData.topic.replace(/^(?:thema|topic)[\\s:]+/i, '');\n        if (beforeThema !== fallbackData.topic) {\n          console.log('[Process DeepSeek Parse] Thema/Topic am Anfang entfernt:', beforeThema, '->', fallbackData.topic);\n        }\n        \n        console.log('[Process DeepSeek Parse] ✅ Final Topic aus Regex:', fallbackData.topic);\n        break;\n      } else {\n        console.log(`[Process DeepSeek Parse] ❌ Pattern \"${name}\" nicht matched`);\n      }\n    }\n    \n    // FALLBACK: Wenn kein Pattern matcht, verwende den gesamten Chat-Input als Topic\n    if (!fallbackData.topic && chatInput.trim().length > 0) {\n      console.log('[Process DeepSeek Parse] 🔄 Kein Pattern matched, verwende gesamten Chat-Input als Topic');\n      fallbackData.topic = chatInput.trim();\n      // Entferne häufige Präfixe\n      const beforeClean = fallbackData.topic;\n      fallbackData.topic = fallbackData.topic.replace(/^(?:thema|topic|ebook|e-book|buch|book|über|ueber|about)[\\s:]+/i, '');\n      if (beforeClean !== fallbackData.topic) {\n        console.log('[Process DeepSeek Parse] Präfixe entfernt:', beforeClean, '->', fallbackData.topic);\n      }\n      console.log('[Process DeepSeek Parse] ✅ Topic aus gesamten Chat-Input:', fallbackData.topic);\n    }\n  } else {\n    console.log('[Process DeepSeek Parse] ✅ Topic bereits von Groq API erhalten:', groqParsedData.topic);\n  }\n  \n  // Extrahiere chapterCount und wordsPerChapter aus Chat-Input\n  if (!groqParsedData || groqParsedData.chapterCount === null || groqParsedData.chapterCount === undefined) {\n    const chapterPatterns = [\n      /(?:kapitel|chapters)[\\s:]+(\\d+)/i,\n      /(\\d+)[\\s]+kapitel/i,\n      /(\\d+)[\\s]+kapiteln/i,\n      /mit[\\s]+(\\d+)[\\s]+kapitel/i\n    ];\n    \n    for (const pattern of chapterPatterns) {\n      const match = chatInput.match(pattern);\n      if (match) {\n        fallbackData.chapterCount = parseInt(match[1] || match[0], 10);\n        if (fallbackData.chapterCount > 0 && fallbackData.chapterCount <= 20) {\n          console.log('[Process DeepSeek Parse] ✅ ChapterCount aus Regex:', fallbackData.chapterCount);\n          break;\n        }\n      }\n    }\n  }\n  \n  if (!groqParsedData || groqParsedData.wordsPerChapter === null || groqParsedData.wordsPerChapter === undefined) {\n    const wordsPatterns = [\n      /(?:a|à|à|a)[\\s]+(\\d+)[\\s]+wörtern?/i,\n      /(?:pro[\\s]+)?kapitel[\\s]+(?:a|à|à|a)[\\s]+(\\d+)[\\s]+wörtern?/i,\n      /(\\d+)[\\s]+wörtern?[\\s]+(?:pro[\\s]+)?kapitel/i\n    ];\n    \n    for (const pattern of wordsPatterns) {\n      const match = chatInput.match(pattern);\n      if (match) {\n        fallbackData.wordsPerChapter = parseInt(match[1] || match[0], 10);\n        if (fallbackData.wordsPerChapter > 0 && fallbackData.wordsPerChapter <= 5000) {\n          console.log('[Process DeepSeek Parse] ✅ WordsPerChapter aus Regex:', fallbackData.wordsPerChapter);\n          break;\n        }\n      }\n    }\n  }\n} else {\n  console.warn('[Process DeepSeek Parse] ⚠️ KEIN CHAT-INPUT - Kann keine Regex-Extraktion durchführen!');\n}\n\n// Kombiniere Groq-Daten mit Fallback-Daten\n// Priorität: Groq-Daten > Fallback-Daten\n// WICHTIG: null bedeutet, dass Parameter nicht gefunden wurde (kein Standard-Wert!)\nconst finalData = {\n  chatInput: chatInput, // WICHTIG: Chat-Input immer weiterleiten\n  topic: groqParsedData?.topic || fallbackData.topic || null,\n  textType: groqParsedData?.textType || fallbackData.textType || null,\n  coverImageType: groqParsedData?.coverImageType || fallbackData.coverImageType || null,\n  chapterCount: groqParsedData?.chapterCount !== null && groqParsedData?.chapterCount !== undefined ? groqParsedData.chapterCount : (fallbackData.chapterCount !== null ? fallbackData.chapterCount : null),\n  wordsPerChapter: groqParsedData?.wordsPerChapter !== null && groqParsedData?.wordsPerChapter !== undefined ? groqParsedData.wordsPerChapter : (fallbackData.wordsPerChapter !== null ? fallbackData.wordsPerChapter : null),\n  imageType: groqParsedData?.imageType || fallbackData.imageType || null,\n  style: groqParsedData?.style || fallbackData.style || null,\n  aspectRatio: groqParsedData?.aspectRatio || fallbackData.aspectRatio || null,\n  hasText: groqParsedData?.hasText !== null && groqParsedData?.hasText !== undefined ? groqParsedData.hasText : (fallbackData.hasText !== null ? fallbackData.hasText : null),\n  imagesInBook: groqParsedData?.imagesInBook !== null && groqParsedData?.imagesInBook !== undefined ? groqParsedData.imagesInBook : (fallbackData.imagesInBook !== null ? fallbackData.imagesInBook : null),\n  imageCount: groqParsedData?.imageCount || fallbackData.imageCount || null,\n  _fromGroq: !!groqParsedData,\n  _fromFallback: !groqParsedData && (fallbackData.topic || fallbackData.chapterCount || fallbackData.wordsPerChapter),\n  _source: groqParsedData?.topic ? 'groq' : (fallbackData.topic ? 'regex' : 'none')\n};\n\n// Berechne Gesamt-Wortanzahl (nur wenn beide Werte vorhanden)\nif (finalData.chapterCount && finalData.wordsPerChapter) {\n  finalData.totalWords = finalData.chapterCount * finalData.wordsPerChapter;\n  finalData.minWordCount = finalData.totalWords;\n} else {\n  finalData.totalWords = null;\n  finalData.minWordCount = null;\n}\n\nconsole.log('[Process DeepSeek Parse] ===== TOPIC EXTRACTION END =====');\nconsole.log('[Process DeepSeek Parse] ✅ FINAL TOPIC:', finalData.topic);\nconsole.log('[Process DeepSeek Parse] Topic Source:', finalData._source);\nconsole.log('[Process DeepSeek Parse] From Groq:', finalData._fromGroq);\nconsole.log('[Process DeepSeek Parse] From Fallback:', finalData._fromFallback);\nconsole.log('[Process DeepSeek Parse] Final Data:');\nconsole.log('  Chat Input:', finalData.chatInput);\nconsole.log('  Topic:', finalData.topic);\nconsole.log('  Text Type:', finalData.textType);\nconsole.log('  Cover Image Type:', finalData.coverImageType);\nconsole.log('  Chapter Count:', finalData.chapterCount);\nconsole.log('  Words Per Chapter:', finalData.wordsPerChapter);\nconsole.log('  Total Words:', finalData.totalWords);\n\nreturn [{ json: finalData }];"},"id":"process-groq-parse","name":"Process DeepSeek Parse","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2272,-368],"disabled":true},{"parameters":{"jsCode":"// ERWEITERT: Kombiniere gespeicherte Proposal-Daten mit Marktanalyse-Daten\n// Supabase gibt nur die gespeicherten Felder zurück, nicht die zusätzlichen Felder (chapterCount, wordsPerChapter, etc.)\n// Dieser Node kombiniert die gespeicherten Daten mit den Marktanalyse-Daten\n// KRITISCH: Hole topic von Intelligent Market Analysis (Trendanalyse), NICHT vom Chat-Input\nconst savedProposal = $input.first().json || {};\n\nconsole.log('[Merge Proposal] ===== MERGE PROPOSAL WITH MARKET DATA START =====');\nconsole.log('[Merge Proposal] Saved Proposal keys:', Object.keys(savedProposal));\nconsole.log('[Merge Proposal] Saved Proposal topic:', savedProposal.topic);\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (Trendanalyse) - HÖCHSTE PRIORITÄT\nlet marketTopic = null;\nlet marketChapterCount = null;\nlet marketWordsPerChapter = null;\n\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').first().json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  marketChapterCount = marketData.chapterCount !== null && marketData.chapterCount !== undefined ? marketData.chapterCount : null;\n  marketWordsPerChapter = marketData.wordsPerChapter !== null && marketData.wordsPerChapter !== undefined ? marketData.wordsPerChapter : null;\n  console.log('[Merge Proposal] ✅ Intelligent Market Analysis gefunden');\n  console.log('[Merge Proposal] Market-Topic:', marketTopic);\n  console.log('[Merge Proposal] Market-ChapterCount:', marketChapterCount);\n  console.log('[Merge Proposal] Market-WordsPerChapter:', marketWordsPerChapter);\n} catch (e) {\n  console.log('[Merge Proposal] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Fallback: Hole von Generate E-Book Suggestions\nlet suggestionTopic = null;\nlet suggestionChapterCount = null;\nlet suggestionWordsPerChapter = null;\n\ntry {\n  const suggestionData = $('Generate E-Book Suggestions').first().json || {};\n  suggestionTopic = suggestionData.topic || suggestionData.thema || null;\n  suggestionChapterCount = suggestionData.chapterCount !== null && suggestionData.chapterCount !== undefined ? suggestionData.chapterCount : null;\n  suggestionWordsPerChapter = suggestionData.wordsPerChapter !== null && suggestionData.wordsPerChapter !== undefined ? suggestionData.wordsPerChapter : null;\n  console.log('[Merge Proposal] ✅ Generate E-Book Suggestions gefunden');\n  console.log('[Merge Proposal] Suggestion-Topic:', suggestionTopic);\n} catch (e) {\n  console.log('[Merge Proposal] ⚠️ Generate E-Book Suggestions not found');\n}\n\n// Hole Input-Daten (von Add Volume Number to Proposal)\n// Diese enthalten chapterCount, wordsPerChapter, etc.\nlet inputData = {};\ntry {\n  inputData = $('Add Volume Number to Proposal').first().json || {};\n  console.log('[Merge Proposal] ✅ Add Volume Number to Proposal gefunden');\n  console.log('[Merge Proposal] Input Data keys:', Object.keys(inputData));\n  console.log('[Merge Proposal] Input chapterCount:', inputData.chapterCount);\n  console.log('[Merge Proposal] Input wordsPerChapter:', inputData.wordsPerChapter);\n  console.log('[Merge Proposal] Input topic:', inputData.topic);\n} catch (e) {\n  console.log('[Merge Proposal] ⚠️ Add Volume Number to Proposal not found');\n  // Versuche von Filter Empty Proposals\n  try {\n    inputData = $('Filter Empty Proposals').first().json || {};\n    console.log('[Merge Proposal] Filter Empty Proposals gefunden');\n  } catch (e2) {\n    console.log('[Merge Proposal] Filter Empty Proposals not found');\n  }\n}\n\nconsole.log('[Merge Proposal] Topic-Priorität:');\nconsole.log('  Market-Topic (Intelligent Market Analysis):', marketTopic || '(nicht vorhanden)');\nconsole.log('  Suggestion-Topic (Generate E-Book Suggestions):', suggestionTopic || '(nicht vorhanden)');\nconsole.log('  Saved Proposal Topic:', savedProposal.topic || '(nicht vorhanden)');\nconsole.log('  Input Topic:', inputData.topic || '(nicht vorhanden)');\n\n// ERWEITERT: Kombiniere gespeicherte Daten mit Marktanalyse-Daten\n// Priorität für topic: Market Topic (Trendanalyse) > Suggestion Topic > Gespeicherte Daten > Input-Daten\n// KRITISCH: Alle Felder müssen vorhanden sein, da Telegram-Notification danach kommt\nconst mergedData = {\n  ...savedProposal, // Gespeicherte Daten haben Priorität\n  // WICHTIG: Topic hat höchste Priorität von Intelligent Market Analysis\n  topic: marketTopic || suggestionTopic || savedProposal.topic || inputData.topic || null,\n  thema: marketTopic || suggestionTopic || savedProposal.topic || inputData.topic || null, // Auch thema setzen für Konsistenz\n  // ERWEITERT: Füge Marktanalyse-Daten hinzu (werden nicht in Supabase gespeichert, aber durch Kette weitergegeben)\n  chapterCount: marketChapterCount !== null ? marketChapterCount : (suggestionChapterCount !== null ? suggestionChapterCount : (inputData.chapterCount !== undefined ? inputData.chapterCount : (savedProposal.chapterCount !== undefined ? savedProposal.chapterCount : null))),\n  wordsPerChapter: marketWordsPerChapter !== null ? marketWordsPerChapter : (suggestionWordsPerChapter !== null ? suggestionWordsPerChapter : (inputData.wordsPerChapter !== undefined ? inputData.wordsPerChapter : (savedProposal.wordsPerChapter !== undefined ? savedProposal.wordsPerChapter : null))),\n  textType: inputData.textType || savedProposal.textType || null,\n  coverImageType: inputData.coverImageType || savedProposal.coverImageType || null,\n  imageType: inputData.imageType || savedProposal.imageType || null,\n  style: inputData.style || savedProposal.style || null,\n  aspectRatio: inputData.aspectRatio || savedProposal.aspectRatio || null,\n  hasText: inputData.hasText !== undefined ? inputData.hasText : (savedProposal.hasText !== undefined ? savedProposal.hasText : null),\n  imagesInBook: inputData.imagesInBook !== undefined ? inputData.imagesInBook : (savedProposal.imagesInBook !== undefined ? savedProposal.imagesInBook : null),\n  imageCount: inputData.imageCount !== undefined ? inputData.imageCount : (savedProposal.imageCount !== undefined ? savedProposal.imageCount : null),\n  _topicSource: marketTopic ? 'market' : (suggestionTopic ? 'suggestion' : (savedProposal.topic ? 'saved' : (inputData.topic ? 'input' : 'none')))\n};\n\nconsole.log('[Merge Proposal] ===== MERGE PROPOSAL WITH MARKET DATA END =====');\nconsole.log('[Merge Proposal] ✅ Final Topic (Priorität: Market > Suggestion > Saved > Input):', mergedData.topic);\nconsole.log('[Merge Proposal] ✅ Final Thema:', mergedData.thema);\nconsole.log('[Merge Proposal] Topic Source:', mergedData._topicSource);\nconsole.log('[Merge Proposal] Chapter Count:', mergedData.chapterCount);\nconsole.log('[Merge Proposal] Words Per Chapter:', mergedData.wordsPerChapter);\nconsole.log('[Merge Proposal] Volume Number:', mergedData.volume_number);\nconsole.log('[Merge Proposal] ⚠️ WICHTIG: Diese Daten gehen an Telegram-Notification!');\n\nreturn [{ json: mergedData }];"},"id":"merge-proposal-with-chat-data","name":"Merge Proposal with Chat Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[816,288]},{"parameters":{"jsCode":"// Sicherstellen dass alle Daten für Telegram-Notification vorhanden sind\n// KRITISCH: Hole Topic von Trendanalyse (Intelligent Market Analysis), NICHT vom Chat-Input\nconst inputData = $input.first().json || {};\n\nconsole.log('[Ensure Proposal Data] ===== ENSURE PROPOSAL DATA FOR TELEGRAM START =====');\nconsole.log('[Ensure Proposal Data] Input Data keys:', Object.keys(inputData));\n\n// WICHTIG: Hole Topic von Intelligent Market Analysis (Trendanalyse) - HÖCHSTE PRIORITÄT\nlet marketTopic = null;\nlet marketChapterCount = null;\nlet marketWordsPerChapter = null;\n\ntry {\n  const marketData = $('Intelligent Market Analysis (MCP)').first().json || {};\n  marketTopic = marketData.topic || marketData.thema || null;\n  marketChapterCount = marketData.chapterCount !== null && marketData.chapterCount !== undefined ? marketData.chapterCount : null;\n  marketWordsPerChapter = marketData.wordsPerChapter !== null && marketData.wordsPerChapter !== undefined ? marketData.wordsPerChapter : null;\n  console.log('[Ensure Proposal Data] ✅ Topic von Intelligent Market Analysis:', marketTopic);\n  console.log('[Ensure Proposal Data] ✅ ChapterCount:', marketChapterCount);\n  console.log('[Ensure Proposal Data] ✅ WordsPerChapter:', marketWordsPerChapter);\n} catch (e) {\n  console.log('[Ensure Proposal Data] ⚠️ Intelligent Market Analysis not found:', e.message);\n}\n\n// Fallback: Hole von Generate E-Book Suggestions\nlet suggestionTopic = null;\nlet suggestionChapterCount = null;\nlet suggestionWordsPerChapter = null;\n\ntry {\n  const suggestionData = $('Generate E-Book Suggestions').first().json || {};\n  suggestionTopic = suggestionData.topic || suggestionData.thema || null;\n  suggestionChapterCount = suggestionData.chapterCount !== null && suggestionData.chapterCount !== undefined ? suggestionData.chapterCount : null;\n  suggestionWordsPerChapter = suggestionData.wordsPerChapter !== null && suggestionData.wordsPerChapter !== undefined ? suggestionData.wordsPerChapter : null;\n  console.log('[Ensure Proposal Data] ✅ Topic von Generate E-Book Suggestions:', suggestionTopic);\n} catch (e) {\n  console.log('[Ensure Proposal Data] ⚠️ Generate E-Book Suggestions not found:', e.message);\n}\n\n// Priorität: Market Topic (Trendanalyse) > Suggestion Topic > Input Data\nconst ensuredData = {\n  ...inputData,\n  topic: marketTopic || suggestionTopic || inputData.topic || inputData.thema || null,\n  thema: marketTopic || suggestionTopic || inputData.thema || inputData.topic || null,\n  chapterCount: marketChapterCount !== null ? marketChapterCount : (suggestionChapterCount !== null ? suggestionChapterCount : (inputData.chapterCount !== undefined && inputData.chapterCount !== null ? inputData.chapterCount : null)),\n  wordsPerChapter: marketWordsPerChapter !== null ? marketWordsPerChapter : (suggestionWordsPerChapter !== null ? suggestionWordsPerChapter : (inputData.wordsPerChapter !== undefined && inputData.wordsPerChapter !== null ? inputData.wordsPerChapter : null)),\n  volume_number: inputData.volume_number || 1,\n  approval_status: inputData.approval_status || 'pending'\n};\n\nconsole.log('[Ensure Proposal Data] ===== ENSURE PROPOSAL DATA FOR TELEGRAM END =====');\nconsole.log('[Ensure Proposal Data] ✅ Final Data:');\nconsole.log('  Topic (von Trendanalyse):', ensuredData.topic);\nconsole.log('  Thema:', ensuredData.thema);\nconsole.log('  ChapterCount:', ensuredData.chapterCount);\nconsole.log('  WordsPerChapter:', ensuredData.wordsPerChapter);\nconsole.log('  Volume Number:', ensuredData.volume_number);\nconsole.log('  Approval Status:', ensuredData.approval_status);\n\nreturn [{ json: ensuredData }];"},"id":"ensure-proposal-data-for-telegram","name":"Ensure Proposal Data for Telegram","type":"n8n-nodes-base.code","typeVersion":2,"position":[1040,288]},{"parameters":{"jsCode":"// Prepare Telegram Data\n// Extract data from input\nconst json = $input.json || {};\n\n// Ensure chatId is available\nconst chatId = json.chatId || json.telegramChatId || json.TELEGRAM_CHAT_ID || json.chat_id || '578345520';\n\n// Prepare output with all data, ensuring chatId is present\nconst output = {\n  ...json, // Keep all original data\n  chatId: chatId,\n  telegramChatId: chatId,\n  TELEGRAM_CHAT_ID: chatId\n};\n\n// Prepare checkpoint data for Supabase Node\n// This will be picked up by the next Supabase Node\nconst checkpointData = {\n  topic: json.topic || json.thema || 'Unbekannt',\n  thema: json.topic || json.thema || 'Unbekannt',\n  chapterCount: json.chapterCount || json.chapters || 0,\n  wordsPerChapter: json.wordsPerChapter || json.words_per_chapter || 0,\n  volume_number: json.volume_number || json.volumeNumber || 1,\n  approval_status: json.approval_status || json.status || 'pending',\n  proposalId: json.proposalId || json.id || json.proposal_id || null,\n  isbn: json.isbn || json.ISBN || null,\n  chatId: chatId,\n  genre: json.genre || null,\n  language: json.language || null,\n  target_audience: json.target_audience || null\n};\n\n// Add checkpoint data to output for Supabase Node\noutput.checkpointData = checkpointData;\noutput.checkpointType = 'proposal';\n\nreturn [{ json: output }];"},"id":"prepare-telegram-data","name":"Prepare Telegram Data","type":"n8n-nodes-base.code","typeVersion":2,"position":[1440,288]},{"parameters":{"jsCode":"// Merge DeepSeek API Response mit Chat Input\n// KRITISCH: DeepSeek Intelligent Parse gibt nur die API-Antwort zurück, nicht den Chat-Input\n// Dieser Node fügt den Chat-Input explizit hinzu, damit Process DeepSeek Parse ihn verwenden kann\nconst apiResponse = $input.first().json || {};\n\nconsole.log('[Merge DeepSeek Response] ===== MERGE DEEPSEEK RESPONSE WITH CHAT INPUT START =====');\nconsole.log('[Merge DeepSeek Response] API Response keys:', Object.keys(apiResponse));\n\n// Hole Chat Input von Extract Chat Input\nlet chatInput = '';\ntry {\n  const extractData = $('Extract Chat Input').item.json || {};\n  chatInput = extractData.chatInput || extractData.message || '';\n  console.log('[Merge DeepSeek Response] ✅ Chat Input von Extract Chat Input:', chatInput);\n} catch (e) {\n  console.log('[Merge DeepSeek Response] Extract Chat Input not found, trying DeepSeek Chat Trigger');\n  // Fallback: DeepSeek Chat Trigger\n  try {\n    const triggerData = $('DeepSeek Chat Trigger').item.json || {};\n    chatInput = triggerData.chatInput || triggerData.message || '';\n    console.log('[Merge DeepSeek Response] ✅ Chat Input von DeepSeek Chat Trigger:', chatInput);\n  } catch (e2) {\n    console.log('[Merge DeepSeek Response] DeepSeek Chat Trigger not found');\n  }\n}\n\nif (!chatInput || chatInput.trim().length === 0) {\n  console.warn('[Merge DeepSeek Response] ⚠️ KEIN CHAT-INPUT GEFUNDEN!');\n}\n\n// Kombiniere API Response mit Chat Input\nconst mergedData = {\n  ...apiResponse,\n  // WICHTIG: Chat Input explizit hinzufügen\n  chatInput: chatInput,\n  message: chatInput\n};\n\nconsole.log('[Merge DeepSeek Response] ===== MERGE DEEPSEEK RESPONSE WITH CHAT INPUT END =====');\nconsole.log('[Merge DeepSeek Response] ✅ Chat Input hinzugefügt:', chatInput);\nconsole.log('[Merge DeepSeek Response] Merged Data keys:', Object.keys(mergedData));\n\nreturn [{ json: mergedData }];"},"id":"merge-deepseek-response-with-chat-input","name":"Merge DeepSeek Response with Chat Input","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2512,-368],"disabled":true},{"parameters":{"jsCode":"// Generiere ISBN-13 Nummer\n// FIXED: Verwendet $input.item.json statt $input.first().json für Run Once for Each Item Modus\nconst inputData = $input.item.json || {};\n\n// Hole Topic für ISBN-Generierung\nconst topic = inputData.topic || inputData.thema || 'ebook';\nconst volumeNumber = inputData.volume_number || inputData.volumeNumber || 1;\n\n// Generiere eine eindeutige ISBN-13 basierend auf Topic und Volume\n// ISBN-13 Format: 978-3-XXXXX-XXX-X (978 = E-Book-Präfix, 3 = Deutschland)\n\n// Erstelle einen Hash aus Topic und Volume für Konsistenz\nfunction simpleHash(str) {\n  let hash = 0;\n  for (let i = 0; i < str.length; i++) {\n    const char = str.charCodeAt(i);\n    hash = ((hash << 5) - hash) + char;\n    hash = hash & hash; // Convert to 32bit integer\n  }\n  return Math.abs(hash);\n}\n\nconst hash = simpleHash(topic + volumeNumber.toString());\n\n// Generiere 9-stellige Nummer aus Hash\nconst baseNumber = (hash % 999999999).toString().padStart(9, '0');\n\n// ISBN-13 Präfix: 978-3 (E-Book, Deutschland)\nconst prefix = '9783';\nconst isbnWithoutCheck = prefix + baseNumber;\n\n// Berechne Prüfziffer (ISBN-13)\nlet sum = 0;\nfor (let i = 0; i < 12; i++) {\n  const digit = parseInt(isbnWithoutCheck[i]);\n  sum += digit * (i % 2 === 0 ? 1 : 3);\n}\nconst checkDigit = (10 - (sum % 10)) % 10;\nconst isbn13 = isbnWithoutCheck + checkDigit.toString();\n\n// Formatiere ISBN mit Bindestrichen: 978-3-XXXXX-XXX-X\nconst formattedISBN = `${isbn13.substring(0, 3)}-${isbn13.substring(3, 4)}-${isbn13.substring(4, 9)}-${isbn13.substring(9, 12)}-${isbn13.substring(12)}`;\n\n// Bereinige ISBN (nur Ziffern) für Dateinamen\nconst isbnClean = isbn13;\n\nconsole.log('[Generate ISBN] Topic:', topic);\nconsole.log('[Generate ISBN] Volume:', volumeNumber);\nconsole.log('[Generate ISBN] ISBN-13:', formattedISBN);\nconsole.log('[Generate ISBN] ISBN Clean:', isbnClean);\n\n// Kombiniere Input-Daten mit ISBN\nreturn {\n  json: {\n    ...inputData,\n    isbn: formattedISBN,\n    isbn13: isbn13,\n    isbnClean: isbnClean,\n    isbnGenerated: true\n  }\n};"},"id":"generate-isbn","name":"Generate ISBN","type":"n8n-nodes-base.code","typeVersion":2,"position":[656,128]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"// Validiere Cover-Größe und Dateiname\n// UND: Stelle sicher, dass alle relevanten Daten weitergegeben werden\n// WICHTIG: Im Modus 'Run Once for Each Item' ist $input direkt das aktuelle Item, kein Array!\n\n// Im 'Run Once for Each Item' Modus ist $input bereits das aktuelle Item\nconst json = $input.json || {};\nconst binary = $input.binary || {};\n\nconsole.log('[Validate Cover Size] ===== START =====');\nconsole.log('[Validate Cover Size] Input keys:', Object.keys(json));\n\n// Hole Cover-Daten\nconst coverBinary = binary.data || binary.cover || null;\nconst imageUrl = json.imageUrl || json.coverUrl || json.url || json.directory || '';\n\n// Generiere oder hole Dateiname\nlet filename = json.filename || json.fileName || 'cover.jpg';\n\n// Wenn kein Dateiname vorhanden, generiere einen basierend auf Title oder ID\nif (filename === 'cover.jpg') {\n  const title = json.title || json.proposal?.title || '';\n  const id = json.id || json.proposalId || json.proposal?.id || Date.now();\n  if (title) {\n    filename = title.toLowerCase().replace(/[^a-z0-9]/g, '-').substring(0, 50) + '.jpg';\n  } else {\n    filename = `cover-${id}.jpg`;\n  }\n}\n\n// Validiere Größe (wenn Binary vorhanden)\nlet isValidSize = true;\nlet sizeInfo = '';\nif (coverBinary) {\n  const sizeInBytes = coverBinary.data ? Buffer.from(coverBinary.data, 'base64').length : 0;\n  const sizeInMB = sizeInBytes / (1024 * 1024);\n  sizeInfo = `${sizeInMB.toFixed(2)} MB`;\n  \n  // Maximale Größe: 10 MB\n  if (sizeInMB > 10) {\n    isValidSize = false;\n    console.warn('[Validate Cover Size] ⚠️ Cover zu groß:', sizeInfo);\n  } else {\n    console.log('[Validate Cover Size] ✅ Cover-Größe OK:', sizeInfo);\n  }\n}\n\n// Hole ISBN und andere Metadaten aus dem Workflow-Kontext\n// Diese sollten durch die Nodes weitergegeben werden\nconst isbn = json.isbn || json.proposal?.isbn || json.ebook?.isbn || 'N/A';\nconst title = json.title || json.proposal?.title || 'E-Book';\nconst proposalId = json.proposalId || json.id || json.proposal?.id || '';\n\nconsole.log('[Validate Cover Size] Extracted:');\nconsole.log('  ISBN:', isbn);\nconsole.log('  Filename:', filename);\nconsole.log('  Size:', sizeInfo || 'N/A');\nconsole.log('  Valid:', isValidSize);\n\n// Output - WICHTIG: Alle Daten weitergeben!\nconst output = {\n  ...json, // Alle vorherigen Daten behalten\n  \n  // Cover-spezifische Daten\n  filename: filename,\n  fileName: filename, // Beide Varianten für Kompatibilität\n  coverFilename: filename,\n  \n  // Cover-Daten\n  imageUrl: imageUrl,\n  coverUrl: imageUrl,\n  \n  // Validierung\n  isValidSize: isValidSize,\n  sizeInfo: sizeInfo,\n  \n  // Metadaten (weitergeben!)\n  isbn: isbn,\n  title: title,\n  proposalId: proposalId,\n  \n  // Binary-Daten behalten (falls vorhanden)\n  ...(coverBinary && { hasBinary: true })\n};\n\nconsole.log('[Validate Cover Size] ===== END =====');\n\n// Return muss ein Array sein, auch im 'Run Once for Each Item' Modus\nreturn [{ json: output, binary: binary }];"},"id":"validate-cover-size","name":"Validate Cover Size & Filename","type":"n8n-nodes-base.code","typeVersion":2,"position":[128,768]},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.chat_id }}","text":"={{ $json.text || $json.message }}","additionalFields":{}},"id":"send-cover-for-validation","name":"Send Cover for Validation (Telegram)","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[592,768],"webhookId":"73790a04-d7d3-4e69-a748-7429274896ce","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const isbn = inputData.isbnClean || inputData.isbn || \"unknown\"; const topic = inputData.topic || inputData.thema || \"Unknown Topic\"; const volumeNumber = inputData.volume_number || 1; const title = inputData.title || topic; const author = \"Salomon F. Owona\"; const publisher = \"Owona Media\"; const publicationDate = new Date().toISOString().split(\"T\")[0]; const language = inputData.sprache || inputData.language || \"ger\"; const genre = inputData.genre || \"General\"; const competitivePrice = 4.99; const onixXML = `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ONIXMessage release=\"3.0\" xmlns=\"http://www.editeur.org/onix/3.0/reference\">\n  <Header>\n    <Sender>\n      <SenderName>${publisher}</SenderName>\n      <ContactName>OWONA Media</ContactName>\n      <EmailAddress>info@owona.de</EmailAddress>\n    </Sender>\n    <SentDateTime>${new Date().toISOString()}</SentDateTime>\n  </Header>\n  <Product>\n    <RecordReference>${isbn}</RecordReference>\n    <NotificationType>03</NotificationType>\n    <ProductIdentifier>\n      <ProductIDType>15</ProductIDType>\n      <IDValue>${isbn}</IDValue>\n    </ProductIdentifier>\n    <DescriptiveDetail>\n      <ProductComposition>00</ProductComposition>\n      <ProductForm>ED</ProductForm>\n      <TitleDetail>\n        <TitleType>01</TitleType>\n        <TitleElement>\n          <TitleElementLevel>01</TitleElementLevel>\n          <TitleText>${title}</TitleText>\n        </TitleElement>\n      </TitleDetail>\n      <Contributor>\n        <ContributorRole>A01</ContributorRole>\n        <PersonName>${author}</PersonName>\n      </Contributor>\n      <Language>\n        <LanguageCode>${language}</LanguageCode>\n      </Language>\n      <Subject>\n        <SubjectSchemeIdentifier>10</SubjectSchemeIdentifier>\n        <SubjectCode>${genre}</SubjectCode>\n      </Subject>\n    </DescriptiveDetail>\n    <PublishingDetail>\n      <Publisher>\n        <PublisherName>${publisher}</PublisherName>\n      </Publisher>\n      <PublishingDate>\n        <PublishingDateRole>01</PublishingDateRole>\n        <Date>${publicationDate}</Date>\n      </PublishingDate>\n    </PublishingDetail>\n    <ProductSupply>\n      <SupplyDetail>\n        <Price>\n          <PriceType>01</PriceType>\n          <PriceAmount>${competitivePrice.toFixed(2)}</PriceAmount>\n          <CurrencyCode>EUR</CurrencyCode>\n        </Price>\n      </SupplyDetail>\n    </ProductSupply>\n  </Product>\n</ONIXMessage>`; return { json: { ...inputData, onixFileName: isbn + \".xml\", onixContent: onixXML, onixNeedsValidation: true, competitivePrice: competitivePrice } };"},"id":"generate-onix-file","name":"Generate ONIX File","type":"n8n-nodes-base.code","typeVersion":2,"position":[544,1072]},{"parameters":{"chatId":"={{ $json.chatId || $json.telegramChatId || $json.chat_id }}","text":"={{ $json.text || $json.message }}","additionalFields":{}},"id":"send-onix-for-validation","name":"Send ONIX for Validation (Telegram)","type":"n8n-nodes-base.telegram","typeVersion":1.2,"position":[1184,1072],"webhookId":"5c14b118-6a00-4907-a94a-db25c854bcb7","credentials":{"telegramApi":{"id":"yP0Fod4gjwAszBSQ","name":"Telegram - Owona Bot"}},"onError":"continueRegularOutput"},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const onixContent = inputData.onixContent || \"\"; const onixFileName = inputData.onixFileName || \"onix.xml\"; const binaryData = Buffer.from(onixContent, \"utf8\"); return { json: { ...inputData, onixFileName: onixFileName }, binary: { data: { data: binaryData.toString(\"base64\"), mimeType: \"application/xml\", fileName: onixFileName } } };"},"id":"convert-onix-to-binary","name":"Convert ONIX to Binary","type":"n8n-nodes-base.code","typeVersion":2,"position":[768,1072]},{"parameters":{"method":"POST","url":"http://151.236.35.202/upload","authentication":"basic","sendHeaders":true,"headerParameters":{"parameters":[{"name":"Content-Type","value":"application/xml"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ $binary.data.data }}","options":{}},"id":"upload-to-epuboo","name":"Upload to epuboo (HTTP)","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1776,848],"disabled":true,"notes":"Host: 151.236.35.202\nUser: 1320@epuboo.com\nPass: uJm_p18aDq@l.H6\n\nDeaktiviert - kann später aktiviert werden.\nHinweis: Basic Auth muss in n8n Credentials konfiguriert werden."},{"parameters":{"method":"POST","url":"={{ 'https://ugsezgnkyhcmsdpohuwf.supabase.co/storage/v1/object/ebook-covers/' + ($json.onixFileName || ($json.isbnClean || $json.isbn || 'onix').replace(/[^a-zA-Z0-9]/g, '') + '.xml') }}","sendHeaders":true,"headerParameters":{"parameters":[{"name":"apikey","value":"={{ $('Load Secrets from Supabase').first().json.SUPABASE_ANON_KEY }}"},{"name":"Authorization","value":"=Bearer {{ $('Load Secrets from Supabase').first().json.SUPABASE_SERVICE_KEY }}"},{"name":"Content-Type","value":"application/xml"},{"name":"x-upsert","value":"true"}]},"sendBody":true,"specifyBody":"json","jsonBody":"={{ Buffer.from($binary.data.data, \"base64\") }}","options":{}},"id":"upload-onix-to-supabase","name":"Upload ONIX to Supabase Storage","type":"n8n-nodes-base.httpRequest","typeVersion":4.3,"position":[1776,1072],"onError":"continueRegularOutput"},{"parameters":{"resume":"webhook","options":{}},"id":"wait-for-cover-approval","name":"Wait for Cover Approval","type":"n8n-nodes-base.wait","typeVersion":1.1,"position":[736,768],"webhookId":"e47d3fa9-6866-4efa-a14b-a0e5e4bb4e76","notes":"Wartet auf Telegram-Nachricht \"ja\" vom Benutzer. Webhook-URL wird generiert."},{"parameters":{"resume":"webhook","options":{}},"id":"wait-for-onix-approval","name":"Wait for ONIX Approval","type":"n8n-nodes-base.wait","typeVersion":1.1,"position":[1376,1072],"webhookId":"7f2b78c0-2908-4ad5-acbd-e103977f677a","notes":"Wartet auf Telegram-Nachricht \"ja\" vom Benutzer. Webhook-URL wird generiert."},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const binaryData = $input.item.binary || {}; const onixFileName = inputData.onixFileName || (inputData.isbnClean || inputData.isbn || \"onix\").replace(/[^a-zA-Z0-9]/g, \"\") + \".xml\"; let onixBinary = null; if (binaryData.data && binaryData.data.data) { onixBinary = binaryData.data; } else if (inputData.onixContent) { const buffer = Buffer.from(inputData.onixContent, \"utf8\"); onixBinary = { data: buffer.toString(\"base64\"), mimeType: \"application/xml\", fileName: onixFileName }; } return { json: { ...inputData, onixFileName: onixFileName }, binary: onixBinary ? { data: onixBinary } : binaryData };"},"id":"prepare-onix-upload","name":"Prepare ONIX for Upload","type":"n8n-nodes-base.code","typeVersion":2,"position":[1600,1072]},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const chapterText = inputData.chapterText || inputData.text || inputData.content || \"\"; const targetWords = inputData.wordsPerChapter || inputData.targetWords || 1000; const minWords = Math.floor(targetWords * 0.8); const wordCount = chapterText.trim().split(/\\s+/).filter(word => word.length > 0).length; const needsExtension = wordCount < minWords; const wordsNeeded = needsExtension ? minWords - wordCount : 0; return [{ json: { ...inputData, chapterText: chapterText, wordCount: wordCount, targetWords: targetWords, minWords: minWords, needsExtension: needsExtension, wordsNeeded: wordsNeeded } }];"},"id":"check-chapter-word-count","name":"Check Chapter Word Count","type":"n8n-nodes-base.code","typeVersion":2,"position":[-2272,1072]},{"parameters":{"conditions":{"options":{"caseSensitive":true,"leftValue":"","typeValidation":"strict"},"conditions":[{"id":"1","leftValue":"={{ $json.needsExtension }}","rightValue":true,"operator":{"type":"boolean","operation":"true"}}],"combinator":"and"},"options":{}},"id":"check-needs-extension","name":"Check: Needs Extension?","type":"n8n-nodes-base.if","typeVersion":2,"position":[-2096,1072],"onError":"continueErrorOutput"},{"parameters":{"workflowId":"RgISyJGT9LvWYfSi","options":{}},"id":"extend-chapter-content","name":"Extend Chapter Content","type":"n8n-nodes-base.executeWorkflow","typeVersion":1,"position":[-1728,1008]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const inputData = $input.item.json || {}; const extendedText = inputData.chapterText || inputData.text || inputData.content || \"\"; const originalText = inputData.existingContent || \"\"; const mergedText = originalText + \"\\n\\n\" + extendedText; const wordCount = mergedText.trim().split(/\\s+/).filter(word => word.length > 0).length; return [{ json: { ...inputData, chapterText: mergedText, text: mergedText, content: mergedText, wordCount: wordCount, wasExtended: true } }];"},"id":"merge-extended-content","name":"Merge Extended Content","type":"n8n-nodes-base.code","typeVersion":2,"position":[-1520,1008]},{"parameters":{"jsCode":"const inputData = $input.item.json || {}; const fullText = inputData.fullText || inputData.content || \"\"; const genre = inputData.genre || \"General\"; const topic = inputData.topic || inputData.thema || \"\"; const expertGuidance = { \"Business\": \"Nutze bewährte Business-Strategien, Fallstudien und praxisorientierte Methoden. Integriere Erkenntnisse erfolgreicher Unternehmer und Management-Experten.\", \"Technology\": \"Nutze aktuelle Technologietrends, Best Practices aus der Software-Entwicklung und Erkenntnisse führender Tech-Experten. Stelle technische Konzepte verständlich dar.\", \"Health\": \"Nutze evidenzbasierte Gesundheitsinformationen, wissenschaftliche Studien und Praktiken erfahrener Mediziner. Stelle medizinische Informationen verständlich und verantwortungsvoll dar.\", \"Self-Help\": \"Nutze bewährte Selbsthilfe-Techniken, psychologische Erkenntnisse und Methoden erfolgreicher Coaches. Fokussiere auf praktische Umsetzbarkeit.\", \"Fiction\": \"Nutze bewährte Erzähltechniken, Charakterentwicklung und Plot-Strukturen erfolgreicher Roman-Autoren. Erschaffe fesselnde und emotionale Geschichten.\", \"Education\": \"Nutze bewährte pädagogische Methoden, didaktische Ansätze und Erkenntnisse erfahrener Pädagogen. Strukturiere Inhalte lernfreundlich.\", \"General\": \"Nutze bewährte Kommunikationstechniken, Strukturierungsmethoden und Erkenntnisse erfolgreicher Sachbuch-Autoren. Stelle Informationen klar und ansprechend dar.\" }; const guidance = expertGuidance[genre] || expertGuidance[\"General\"]; const enhancementPrompt = `Als Experte für ${genre}-Inhalte, prüfe und verbessere den folgenden Text. ${guidance}\\n\\n**Text:**\\n${fullText.substring(0, 5000)}\\n\\n**Thema:** ${topic}\\n\\n**Aufgabe:**\\n- Prüfe die Qualität und Experten-Expertise\\n- Stelle sicher, dass der Text die Erfahrung der besten Autoren dieses Genres widerspiegelt\\n- Verbessere wo nötig, ohne den Stil zu ändern\\n- Gib NUR Verbesserungsvorschläge oder bestätige die Qualität`; return { json: { ...inputData, expertEnhancementPrompt: enhancementPrompt, genre: genre, expertGuidance: guidance } };"},"id":"expert-quality-enhancement","name":"Expert Quality Enhancement","type":"n8n-nodes-base.code","typeVersion":2,"position":[-640,768]},{"parameters":{"jsCode":"const allThemeAreas = [\"Business\", \"Technology\", \"Health\", \"Self-Help\", \"Fiction\", \"Education\", \"Science\", \"History\", \"Travel\", \"Cooking\", \"Sports\", \"Finance\", \"Relationships\", \"Parenting\", \"Career\", \"Marketing\", \"Design\", \"Photography\", \"Music\", \"Art\", \"Philosophy\", \"Psychology\", \"Spirituality\", \"Fitness\", \"Nutrition\", \"Environment\", \"Politics\", \"Law\", \"Real Estate\", \"Investing\"]; const triggerType = $input.first().json._triggerType || \"schedule\"; const lastUsedArea = $input.first().json._lastThemeArea || \"Business\"; const currentIndex = allThemeAreas.indexOf(lastUsedArea); const nextIndex = (currentIndex + 1) % allThemeAreas.length; const selectedArea = allThemeAreas[nextIndex]; const targetAudience = triggerType === \"schedule\" ? [\"young\", \"old\"] : [\"business\", \"private\"]; const style = triggerType === \"schedule\" ? \"professional\" : \"casual\"; return [{ json: { selectedThemeArea: selectedArea, allThemeAreas: allThemeAreas, targetAudience: targetAudience, style: style, _triggerType: triggerType, _lastThemeArea: selectedArea } }];"},"id":"rotate-theme-areas","name":"Rotate Theme Areas","type":"n8n-nodes-base.code","typeVersion":2,"position":[-880,304]},{"parameters":{"jsCode":"return [{ json: { _triggerType: \"schedule\", timestamp: new Date().toISOString() } }];"},"id":"mark-trigger-type-schedule","name":"Mark Trigger Type (Schedule)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-3376,-112]},{"parameters":{"jsCode":"return [{ json: { _triggerType: \"manual\", timestamp: new Date().toISOString() } }];"},"id":"mark-trigger-type-manual","name":"Mark Trigger Type (Manual)","type":"n8n-nodes-base.code","typeVersion":2,"position":[-3360,64]},{"parameters":{"jsCode":"// Prepare Telegram Notification\n// Extract data from input - can come from multiple sources\nconst json = $input.json || {};\n\n// Try to get chatId from multiple possible sources\nconst chatId = json.chatId || json.telegramChatId || json.TELEGRAM_CHAT_ID || json.chat_id || '578345520';\n\n// Check if we have checkpoint data from Supabase Node\n// Supabase Node output structure: { json: { data: {...}, ... } }\nlet checkpointData = null;\n\n// Try to find checkpoint data in input (could be from Supabase Node)\nif (json.data && typeof json.data === 'object') {\n  // This is likely from Supabase Node\n  checkpointData = json.data;\n} else if (json.checkpointData) {\n  // This is from previous Code Node\n  checkpointData = json.checkpointData;\n}\n\n// Merge checkpoint data with input data (checkpoint has priority for missing values)\nconst mergedData = { ...json };\n\nif (checkpointData) {\n  // Remove nested 'data' wrapper if present\n  const actualData = checkpointData.data || checkpointData;\n  \n  if (!mergedData.topic || mergedData.topic === 'Unbekannt') {\n    mergedData.topic = actualData.topic || mergedData.topic;\n  }\n  if (!mergedData.thema || mergedData.thema === 'Unbekannt') {\n    mergedData.thema = actualData.thema || actualData.topic || mergedData.thema;\n  }\n  if (!mergedData.chapterCount || mergedData.chapterCount === 0) {\n    mergedData.chapterCount = actualData.chapterCount || mergedData.chapterCount;\n  }\n  if (!mergedData.wordsPerChapter || mergedData.wordsPerChapter === 0) {\n    mergedData.wordsPerChapter = actualData.wordsPerChapter || mergedData.wordsPerChapter;\n  }\n  if (!mergedData.volume_number) {\n    mergedData.volume_number = actualData.volume_number || mergedData.volume_number;\n  }\n  if (!mergedData.approval_status) {\n    mergedData.approval_status = actualData.approval_status || mergedData.approval_status;\n  }\n}\n\n// Extract proposal data - use merged data\nlet topic = mergedData.topic || mergedData.thema || mergedData.title || 'Unbekannt';\n\n// Volume number\nconst volumeNumber = mergedData.volume_number || mergedData.volumeNumber || mergedData.volume || 1;\n\n// Status\nconst status = mergedData.approval_status || mergedData.status || mergedData.approvalStatus || 'pending';\n\n// Chapter count\nlet chapterCount = mergedData.chapterCount || mergedData.chapters || 0;\nif (typeof chapterCount === 'string') {\n  chapterCount = parseInt(chapterCount) || 0;\n}\nif (Array.isArray(mergedData.chapters)) {\n  chapterCount = mergedData.chapters.length;\n}\n\n// Words per chapter\nlet wordsPerChapter = mergedData.wordsPerChapter || mergedData.words_per_chapter || 0;\nif (typeof wordsPerChapter === 'string') {\n  wordsPerChapter = parseInt(wordsPerChapter) || 0;\n}\n\n// Build telegram message\nconst telegramMessage = `📚 Neues E-Book Proposal erstellt:\n\nThema: ${topic}\nBand: ${volumeNumber}\nStatus: ${status}\n\nKapitel: ${chapterCount}\nWörter pro Kapitel: ${wordsPerChapter}\n\nThis message was sent automatically with n8n`;\n\n// Prepare output with all necessary fields\nconst output = {\n  ...mergedData, // Keep all merged data\n  chatId: chatId,\n  telegramChatId: chatId,\n  TELEGRAM_CHAT_ID: chatId,\n  text: telegramMessage,\n  message: telegramMessage,\n  telegramMessage: telegramMessage,\n  topic: topic,\n  thema: topic,\n  volume_number: volumeNumber,\n  chapterCount: chapterCount,\n  wordsPerChapter: wordsPerChapter\n};\n\nreturn [{ json: output }];"},"id":"prepare-telegram-notification","name":"Prepare Telegram Notification","type":"n8n-nodes-base.code","typeVersion":2,"position":[1760,288]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const inputData = $input.item.json || {}; const topic = inputData.topic || inputData.thema || \"N/A\"; const volumeNumber = inputData.volume_number || 1; const status = inputData.status || \"completed\"; const finalMessage = `✅ E-Book vollständig erstellt:\n\nThema: ${topic}\nBand: ${volumeNumber}\nStatus: ${status}\n\nThis message was sent automatically with n8n`; return { json: { ...inputData, finalTelegramMessage: finalMessage } };"},"id":"prepare-final-notification","name":"Prepare Final Notification","type":"n8n-nodes-base.code","typeVersion":2,"position":[1616,1280]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"// Bereite Telegram-Nachricht für Cover-Validierung vor\n// WICHTIG: Daten sollten von Upload Cover to Supabase Storage kommen\n// Im Modus \"Run Once for Each Item\" ist $input bereits das aktuelle Item\n\n// Im \"Run Once for Each Item\" Modus ist $input bereits das aktuelle Item, kein Array\nconst json = $input.json || {};\nconst binary = $input.binary || {};\n\nconsole.log('[Prepare Cover Validation] ===== START =====');\nconsole.log('[Prepare Cover Validation] All input keys:', Object.keys(json));\nconsole.log('[Prepare Cover Validation] Input sample:', JSON.stringify(json, null, 2).substring(0, 1000));\n\n// Hole ISBN - sollte durch Nodes weitergegeben worden sein\nlet isbn = json.isbn || \n            json.proposal?.isbn || \n            json.ebook?.isbn || \n            json.data?.isbn ||\n            'N/A';\n\n// Hole Dateiname - sollte von Validate Cover Size & Filename kommen\nlet filename = json.filename || \n               json.fileName || \n               json.coverFilename || \n               json.name ||\n               'cover.jpg';\n\n// Hole Cover-URL - Supabase Upload gibt eine public URL zurück\n// Prüfe verschiedene mögliche Felder\nlet coverImage = json.publicUrl || \n                 json.public_url || \n                 json.url || \n                 json.fullPath ||\n                 json.path ||\n                 json.coverUrl || \n                 json.cover_url || \n                 json.imageUrl || \n                 json.image_url ||\n                 json.directory ||\n                 '';\n\n// Wenn path vorhanden ist, konstruiere Supabase Storage URL\nif (!coverImage && json.path) {\n  const bucket = json.bucket || 'ebooks';\n  // Versuche aus JSON oder Environment zu holen\n  const supabaseUrl = json.supabaseUrl || 'https://ugsezgnkyhcmsdpohuwf.supabase.co';\n  coverImage = `${supabaseUrl}/storage/v1/object/public/${bucket}/${json.path}`;\n  console.log('[Prepare Cover Validation] Konstruierte Supabase URL:', coverImage);\n}\n\n// Hole weitere Metadaten\nconst title = json.title || json.proposal?.title || json.ebook?.title || 'E-Book';\nconst proposalId = json.proposalId || json.id || json.proposal?.id || '';\n\nconsole.log('[Prepare Cover Validation] Extracted values:');\nconsole.log('  ISBN:', isbn);\nconsole.log('  Filename:', filename);\nconsole.log('  Cover Image URL:', coverImage ? (coverImage.substring(0, 100) + '...') : 'NICHT GEFUNDEN');\nconsole.log('  Title:', title);\nconsole.log('  Proposal ID:', proposalId);\n\n// Formatiere Telegram-Nachricht\nconst telegramMessage = `📷 E-Book Cover zur Validierung:\n\nISBN: ${isbn}\nDateiname: ${filename}\n\nBitte antworten Sie mit ja zur Bestätigung.\n\n${coverImage ? `📸 Cover-Bild:\n${coverImage}` : '⚠️ Cover-Bild konnte nicht geladen werden'}\n\nDateiname: ${filename}\n\nBitte antworte mit \"Ja\" zum Fortfahren oder \"Nein\" zum Regenerieren.`;\n\n// Output für Telegram Node\nconst output = {\n  // Telegram sendMessage erwartet: chatId, text\n  chatId: json.chatId || json.telegramChatId || json.chat_id || undefined,\n  text: telegramMessage,\n  \n  // Speichere die extrahierten Werte für Debugging und spätere Nodes\n  isbn: isbn,\n  filename: filename,\n  coverImage: coverImage,\n  coverUrl: coverImage,\n  title: title,\n  proposalId: proposalId,\n  \n  // Alle Original-Daten behalten\n  ...(Object.keys(json).reduce((acc, key) => {\n    if (!['chatId', 'telegramChatId', 'chat_id', 'text'].includes(key)) {\n      acc[key] = json[key];\n    }\n    return acc;\n  }, {}))\n};\n\nconsole.log('[Prepare Cover Validation] ===== END =====');\n\nreturn [{ json: output }];"},"id":"prepare-cover-validation","name":"Prepare Cover Validation","type":"n8n-nodes-base.code","typeVersion":2,"position":[352,768]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"const inputData = $input.item.json || {}; const isbn = inputData.isbnClean || inputData.isbn || \"N/A\"; const filename = inputData.onixFileName || \"onix.xml\"; const onixMessage = `📄 ONIX-Datei zur Validierung:\n\nISBN: ${isbn}\nDateiname: ${filename}\n\nBitte antworten Sie mit ja zur Bestätigung.`; return { json: { ...inputData, onixValidationMessage: onixMessage } };"},"id":"prepare-onix-validation","name":"Prepare ONIX Validation","type":"n8n-nodes-base.code","typeVersion":2,"position":[976,1072]},{"parameters":{"mode":"runOnceForEachItem","jsCode":"// Check approval response\nconst response = ($input.item.json.body?.message?.text || '').toLowerCase();\nconst inputData = $input.item.json || {};\n\n// Preserve cover URL and filename from previous steps\nconst coverData = {\n  coverImageUrl: inputData.coverImageUrl,\n  coverImageFileName: inputData.coverImageFileName\n};\n\n// Check for approval\nif (response.includes('ja') || response.includes('yes') || response.includes('approved') || response.includes('ok')) {\n  // Approved - route to Output 0 (continue to PDF generation)\n  return { json: { ...inputData, ...coverData, _approved: true }, pairedItem: { item: 0, output: 0 } };\n} else {\n  // Rejected - route to Output 1 for regeneration\n  return { json: { ...inputData, ...coverData, _rejected: true }, pairedItem: { item: 0, output: 1 } };\n}"},"id":"0bc09476-652f-49ba-8c2a-1f916fd0e80a","name":"Check Cover Approval Response","type":"n8n-nodes-base.code","typeVersion":2,"position":[896,560],"onError":"continueErrorOutput"},{"parameters":{"jsCode":"// Prepare for cover regeneration with variation\nconst inputData = $input.item.json || {};\n\n// Note: Old cover is already uploaded to Supabase\n// We'll generate a new one and it will overwrite the old one with same ISBN filename\n\n// Add variation to the prompt\nconst variations = [\n  'alternative composition',\n  'different color scheme',\n  'varied perspective',\n  'modified layout',\n  'alternative style'\n];\n\nconst randomVariation = variations[Math.floor(Math.random() * variations.length)];\n\n// Modify the image generation parameters\nconst modifiedData = {\n  ...inputData,\n  textSummary: (inputData.textSummary || '') + '. ' + randomVariation,\n  regenerationAttempt: (inputData.regenerationAttempt || 0) + 1,\n  _regeneration: true\n};\n\nconsole.log('[Cover Regeneration] Attempt:', modifiedData.regenerationAttempt);\nconsole.log('[Cover Regeneration] Variation:', randomVariation);\nconsole.log('[Cover Regeneration] Old cover will be overwritten');\n\nreturn [{ json: modifiedData }];"},"id":"2f0feb95-52a0-43eb-9165-c515de693586","name":"Prepare Cover Regeneration","type":"n8n-nodes-base.code","typeVersion":2,"position":[1584,608]},{"parameters":{"tableId":"n8n_workflow_checkpoints","fieldsUi":{"fieldValues":[{"fieldId":"workflow_id","fieldValue":"={{ $workflow.id }}"},{"fieldId":"execution_id","fieldValue":"={{ $execution.id }}"},{"fieldId":"data","fieldValue":"={{ $json }}"}]}},"id":"save-proposal-checkpoint","name":"Save Proposal Checkpoint","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[1600,288],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"tableId":"n8n_workflow_checkpoints"},"id":"save-chapter-checkpoint","name":"Save Chapter Checkpoint","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-1504,768],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}},{"parameters":{"tableId":"n8n_workflow_checkpoints"},"id":"save-full-ebook-checkpoint","name":"Save Full E-Book Checkpoint","type":"n8n-nodes-base.supabase","typeVersion":1,"position":[-704,768],"credentials":{"supabaseApi":{"id":"pbnCP4braYKJu1cd","name":"Supabase account"}}}],"connections":{"Calculate Volume Number":{"main":[[{"node":"Rotate Theme Areas","type":"main","index":0}]]},"Generate E-Book Suggestions":{"main":[[{"node":"Set Volume Number & Title","type":"main","index":0}]]},"Set Volume Number & Title":{"main":[[{"node":"Save Market Analysis","type":"main","index":0}]]},"Save Market Analysis":{"main":[[{"node":"Extract E-Book Suggestions","type":"main","index":0}]]},"Send Telegram Notification":{"main":[[{"node":"Initialize Multi-Chapter Loop","type":"main","index":0}]]},"Initialize Multi-Chapter Loop":{"main":[[{"node":"Split Chapters (Sequential)","type":"main","index":0}]]},"Split Chapters (Sequential)":{"main":[[{"node":"Delay Between Chapters","type":"main","index":0}]]},"Delay Between Chapters":{"main":[[{"node":"Generate Chapter (Text Baustein V2)","type":"main","index":0}]]},"Generate Chapter (Text Baustein V2)":{"main":[[{"node":"Collect Chapter & Update Previous","type":"main","index":0}]]},"Collect Chapter & Update Previous":{"main":[[{"node":"Save Chapter Checkpoint","type":"main","index":0}]]},"Prepare Next Chapter":{"main":[[{"node":"Split Chapters (Sequential)","type":"main","index":0}]]},"Combine & Save Full E-Book":{"main":[[{"node":"Save Full E-Book Checkpoint","type":"main","index":0}]]},"Quality Check":{"main":[[{"node":"Generate Cover (Bild Baustein)","type":"main","index":0}]]},"Generate Cover (Bild Baustein)":{"main":[[{"node":"Convert Cover to Binary","type":"main","index":0}]]},"Upload Cover to Supabase Storage":{"main":[[{"node":"Prepare Cover Validation","type":"main","index":0}]]},"Create Professional PDF":{"main":[[{"node":"Create HTML Binary","type":"main","index":0}]]},"Create HTML Binary":{"main":[[{"node":"Generate ONIX File","type":"main","index":0}]]},"Upload PDF to Supabase Storage":{"main":[[{"node":"Save Full E-Book to DB","type":"main","index":0}]]},"Check: More Chapters?":{"true":[[{"node":"Combine & Save Full E-Book","type":"true","index":0}]],"false":[[{"node":"Prepare Next Chapter","type":"false","index":0}]]},"Convert Done to String":{"main":[[{"node":"Check: More Chapters?","type":"main","index":0}]]},"Check Existing E-Books (Duplikatsprüfung)":{"main":[[{"node":"Query Existing E-Books (Supabase)","type":"main","index":0}]]},"Filter Empty Proposals":{"main":[[{"node":"Add Volume Number to Proposal","type":"main","index":0}]]},"Normalize Query Result":{"main":[[{"node":"Calculate Volume Number","type":"main","index":0}]]},"Query Existing E-Books (Supabase)":{"main":[[{"node":"Ensure Query Item","type":"main","index":0}]]},"Ensure Query Item":{"main":[[{"node":"Normalize Query Result","type":"main","index":0}]]},"Load Secrets from Supabase":{"main":[[{"node":"Analyze Trends","type":"main","index":0},{"node":"DeepSeek Intelligent Parse","type":"main","index":0}]]},"Schedule Trigger":{"main":[[{"node":"Mark Trigger Type (Schedule)","type":"main","index":0}]]},"When clicking ‘Execute workflow’":{"main":[[{"node":"Mark Trigger Type (Manual)","type":"main","index":0}]]},"Fetch Secrets from Supabase":{"main":[[{"node":"Load Secrets from Supabase","type":"main","index":0}]]},"Add Volume Number to Proposal":{"main":[[{"node":"Create E-Book Proposals","type":"main","index":0}]]},"Extract E-Book Suggestions":{"main":[[{"node":"Split into Proposals","type":"main","index":0}]]},"Check: All Proposals Done?":{"true":[[{"node":"Send Telegram Notification","type":"main","index":0}]],"false":[[{"node":"Split into Proposals","type":"loop","index":0}]],"main":[[{"node":"Prepare Telegram Data","type":"main","index":0}],[{"node":"Send Telegram Notification","type":"main","index":0}]]},"Create E-Book Proposals":{"main":[[{"node":"Merge Proposal with Chat Data","type":"main","index":0},{"node":"Generate ISBN","type":"main","index":0}]]},"Split into Proposals":{"loop":[[{"node":"Filter Empty Proposals","type":"main","index":0}]],"main":[[{"node":"Check: All Proposals Done?","type":"main","index":0}],[{"node":"Filter Empty Proposals","type":"main","index":0}]]},"Update Chapter State":{"main":[[{"node":"Check: More Chapters?","type":"main","index":0}]]},"DeepSeek Chat Trigger":{"main":[[{"node":"Extract Chat Input","type":"main","index":0}]]},"Intelligent Market Analysis (MCP)":{"main":[[{"node":"Check Existing E-Books (Duplikatsprüfung)","type":"main","index":0},{"node":"DeepSeek Enhanced Analysis","type":"main","index":0}]]},"Merge Market Analysis Params":{"main":[[{"node":"Check Existing E-Books (Duplikatsprüfung)","type":"main","index":0}]]},"Process Analyze Trends Response":{"main":[[{"node":"Intelligent Market Analysis (MCP)","type":"main","index":0}]]},"Process DeepSeek Enhanced Response":{"main":[[{"node":"Merge Market Analysis Params","type":"main","index":0}]]},"Analyze Trends":{"main":[[{"node":"Ensure Analyze Trends Data","type":"main","index":0}]]},"Ensure Analyze Trends Data":{"main":[[{"node":"Process Analyze Trends Response","type":"main","index":0}]]},"DeepSeek Enhanced Analysis":{"main":[[{"node":"Ensure DeepSeek Enhanced Data","type":"main","index":0}]]},"Ensure DeepSeek Enhanced Data":{"main":[[{"node":"Process DeepSeek Enhanced Response","type":"main","index":0}]]},"Process DeepSeek Parse":{"main":[[{"node":"Check Existing E-Books (Duplikatsprüfung)","type":"main","index":0}]]},"Extract Chat Input":{"main":[[{"node":"Fetch Secrets from Supabase","type":"main","index":0}]]},"Merge Proposal with Chat Data":{"main":[[{"node":"Ensure Proposal Data for Telegram","type":"main","index":0}]]},"Ensure Proposal Data for Telegram":{"main":[[{"node":"Check: All Proposals Done?","type":"main","index":0}]]},"DeepSeek Intelligent Parse":{"main":[[{"node":"Merge DeepSeek Response with Chat Input","type":"main","index":0}]]},"Merge DeepSeek Response with Chat Input":{"main":[[{"node":"Process DeepSeek Parse","type":"main","index":0}]]},"Generate ISBN":{"main":[[{"node":"Merge Proposal with Chat Data","type":"main","index":0}]]},"Convert Cover to Binary":{"main":[[{"node":"Validate Cover Size & Filename","type":"main","index":0}]]},"Generate ONIX File":{"main":[[{"node":"Convert ONIX to Binary","type":"main","index":0}]]},"Upload ONIX to Supabase Storage":{"main":[[{"node":"Upload PDF to Supabase Storage","type":"main","index":0}]]},"Send Cover for Validation (Telegram)":{"main":[[{"node":"Wait for Cover Approval","type":"main","index":0}]]},"Wait for Cover Approval":{"main":[[{"node":"Check Cover Approval Response","type":"main","index":0}]]},"Send ONIX for Validation (Telegram)":{"main":[[{"node":"Wait for ONIX Approval","type":"main","index":0}]]},"Wait for ONIX Approval":{"main":[[{"node":"Prepare ONIX for Upload","type":"main","index":0}]]},"Prepare ONIX for Upload":{"main":[[{"node":"Upload to epuboo (HTTP)","type":"main","index":0},{"node":"Upload ONIX to Supabase Storage","type":"main","index":0}]]},"Check Chapter Word Count":{"main":[[{"node":"Check: Needs Extension?","type":"main","index":0}]]},"Check: Needs Extension?":{"main":[[{"node":"Extend Chapter Content","type":"main","index":0}],[{"node":"Update Chapter State","type":"main","index":0}]]},"Extend Chapter Content":{"main":[[{"node":"Merge Extended Content","type":"main","index":0}]]},"Merge Extended Content":{"main":[[{"node":"Update Chapter State","type":"main","index":0}]]},"Expert Quality Enhancement":{"main":[[{"node":"Quality Check","type":"main","index":0}]]},"Rotate Theme Areas":{"main":[[{"node":"Generate E-Book Suggestions","type":"main","index":0}]]},"Mark Trigger Type (Schedule)":{"main":[[{"node":"Fetch Secrets from Supabase","type":"main","index":0}]]},"Mark Trigger Type (Manual)":{"main":[[{"node":"Fetch Secrets from Supabase","type":"main","index":0}]]},"Prepare Telegram Data":{"main":[[{"node":"Save Proposal Checkpoint","type":"main","index":0}]]},"Prepare Telegram Notification":{"main":[[{"node":"Send Telegram Notification","type":"main","index":0}]]},"Save Full E-Book to DB":{"main":[[{"node":"Prepare Final Notification","type":"main","index":0}]]},"Prepare Final Notification":{"main":[[{"node":"Final Notification (Telegram)","type":"main","index":0}]]},"Validate Cover Size & Filename":{"main":[[{"node":"Upload Cover to Supabase Storage","type":"main","index":0}]]},"Prepare Cover Validation":{"main":[[{"node":"Send Cover for Validation (Telegram)","type":"main","index":0}]]},"Convert ONIX to Binary":{"main":[[{"node":"Prepare ONIX Validation","type":"main","index":0}]]},"Prepare ONIX Validation":{"main":[[{"node":"Send ONIX for Validation (Telegram)","type":"main","index":0}]]},"Check Cover Approval Response":{"main":[[{"node":"Create Professional PDF","type":"main","index":0}],[{"node":"Prepare Cover Regeneration","type":"main","index":0}]]},"Prepare Cover Regeneration":{"main":[[{"node":"Generate Cover (Bild Baustein)","type":"main","index":0}]]},"Save Proposal Checkpoint":{"main":[[{"node":"Prepare Telegram Notification","type":"main","index":0}]]}},"authors":"salomon owona","name":null,"description":null}}